<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[firewall-cmd语法]]></title>
    <url>%2F2019%2F04%2F09%2Ffirewall-cmd%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[firewall-cmd&ensp;&ensp;firewall-cmd是firewalld的主要命令行工具。它可用于获取有关firewalld的状态信息，获取运行时和永久环境的防火墙配置，以及更改这些信息。&ensp;&ensp;根据所选策略，需要通过身份验证才能访问或更改firewalld配置。它仅在firewalld运行时才可用 常规参数&ensp;&ensp;-h &ensp; 打印简短的帮助文本并退出 &ensp;&ensp;-V &ensp; 打印firewalld的版本字符串。此选项不能与其他选项组合使用 &ensp;&ensp;-q &ensp;不要打印状态消息 状态参数&ensp;&ensp;–state&ensp; 检查firewalld守护程序是否处于运行状态 &ensp;&ensp;–reload &ensp; 重新加载防火墙规则并保留状态信息。当前的系统配置将成为新的运行时配置，如果当前配置未处于永久配置中会因重新加载而丢失 &ensp;&ensp;–complete-reload &ensp; 完全重新加载防火墙，甚至netfilter内核模块。这会终止活动连接，此选项只应在防火墙出现严重问题时使用 &ensp;&ensp;–runtime-to-permanent &ensp; 保存当前运行时配置并重写系统配置，该方法的工作原理是，在配置firewalld时只进行运行时配置更改，一旦对配置满意并测试了它的工作方式，就可以将其保存到系统配置中 拒绝日志参数&ensp;&ensp;通过使用LogDenied选项，firewalld可以为拒绝的数据包添加简单的日志记录机制。这些是被拒绝或丢弃的数据包。 &ensp;&ensp;–get-log-denied &ensp;打印拒绝日志 &ensp;&ensp;–set-log-denied=value &ensp; value的值可以为all，unicast，broadcast，multicast和off。默认设置为off，禁用日志记录。all为所有。这会改变运行时配置和系统配置，并会重新加载防火墙以开启日志规则。 系统选项&ensp;&ensp;–permanent&ensp; 用于设置系统选项，仅在系统重启或服务restart/reload后生效，如果不加该参数则只是运行时配置的一部分 Zone&ensp;&ensp;–get-default-zone &ensp;打印连接和接口的默认区域 &ensp;&ensp;–set-default-zone=zone &ensp; 为没有选择区域的连接和接口设置默认区域。也可以更改连接或接口默认区域。这会改变运行配置和系统配置 &ensp;&ensp;–get-active-zones &ensp;打印当前区域以及区域中使用的接口和源。该是与接口或源绑定的区域 &ensp;&ensp;[–permanent] –get-zones &ensp; 将预定义的区域打印为空格分隔的列表(firewalld将网卡对应到不同的区域（zone），zone 默认共有9个:block、dmz、drop、external、home、internal、public、trusted、work &ensp;&ensp;[–permanent] –get-services&ensp; 将预定义的服务打印为空格分隔的列表 &ensp;&ensp;[–permanent] –get-icmptypes&ensp; 将预定义的icmptypes打印为空格分隔的列表。 &ensp;&ensp;[–permanent] –get-zone-of-interface=interface&ensp; 打印接口绑定的区域名称 &ensp;&ensp;[–permanent] –get-zone-of-source=source[/mask]|MAC|ipset:ipset&ensp; 打印源绑定的区域 &ensp;&ensp;[–permanent] –info-zone=zone&ensp; 打印指定Zone的相关信息 &ensp;&ensp;[–permanent] –list-all-zones&ensp; 列出所有区域添加和开启的所有内容 &ensp;&ensp;–permanent –new-zone=zone&ensp; 添加新的系统配置和空区域 &ensp;&ensp;–permanent –new-zone-from-file=filename [–name=zone]&ensp; 从已准备的区域文件中添加新永久区域 &ensp;&ensp;–permanent –delete-zone=zone&ensp; 删除现有的永久区域 &ensp;&ensp;–permanent –load-zone-defaults=zone&ensp; 加载区域默认设置或报告NO_DEFAULTS错误 &ensp;&ensp;–permanent –path-zone=zone&ensp; 打印区域配置文件的路径 &ensp;&ensp;–permanent –zone=zone –set-description=description&ensp; 为区域添加描述信息 &ensp;&ensp;–permanent –zone=zone –get-description&ensp; 打印区域描述信息 &ensp;&ensp;–permanent [–zone=zone] –get-target&ensp; 获得永久的目标区域 &ensp;&ensp;–permanent [–zone=zone] –set-target=target&ensp; 设定一个永久区域的目标。参数为：default, ACCEPT, DROP, REJECT 更改和查询区域的参数&ensp;&ensp;本节中的选项只影响一个特定区域。如果与 –zone=zone选项一起使用，则会影响指定zone。如果省略该选项，则会影响默认区域(–get-default-zone)。 &ensp;&ensp;[–permanent] [–zone=zone] –list-all&ensp; 列出在指定区域的所有内容 service&ensp;&ensp;[–permanent] [–zone=zone] –list-services&ensp; 列出区域中添加的服务 &ensp;&ensp;[–permanent] [–zone=zone] –add-service=service [–timeout=timeval]&ensp; 为Zone添加指定服务。可以多次指定此选项。也可指定时间，规则将在指定的时间内处于活动状态，并在之后自动删除。timeval格式为10s，20m或1h。–timeout不能与–permanent组合使用 &ensp;&ensp;[–permanent] [–zone=zone] –remove-service=service&ensp; 从区域中删除服务 &ensp;&ensp;[–permanent] [–zone=zone] –query-service=service&ensp; 查询是否为Znoe添加了服务。如果为真，返回0，否则返回1 port&ensp;&ensp;[–permanent] [–zone=zone] –list-ports&ensp; 列出区域中添加的端口，格式为”端口号/协议” &ensp;&ensp;[–permanent] [–zone=zone] –add-port=portid[-portid]/protocol [–timeout=timeval]&ensp; 将端口添加到区域，并设定超时时间，可以是单个端口也可以是端口范围。协议可以是 tcp, udp, sctp ， dccp等，–timeout不能与–permanent组合使用 &ensp;&ensp;[–permanent] [–zone=zone] –remove-port=portid[-portid]/protocol&ensp; 从ZONE中删除端口 &ensp;&ensp;[–permanent] [–zone=zone] –query-port=portid[-portid]/protocol&ensp; 查询是Znoe是否包含指定端口。如果为真，返回0，否则返回1 protocol&ensp;&ensp;[–permanent] [–zone=zone] –list-protocols&ensp; 列出Zone中包含的协议 &ensp;&ensp;[–permanent] [–zone=zone] –add-protocol=protocol [–timeout=timeval]&ensp; 为Zone添加指定协议。可以多次指定此选项。也可指定时间，规则将在指定的时间内处于活动状态，并在之后自动删除。timeval格式为10s，20m或1h。–timeout不能与–permanent组合使用 &ensp;&ensp;[–permanent] [–zone=zone] –remove-protocol=protocol&ensp; 从ZONE中删除协议 &ensp;&ensp;[–permanent] [–zone=zone] –query-protocol=protocol&ensp; 查询是Znoe是否包含指定协议。如果为真，返回0，否则返回1 source-port&ensp;&ensp;[–permanent] [–zone=zone] –list-source-ports&ensp; 列出区域中添加的源端口，格式为”端口号/协议” &ensp;&ensp;[–permanent] [–zone=zone] –add-source-port=portid[-portid]/protocol [–timeout=timeval]&ensp; 将源端口添加到区域，并设定超时时间，可以是单个端口也可以是端口范围。协议可以是 tcp, udp, sctp ， dccp等，–timeout不能与–permanent组合使用 &ensp;&ensp;[–permanent] [–zone=zone] –remove-source-port=portid[-portid]/protocol&ensp; 从ZONE中删除源端口 &ensp;&ensp;[–permanent] [–zone=zone] –query-source-port=portid[-portid]/protocol&ensp; 查询是Znoe是否包含指定源端口。如果为真，返回0，否则返回1 icmp-block&ensp;&ensp;[–permanent] [–zone=zone] –list-icmp-blocks&ensp; 列出Zone中的ICMP协议块 &ensp;&ensp;[–permanent] [–zone=zone] –add-icmp-block=icmptype [–timeout=timeval]&ensp; 为Zone的icmp块添加icmptype，可以多次指定此选项。也可指定时间，规则将在指定的时间内处于活动状态，并在之后自动删除。timeval格式为10s，20m或1h。–timeout不能与–permanent组合使用 &ensp;&ensp;[–permanent] [–zone=zone] –remove-icmp-block=icmptype&ensp; 从Zone的icmp块中删除icmptype &ensp;&ensp;[–permanent] [–zone=zone] –query-icmp-block=icmptype&ensp; 查询是Zone中是否包含指定icmptype。如果为真，返回0，否则返回1 forward-ports&ensp;&ensp;[–permanent] [–zone=zone] –list-forward-ports&ensp; 列出Zone中的IPv4转发端口 &ensp;&ensp;[–permanent] [–zone=zone] –add-forward-port=port=portid[-portid]:proto=protocol[:toport=portid[-portid]][:toaddr=address[/mask]] [–timeout=timeval]&ensp; 在Zone中添加端口转发，可以多次指定此选项。也可指定时间，规则将在指定的时间内处于活动状态，并在之后自动删除。timeval格式为10s，20m或1h。–timeout不能与–permanent组合使用。&ensp;&ensp;端口可以是单个端口号，也可以是端口范围portid-portid。协议可以是tcp、udp、sctp或dccp。目标地址是一个简单的IP地址。 &ensp;&ensp;[–permanent] [–zone=zone] –remove-forward-port=port=portid[-portid]:proto=protocol[:toport=portid[-portid]][:toaddr=address[/mask]]&ensp; 删除端口转发 &ensp;&ensp;[–permanent] [–zone=zone] –query-forward-port=port=portid[-portid]:proto=protocol[:toport=portid[-portid]][:toaddr=address[/mask]]&ensp; 查询端口转发，如果为真，返回0，否则返回1 masquerade&ensp;&ensp;[–permanent] [–zone=zone] –add-masquerade [–timeout=timeval] &ensp; 设置IPv4地址转换，可指定时间，规则将在指定的时间内处于活动状态，并在之后自动删除。timeval格式为10s，20m或1h。 &ensp;&ensp;[–permanent] [–zone=zone] –remove-masquerade&ensp; 关闭Zone中的Ipv4地址转换，当其超时了也会被关闭 &ensp;&ensp;[–permanent] [–zone=zone] –query-masquerade&ensp; 查询Zone中是否开启了IPv4地址转换，如果为真，返回0，否则返回1 rich-rule&ensp;&ensp;[–permanent] [–zone=zone] –list-rich-rules&ensp; 列出Zone中的rich-rule &ensp;&ensp;[–permanent] [–zone=zone] –add-rich-rule=’rule’ [–timeout=timeval]&ensp; 为Zone中添加rich-rule &ensp;&ensp;[–permanent] [–zone=zone] –remove-rich-rule=’rule’&ensp; 删除 Zone中的rich-rule &ensp;&ensp;[–permanent] [–zone=zone] –query-rich-rule=’rule’&ensp; 查询Zone中是否有rich-rule，如果为真，返回0，否则返回1 接口绑定参数&ensp;&ensp;将接口绑定到Zone意味着此Zone设置用于限制通过接口的流量。&ensp;&ensp;本节中的选项只影响一个特定区域。如果与 –zone=zone选项一起使用，则会影响指定zone。如果省略该选项，则会影响默认区域(–get-default-zone)。使用firewall-cmd –get-zones &ensp;&ensp;[–permanent] [–zone=zone] –list-interfaces&ensp; 列出绑定到Zone的接口 &ensp;&ensp;[–permanent] [–zone=zone] –add-interface=interface&ensp; 绑定接口到Zone。如果接口受NetworkManager控制，则首先连接到接口更改其连接区域。如果失败，则在防火墙中创建区域绑定。对于不受NetworkManager控制的接口，firewalld尝试更改ifcfg文件中的区域设置（如果该文件存在）。 &ensp;&ensp;作为终端用户，在大多数情况下不需要这样做，当没有设定NM_CONTROLLED=no时，NetworkManager会自动根据ifcfg接口文件中的zone=option向Zone中添加接口，只有在没有/etc/sysconfig/network scripts/ifcfg接口文件的情况下才应该这样做。如果存在这样的文件，并且使用–add-interface选项将接口添加到区域中，请确保在这两种情况下区域是相同的，否则行为将是未定义的。 &ensp;&ensp;[–zone=zone] –change-interface=interface&ensp; 如果接口受NetworkManager控制，则首先连接到接口更改其连接区域。如果失败，则在防火墙中创建区域绑定。对于不受NetworkManager控制的接口，firewalld尝试更改ifcfg文件中的区域设置（如果该文件存在）。. &ensp;&ensp;更改接口绑定的区域。步骤是–remove-interface然后–add-interface。如果接口以前没有绑定到Zone，那么它类似于–add-interface &ensp;&ensp;[–permanent] [–zone=zone] –query-interface=interface&ensp; 查询接口是否和该Zone绑定 &ensp;&ensp;[–permanent] –remove-interface=interface&ensp; 仅用于删除不受NetworkManager控制的接口，firewalld不会更改ifcfg文件中的区域设置 绑定源(source)的参数&ensp;&ensp;将源绑定到Zone意味着此区域设置用于限制来自此源的流量。 &ensp;&ensp;源地址是IP地址或地址范围，要么是带有IPv4或IPv6掩码的网络IP地址，或者是MAC地址，或者是ipset: prefix。对于IPv4，掩码可以是网络掩码，也可以是普通数字。对于IPv6，掩码是一个普通的数字。不支持使用主机名。 &ensp;&ensp;[–permanent] [–zone=zone] –list-sources&ensp; 列出绑定到Zone的源 &ensp;&ensp;[–permanent] [–zone=zone] –add-source=source[/mask]|MAC|ipset:ipset&ensp; 将源绑定到Zone &ensp;&ensp;[–zone=zone] –change-source=source[/mask]|MAC|ipset:ipset&ensp; 改变区域中绑定的源 &ensp;&ensp;[–permanent] [–zone=zone] –query-source=source[/mask]|MAC|ipset:ipset&ensp; 查询源是否在Zone中 &ensp;&ensp;[–permanent] –remove-source=source[/mask]|MAC|ipset:ipset&ensp; 删除源 IPSet 参数12firewall-cmd --get-ipset-types #打印出ipset类型hash:ip hash:ip,mark hash:ip,port hash:ip,port,ip hash:ip,port,net hash:mac hash:net hash:net,iface hash:net,net hash:net,port hash:net,port,net &ensp;&ensp;–permanent –new-ipset=ipset –type=type [–family=inet|inet6] [–option=key[=value]]&ensp; 添加永久的ipset，以及指定各种参数 &ensp;&ensp;–permanent –new-ipset-from-file=filename [–name=ipset]&ensp; 从文件中添加永久ipset配置 &ensp;&ensp;–permanent –delete-ipset=ipset&ensp; 删除已存在的ipset配置 &ensp;&ensp;–permanent –load-ipset-defaults=ipset&ensp; 加载ipset 默认配置或者报告NO_DEFAULTS &ensp;&ensp;[–permanent] –info-ipset=ipset&ensp; 打印ipset的信息 1234ipset type: type options: option1[=value1] .. entries: entry1 .. &ensp;&ensp;[–permanent] –get-ipsets&ensp; 打印预定义的ipset &ensp;&ensp;–permanent –ipset=ipset –set-description=description&ensp; 为ipset添加描述 &ensp;&ensp;–permanent –ipset=ipset –get-description&ensp; 打印ipset的描述 &ensp;&ensp;[–permanent] –ipset=ipset –add-entry=entry&ensp; 为ipset添加新条目 &ensp;&ensp;Adding an entry to an ipset with option timeout is permitted, but these entries are not tracked by firewalld. &ensp;&ensp;[–permanent] –ipset=ipset –remove-entry=entry&ensp; 删除ipset中的一个条目 &ensp;&ensp;[–permanent] –ipset=ipset –query-entry=entry&ensp; 查询ipset中是否包含指定条目。Querying an ipset with a timeout will yield an error. Entries are not tracked for ipsets with a timeout. &ensp;&ensp;[–permanent] –ipset=ipset –get-entries&ensp; 列出ipset的所有条目 &ensp;&ensp;[–permanent] –ipset=ipset –add-entries-from-file=filename&ensp; 使用文件向ipset添加条目，对于文件中列出的条目在ipset中已经存在的时候，打印警告。以#号、分号开头的行以及空白行会被忽略 &ensp;&ensp;[–permanent] –ipset=ipset –remove-entries-from-file=filename&ensp; 使用文件从ipset删除条目，对于文件中列出的条目在ipset中已经存在的时候，打印警告。以#号、分号开头的行以及空白行会被忽略 &ensp;&ensp;–permanent –path-ipset=ipset&ensp; 打印ipset配置文件的路径 Service参数&ensp;&ensp;此部分中的选项仅影响一个特定服务。 &ensp;&ensp;[–permanent] –info-service=service&ensp; 打印Service相关信息 123456service ports: port1 .. protocols: protocol1 .. source-ports: source-port1 .. modules: module1 .. destination: ipv1:address1 .. &ensp;&ensp;–permanent –new-service=service&ensp;系统配置中添加服务 &ensp;&ensp;–permanent –new-service-from-file=filename [–name=service]&ensp; 通过文件项系统配置中添加服务 &ensp;&ensp;–permanent –delete-service=service&ensp; 删除已存在的服务 &ensp;&ensp;–permanent –load-service-defaults=service&ensp; 加载服务默认设置或者报告NO_DEFAULTS错误 &ensp;&ensp;–permanent –path-service=service&ensp; 打印服务配置文件的路径 &ensp;&ensp;–permanent –service=service –set-description=description&ensp; 为服务添加描述 &ensp;&ensp;–permanent –service=service –get-description&ensp; 打印服务的描述 &ensp;&ensp;–permanent –service=service –add-port=portid[-portid]/protocol&ensp; 向服务中添加端口 &ensp;&ensp;–permanent –service=service –remove-port=portid[-portid]/protocol&ensp; 从指定的服务中移除某端口 &ensp;&ensp;–permanent –service=service –query-port=portid[-portid]/protocol&ensp; 查询端口是否添加到服务中 &ensp;&ensp;–permanent –service=service –get-ports&ensp; 列出服务中添加的端口 &ensp;&ensp;–permanent –service=service –add-protocol=protocol&ensp; 向服务中添加协议 &ensp;&ensp;–permanent –service=service –remove-protocol=protocol&ensp; 从服务中删除某协议 &ensp;&ensp;–permanent –service=service –query-protocol=protocol&ensp;查询服务中是否包含某协议 &ensp;&ensp;–permanent –service=service –get-protocols&ensp;列出服务中包含的协议 &ensp;&ensp;–permanent –service=service –add-source-port=portid[-portid]/protocol&ensp; 向某服务中添加源端口 &ensp;&ensp;–permanent –service=service –remove-source-port=portid[-portid]/protocol&ensp;从某服务中删除源端口 &ensp;&ensp;–permanent –service=service –query-source-port=portid[-portid]/protocol&ensp;查询源端口是否添加到服务中 &ensp;&ensp;–permanent –service=service –get-source-ports&ensp; 列出某服务中的添加的源端口 &ensp;&ensp;–permanent –service=service –add-module=module&ensp; 向服务中添加模块 &ensp;&ensp;–permanent –service=service –remove-module=module&ensp; 从服务中删除模块 &ensp;&ensp;–permanent –service=service –query-module=module&ensp; 查询模块是否已经添加到服务 &ensp;&ensp;–permanent –service=service –get-modules&ensp; 列出服务中添加的模块 &ensp;&ensp;–permanent –service=service –set-destination=ipv:address[/mask]&ensp; 为某服务设置目的地址 &ensp;&ensp;–permanent –service=service –remove-destination=ipv&ensp; 从某服务中删除目的地址 &ensp;&ensp;–permanent –service=service –query-destination=ipv:address[/mask]&ensp; 查询目的地址是否存在于服务设置中 &ensp;&ensp;–permanent –service=service –get-destinations&ensp; 列出服务中添加的目的地址 Internet Control Message Protocol (ICMP)类型选项&ensp;&ensp;Options in this section affect only one particular icmptype. 1234567891011firewall-cmd --get-icmptypes #获取所有支持的ICMP类型[root@docker-study ~]# firewall-cmd --get-icmptypesaddress-unreachable bad-header communication-prohibited destination-unreachable echo-reply echo-request fragmentation-needed host-precedence-violation host-prohibited host-redirect host-unknown host-unreachable ip-header-bad neighbour-advertisement neighbour-solicitation network-prohibited network-redirect network-unknown network-unreachable no-route packet-too-big parameter-problem port-unreachable precedence-cutoff protocol-unreachable redirect required-option-missing router-advertisement router-solicitation source-quench source-route-failed time-exceeded timestamp-reply timestamp-request tos-host-redirect tos-host-unreachable tos-network-redirect tos-network-unreachable ttl-zero-during-reassembly ttl-zero-during-transit unknown-header-type unknown-option &ensp;&ensp;[–permanent] –info-icmptype=icmptype &ensp; 打印有关ICMPtype 的信息 123[root@docker-study ~]# firewall-cmd --info-icmptype=bad-headerbad-header destination: ipv6 &ensp;&ensp;–permanent –new-icmptype=icmptype &ensp; 添加新的ICMPtype &ensp;&ensp;–permanent –new-icmptype-from-file=filename [–name=icmptype] &ensp; 用过文件添加新的ICMPtype &ensp;&ensp;–permanent –delete-icmptype=icmptype &ensp;删除已存在的ICMPtype &ensp;&ensp;–permanent –load-icmptype-defaults=icmptype &ensp; 加载icmptype默认设置或报告NO_DEFAULTS错误 &ensp;&ensp;–permanent –icmptype=icmptype –set-description=description&ensp;&ensp; 为ICMPtype 设置新的描述 &ensp;&ensp;–permanent –icmptype=icmptype –get-description &ensp; 打印指定ICMPtype的描述 &ensp;&ensp;–permanent –icmptype=icmptype –add-destination=ipv&ensp; 在ICMPtype中开启目的地址，可以是ipv4 或 ipv6 &ensp;&ensp;–permanent –icmptype=icmptype –remove-destination=ipv &ensp; 在ICMPtype中禁用目的地址，可以是ipv4 或 ipv6 &ensp;&ensp;–permanent –icmptype=icmptype –query-destination=ipv&ensp; 返回在ICMPtype中是否开启ipv4 或ipv6目的地址 1234[root@docker-study ~]# firewall-cmd --permanent --icmptype=bad-header --query-destination=ipv4no[root@docker-study ~]# firewall-cmd --permanent --icmptype=bad-header --query-destination=ipv6yes &ensp;&ensp;–permanent –icmptype=icmptype –get-destinations &ensp; List destinations in permanent icmptype. 12[root@docker-study ~]# firewall-cmd --permanent --icmptype=bad-header --get-destinationsipv6 &ensp;&ensp;–permanent –path-icmptype=icmptype&ensp; 打印出icmptype配置文件的路径。 锁定(Lockdown)参数&ensp;&ensp;如果本地应用程序或服务以根用户身份运行（例如：libvirt）或使用policykit进行身份验证，则它们可以更改防火墙配置。使用此功能，管理员可以锁定防火墙配置，以便只有锁定白名单上的应用程序才能请求防火墙更改。 &ensp;&ensp;锁定访问检查限制了正在更改防火墙规则的D-Bus方法。查询、列表和get方法不受限制。 &ensp;&ensp;锁定功能是firewalld用户和应用程序策略的一个非常轻量级的版本，默认情况下是关闭的。&ensp;&ensp;–lockdown-on&ensp;启用锁定。注意 , 如果启用锁定时firewall-cmd不在锁定白名单中，则无法使用firewall-cmd再次禁用它，需要编辑firewalld.conf。这是运行时和永久性更改。 &ensp;&ensp;–lockdown-off&ensp;禁用锁定。这是运行时和永久性更改。 &ensp;&ensp;–query-lockdown&ensp;查询是否启用了锁定。如果启用了锁定，则返回0，否则返回1。 锁定白名单(Lockdown Whitelist)参数&ensp;&ensp;该锁定白名单可以包括commands，contexts，users和user ids。如果白名单上的命令条目以星号“*”结尾，那么以该命令开头的所有命令行都将匹配。如果没有“*”，则必须匹配绝对命令包含的参数。 &ensp;&ensp;用户root和其他用户的命令并不总是相同。示例：root使用 /bin/firewall-cmd，在Fedora上的普通用户使用 /usr/bin/firewall-cmd。 &ensp;&ensp;[ –permanent]–list-lockdown-whitelist-commands&ensp;列出白名单中的所有命令。 &ensp;&ensp;[ –permanent] –add-lockdown-whitelist-command=command&ensp;添加command到白名单。 &ensp;&ensp;[ –permanent] –remove-lockdown-whitelist-command=command&ensp;command从白名单中 删除。 &ensp;&ensp;[ –permanent] –query-lockdown-whitelist-command=command&ensp;查询是否command在白名单中。如果为true则返回0，否则返回1。 &ensp;&ensp;[ –permanent]–list-lockdown-whitelist-contexts&ensp;列出白名单中的所有环境。 &ensp;&ensp;[ –permanent] –add-lockdown-whitelist-context=context&ensp;添加context到白名单。 &ensp;&ensp;[ –permanent] –remove-lockdown-whitelist-context=context&ensp;从白名单中 删除context。 &ensp;&ensp;[ –permanent] –query-lockdown-whitelist-context=context&ensp;查询context是否在白名单中。如果为true则返回0，否则返回1。 &ensp;&ensp;[ –permanent]–list-lockdown-whitelist-uids&ensp;列出白名单中的所有用户ID。 &ensp;&ensp;[ –permanent] –add-lockdown-whitelist-uid=uid&ensp;添加uid到白名单。 &ensp;&ensp;[ –permanent] –remove-lockdown-whitelist-uid=uid&ensp;从白名单中 删除用户ID 。 &ensp;&ensp;[ –permanent] –query-lockdown-whitelist-uid=uid&ensp;查询用户uid标识是否在白名单中。如果为true则返回0，否则返回1。 &ensp;&ensp;[ –permanent]–list-lockdown-whitelist-users&ensp;列出白名单中的所有用户名。 &ensp;&ensp;[ –permanent] –add-lockdown-whitelist-user=user&ensp;添加user到白名单。 &ensp;&ensp;[ –permanent] –remove-lockdown-whitelist-user=user&ensp;从白名单中 删除用户。 &ensp;&ensp;[ –permanent] –query-lockdown-whitelist-user=user&ensp;查询user是否在白名单中。如果为true则返回0，否则返回1。 紧急参数&ensp;&ensp;–panic-on &ensp; 开启紧急模式，所有进出包都被丢弃，活动连接将超时。只有在网络环境出现严重问题时才启用此功能。例如，黑客入侵。这是运行时配置的更改 &ensp;&ensp;–panic-off&ensp; 禁用紧急选项 &ensp;&ensp;–query-panic&ensp; 查询是否开启紧急模式]]></content>
      <tags>
        <tag>Firewall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[firewalld概念及配置项]]></title>
    <url>%2F2019%2F04%2F05%2Ffirewalld%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%85%8D%E7%BD%AE%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[概念&ensp;&ensp;Firewall被设计为两层：核心层和D-BUS层。核心层负责处理firewall的配置和iptables, ip6tables, ebtables, ipset，module loader 等底层功能。&ensp;&ensp;Firewalld D-Bus接口是更改和创建防火墙配置的主要方法。该接口被所有firewalld提供的在线工具所使用，例如firewall-cmd、firewall-config和firewall-applet。firewall-offline-cmd 并不与Firewalld通信，而是通过带有IO处理程序的Firewalld核心直接修改和创建firewalld配置文件。firewall-offline-cmd可以在Firewalld运行时使用，但不推荐使用它，因为它在大约5秒后才会更改防火墙中可见的永久配置。 &ensp;&ensp;Firewalld不依赖于NetworkManager组件，但是推荐使用。如果不使用NetworkManager，会有一些限制，例如:Firewalld不会收到关于网络设备重命名的通知。如果在network已经启动之后才启动firewalld，那么连接和手动创建的接口不会绑定到zone。使用firewall-cmd [–permanent] –zone=zone –add-interface=interface命令可以将接口添加到zone，但是要确保是否有/etc/sysconfig/network-scripts/ifcfg-*** 的网卡文件，ZONE和zone在这里不区分大小写，默认zone为空。 &ensp;&ensp;Firewalld支持znoe、service、ipset和icmptype 配置关于目录&ensp;&ensp;Firewall 支持两个配置目录：默认和后备配置，系统特定配置 默认和后备配置&ensp;&ensp;/usr/lib/firewalld目录下包含icmptypes, services ,zones等默认和后备配置，Firewall所提供的晚间不应被修改，做出的更改会随着Firewall的更新而消失，Additional icmptypes, services and zones can be provided with packages or by creating files. 系统特定配置&ensp;&ensp;/etc/firewalld中存储的系统或用户配置要么由系统管理员创建，要么使用firewalld的配置接口进行定制，要么手工创建。这些文件将覆盖默认文件。要手动更改预定义的 icmptypes, zones，services的设置，应将文件从默认配置目录复制到系统配置目录中，并相应地进行修改。&ensp;&ensp;如果没有/etc/firewalld目录，Firewalld将使用firewall .conf中的默认配置和默认设置。 运行性配置和永久配置&ensp;&ensp;配置被分为运行时配置和永久配置 运行时配置&ensp;&ensp;运行时配置是实际有效的配置，应用于内核中的防火墙，Firewalld服务启动时，永久配置变为运行时配置，运行时配置中的更改不会自动保存到永久配置。运行时配置将随着Firewalld服务停止而丢失。&ensp;&ensp;Firewalld重载时将用永久配置替换运行时配置。重新加载后，将恢复已更改的zone绑定。 永久配置&ensp;&ensp;永久配置存储在配置文件中，将在每次机器重启或服务重新加载或重新启动时加载并成为新的运行时配置运行时环境同样可用于创建符合需要的防火墙设置，当完成工作时可以和运行时状态一起迁移(When it is complete and working it can be migrated with the runtime to permanent migration).&ensp;&ensp;可以使用firewall-config和firewall-cmd –runtime-to-permanent两条命令。如果防火墙设置不工作，一个简单的firewalld reload/restart 将重新加载永久配置。 firewalld.conf&ensp;&ensp;/etc/firewalld中的firewall .conf文件提供了firewalld的基本配置。如果不存在该文件或/etc/firewalld缺失，则将使用firewalld内部缺省值。 &ensp;&ensp;下面列出的为设置默认参数： Default Zone&ensp;&ensp;如果区域字符串为空，则使用默认区域。没有指定绑定到其他区域的所有内容都将由默认区域处理。 1234# default zone# The default zone used if an empty zone string is used.# Default: publicDefaultZone=public Minimal Mark&ensp;&ensp;这个最小值以下的标记可以自由使用，例如在direct接口中。如果需要更多的自由数则增加最小值。 12345# Minimal mark# Marks up to this minimum are free for use for example in the direct # interface. If more free marks are needed, increase the minimum# Default: 100MinimalMark=100 Clean Up On Exit&ensp;&ensp;如果设置为no或false，防火墙配置将不会在firewalld退出或停止时清除 12345# Clean up on exit# If set to no or false the firewall configuration will not get cleaned up# on exit or stop of firewalld# Default: yesCleanupOnExit=yes Lockdown&ensp;&ensp;如果设置为”启用”，使用D-Bus接口的防火墙的更改将仅限于锁定白名单中列出的应用程序。锁定白名单文件是lockdown-white.xml。 123456# Lockdown# If set to enabled, firewall changes with the D-Bus interface will be limited# to applications that are listed in the lockdown whitelist.# The lockdown whitelist file is lockdown-whitelist.xml# Default: noLockdown=no IPv6_rpfilter&ensp;&ensp;对IPv6数据包执行反向路径筛选测试。如果对包的应答通过与包到达时相同的接口发送，那么将被接受，否则将被丢弃(防止DDOS和IP Spoofing)。IPv4的rp_filter是使用sysctl控制的。 1234567# IPv6_rpfilter# Performs a reverse path filter test on a packet for IPv6. If a reply to the# packet would be sent via the same interface that the packet arrived on, the # packet will match and be accepted, otherwise dropped.# The rp_filter for IPv4 is controlled using sysctl.# Default: yesIPv6_rpfilter=yes Individual Calls&ensp;&ensp;Do not use combined -restore calls, but individual calls. This increases the time that is needed to apply changes and to start the daemon, but is good for debugging. 123456# IndividualCalls# Do not use combined -restore calls, but individual calls. This increases the# time that is needed to apply changes and to start the daemon, but is good for# debugging.# Default: noIndividualCalls=no Log Denied&ensp;&ensp;在缺省规则的输入、转发和输出链中添加日志记录规则，并在区域中添加最终的拒绝和删除规则。可能的值是: all, unicast, broadcast, multicast,off 123456# LogDenied# Add logging rules right before reject and drop rules in the INPUT, FORWARD# and OUTPUT chains for the default rules and also final reject and drop rules# in zones. Possible values are: all, unicast, broadcast, multicast and off.# Default: offLogDenied=off AutomaticHelpers&ensp;&ensp;为了安全使用iptables和连接跟踪助手，建议关闭AutomaticHelpers。但是这可能会对使用netfilter helper作为/proc/sys/net/netfilter/nf_conntrack_helper中的sysctl设置的其他服务产生副作用。对于系统设置，将使用内核或sysctl中设置的默认值。可能的值是:yes、no、system。 123456789# AutomaticHelpers# For the secure use of iptables and connection tracking helpers it is# recommended to turn AutomaticHelpers off. But this might have side effects on# other services using the netfilter helpers as the sysctl setting in# /proc/sys/net/netfilter/nf_conntrack_helper will be changed.# With the system setting, the default value set in the kernel or with sysctl# will be used. Possible values are: yes, no and system.# Default: systemAutomaticHelpers=system]]></content>
      <tags>
        <tag>Firewall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 配置 TLS 认证]]></title>
    <url>%2F2019%2F04%2F04%2FDocker-%E9%85%8D%E7%BD%AE-TLS-%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[&ensp;&ensp;上一篇文章中的警告在这里展开，警告内容如下： 1234WARNING: API is accessible on http://0.0.0.0:2376 without encryption. Access to the remote API is equivalent to root access on the host. Refer to the &apos;Docker daemon attack surface&apos; section in the documentation for more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface &ensp;&ensp;这样所有 ip 都能通过 docker -H &lt;remote-dcoker-server_ip&gt;:6379 [OPTION]命令与远程的 docker 守护进程通信，操作 docker 容器，生产上不提倡这种做法。 TLS&ensp;&ensp;传输层安全性协议（英语：Transport Layer Security，缩写作TLS），及其前身安全套接层（Secure Sockets Layer，缩写作SSL）是一种安全协议，目的是为互联网通信提供安全及数据完整性保障。 &ensp;&ensp;CA是证书的签发机构。CA是负责签发证书、认证证书、管理已颁发证书的机关。它要制定政策和具体步骤来验证、识别用户身份，并对用户证书进行签名，以确保证书持有者的身份和公钥的拥有权。 &ensp;&ensp;CA 也拥有一个证书（内含公钥）和私钥。网上的公众用户通过验证 CA 的签字从而信任 CA ，任何人都可以得到 CA 的证书（含公钥），用以验证它所签发的证书。 &ensp;&ensp;证书包含以下信息：申请者公钥、申请者的组织信息和个人信息、签发机构 CA 的信息、有效时间、证书序列号等信息的明文，同时包含一个签名。 &ensp;签名的产生算法：首先，使用散列函数计算公开的明文信息的信息摘要，然后，采用 CA 的私钥对信息摘要进行加密，密文即签名。 &ensp;&ensp;整个过程为： 1.服务器向CA机构获取证书，当浏览器首次请求服务器的时候，服务器返回证书给浏览器。（证书包含：公钥+申请者与颁发者的相关信息+签名） 2.浏览器得到证书后，开始验证证书的相关信息。 3.验证完证书后，如果证书有效，客户端是生成一个随机数，然后用证书中的公钥进行加密，加密后，发送给服务器，服务器用私钥进行解密，得到随机数。之后双方便开始用该随机数作为钥匙，对要传递的数据进行加密、解密。 &ensp;&ensp;我们需要在远程 docker 服务器使用CA 认证来生成客户端和服务端证书、服务器密钥，然后自签名，再颁发证书给需要连接远程 docker ademon 的客户端。 以上内容部分摘自https://www.cnblogs.com/yunlongaimeng/p/9417276.html TLS验证&ensp;&ensp;文档中指出：Docker over TLS should run on TCP port 2376. 服务端（CA机构、Docker Daemon在同一台服务器）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#1.生成CA私钥ca-key.pem（rsa加密）root@admin-dsq:~/CA# openssl genrsa -aes256 -out ca-key.pem 4096 Generating RSA private key, 4096 bit long modulus.................................................................++.....................................................................................................................................................................++e is 65537 (0x10001)Enter pass phrase for ca-key.pem:Verifying - Enter pass phrase for ca-key.pem:#2.生成CA自签名证书ca.pem（其中包含证书信息、公钥信息）root@admin-dsq:~/CA# openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pemEnter pass phrase for ca-key.pem:You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &apos;.&apos;, the field will be left blank.-----Country Name (2 letter code) [AU]:CHState or Province Name (full name) [Some-State]:HBLocality Name (eg, city) []:SJZOrganization Name (eg, company) [Internet Widgits Pty Ltd]:HEUETOrganizational Unit Name (eg, section) []:NETLABCommon Name (e.g. server FQDN or YOUR name) []:admin-dsqEmail Address []:#3.生成服务器私钥server-key.pemroot@admin-dsq:~/local_p_key# openssl genrsa -out server-key.pem 4096Generating RSA private key, 4096 bit long modulus.....................................++...........................................++e is 65537 (0x10001)#4. 生成服务器申请文件server.csrroot@admin-dsq:~/local_p_key# openssl req -subj &quot;/CN=admin-dsq&quot; -sha256 -new -key server-key.pem -out server.csr#5.由于可以通过IP地址和DNS名称建立TLS连接，因此在创建证书时需要指定IP地址#即允许通过admin-dsq、172.18.74.62/127.0.0.1建立TLS连接root@admin-dsq:~/local_p_key# echo subjectAltName = DNS:admin-dsq,IP:172.18.74.62,IP:127.0.0.1 &gt;&gt; extfile.cnf#6.将Docker守护程序密钥的扩展使用情况属性设置为仅用于服务器身份验证root@admin-dsq:~/local_p_key# echo extendedKeyUsage = serverAuth &gt;&gt; extfile.cnf#7.向服务器颁发CA证书server-cert.pemroot@admin-dsq:~/local_p_key# openssl x509 -req -days 365 -sha256 -in server.csr -CA /root/CA/ca.pem -CAkey \/root/CA/ca-key.pem -CAcreateserial -out server-cert.pem -extfile extfile.cnfSignature oksubject=/CN=admin-dsqGetting CA Private KeyEnter pass phrase for ca-key.pem:#8.现在，可以使Docker守护程序仅接受来自提供CA信任的证书的客户端的连接root@admin-dsq:~/local_p_key# dockerd --tlsverify --tlscacert=/root/CA/ca.pem --tlscert=server-cert.pem --tlskey=server-key.pem -H 0.0.0.0:2376INFO[2019-04-03T10:37:04.136031407+08:00] parsed scheme: &quot;unix&quot; module=grpcINFO[2019-04-03T10:37:04.136192758+08:00] scheme &quot;unix&quot; not registered, fallback to default scheme module=grpcINFO[2019-04-03T10:37:04.136474710+08:00] parsed scheme: &quot;unix&quot; module=grpcINFO[2019-04-03T10:37:04.136532152+08:00] scheme &quot;unix&quot; not registered, fallback to default scheme module=grpcINFO[2019-04-03T10:37:04.137278333+08:00] ccResolverWrapper: sending new addresses to cc: [&#123;unix:///run/containerd/containerd.sock 0 &lt;nil&gt;&#125;] module=grpcINFO[2019-04-03T10:37:04.140277683+08:00] [graphdriver] using prior storage driver: overlay2 INFO[2019-04-03T10:37:04.140248053+08:00] ClientConn switching balancer to &quot;pick_first&quot; module=grpcINFO[2019-04-03T10:37:04.140963667+08:00] pickfirstBalancer: HandleSubConnStateChange: 0xc4205fc620, CONNECTING module=grpcINFO[2019-04-03T10:37:04.141777530+08:00] pickfirstBalancer: HandleSubConnStateChange: 0xc4205fc620, READY module=grpcINFO[2019-04-03T10:37:04.142772412+08:00] ccResolverWrapper: sending new addresses to cc: [&#123;unix:///run/containerd/containerd.sock 0 &lt;nil&gt;&#125;] module=grpcINFO[2019-04-03T10:37:04.142836434+08:00] ClientConn switching balancer to &quot;pick_first&quot; module=grpcINFO[2019-04-03T10:37:04.142922653+08:00] pickfirstBalancer: HandleSubConnStateChange: 0xc4205fc8e0, CONNECTING module=grpcINFO[2019-04-03T10:37:04.143886004+08:00] pickfirstBalancer: HandleSubConnStateChange: 0xc4205fc8e0, READY module=grpcINFO[2019-04-03T10:37:04.179907069+08:00] Graph migration to content-addressability took 0.00 seconds WARN[2019-04-03T10:37:04.180499617+08:00] Your kernel does not support cgroup rt period WARN[2019-04-03T10:37:04.180563168+08:00] Your kernel does not support cgroup rt runtime INFO[2019-04-03T10:37:04.181663787+08:00] Loading containers: start. INFO[2019-04-03T10:37:04.463375483+08:00] Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address INFO[2019-04-03T10:37:04.607165080+08:00] Loading containers: done. INFO[2019-04-03T10:37:04.669799451+08:00] Docker daemon commit=e8ff056 graphdriver(s)=overlay2 version=18.09.5INFO[2019-04-03T10:37:04.669985943+08:00] Daemon has completed initialization INFO[2019-04-03T10:37:04.702975124+08:00] API listen on [::]:2376#此时docker daemon已经启动监听2376端口 &ensp;&ensp;使用scp将ca.pem，ca-key.pem发送到客户端服务器。其实应该先将服务器和客户端的申请文件发送至CA，由CA认证后向二者发放CA证书。 客户端&ensp;&ensp;对于客户端身份验证，应创建客户端密钥和证书签名请求 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#1.生成客户端私钥client-key.pem[root@docker-study client]# openssl genrsa -out client-key.pem 4096Generating RSA private key, 4096 bit long modulus......................................................++.......................++e is 65537 (0x10001)#2.生成客户端申请文件client.csr[root@docker-study client]# openssl req -subj &apos;/CN=docker-study&apos; -new -key client-key.pem -out client.csr#3.使密钥适合客户端身份验证[root@docker-study client]# echo extendedKeyUsage = clientAuth &gt; extfile-client.cnf#4.向客户端颁发CA证书client-cert.pem[root@docker-study client]# openssl x509 -req -days 365 -sha256 -in client.csr -CA /root/ca.pem -CAkey \/root/ca-key.pem -CAcreateserial -out client-cert.pem -extfile extfile-client.cnfSignature oksubject=/CN=docker-studyGetting CA Private KeyEnter pass phrase for ../ca-key.pem:#5.向Docker Daemon连接，要携带CA自签名证书、客户端CA证书、客户端私钥[root@docker-study client]# docker --tlsverify --tlscacert=/root/ca.pem --tlscert=client-cert.pem --tlskey=client-key.pem -H 172.18.74.62 info Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 18.09.5Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: bb71b10fd8f58240ca47fbb579b9d1028eea7c84runc version: 2b18fe1d885ee5083ef9f0838fee39b62d653e30init version: fec3683Security Options: apparmor seccomp Profile: defaultKernel Version: 4.4.0-145-genericOperating System: Ubuntu 16.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 4.031GiBName: admin-dsqID: 26JC:YRWW:2HL7:W5AA:6FGM:UZEZ:EXMR:IR6A:GA2Z:IJBS:S5OA:QYKADocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community Engine#文章开头出的警告以消失 默认安全连接&ensp;&ensp;为简化操作，不必每次都对-H tcp://$host，–tls等参数进行调用，可以按下面步骤更改 &ensp;&ensp;服务端：将安全验证添加到/lib/systemd/system/docker.service中 12345678910111213141516171819202122232425262728293031323334353637383940root@admin-dsq:~/.docker# ls # 此处为CA自签名证书、服务器证书、服务器密钥ca.pem cert.pem key.pemroot@admin-dsq:~/.docker# cat /lib/systemd/system/docker.service |grep ExecStartExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/root/.docker/ca.pem --tlscert=/root/.docker/cert.pem \--tlskey=/root/.docker/key.pem -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sockroot@admin-dsq:~/.docker# systemctl daemon-reload #重载守护进程root@admin-dsq:~/.docker# systemctl restart dockerroot@admin-dsq:~/.docker# systemctl status docker● docker.service - Docker Application Container Engine Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled) Active: active (running) since Wed 2019-04-04 09:03:25 CST; 5min ago Docs: https://docs.docker.com Main PID: 15180 (dockerd) Tasks: 10 Memory: 30.5M CPU: 779ms CGroup: /system.slice/docker.service └─15180 /usr/bin/dockerd --tlsverify --tlscacert=/root/.docker/ca.pem --tlscert=/root/.docker/cert.pem --tlskey=/root/.docker/key.pem ………………root@admin-dsq:~/local_p_key# docker info | grep Name Name: admin-dsqroot@admin-dsq:~/.docker# docker versionClient: Version: 18.09.5 API version: 1.39 Go version: go1.10.8 Git commit: e8ff056 Built: Thu Apr 11 04:44:24 2019 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 18.09.5 API version: 1.39 (minimum version 1.12) Go version: go1.10.8 Git commit: e8ff056 Built: Thu Apr 11 04:10:53 2019 OS/Arch: linux/amd64 Experimental: false &ensp;&ensp;客户端：如果要在默认情况下保护Docker客户端连接，可以将文件移动到.docker目录中，并设置 DOCKER_HOST和DOCKER_TLS_VERIFY变量 123456789101112131415161718192021222324[root@docker-study .docker]# ls #此处为CA自签名证书、客户端证书、客户端密钥ca.pem cert.pem key.pem# 添加环境变量，设置远程主机和开启TLS验证[root@docker-study .docker]# export DOCKER_HOST=tcp://172.18.74.62:2376 DOCKER_TLS_VERIFY=1[root@docker-study .docker]# docker version # 连接到了远程服务端Client: Version: 18.09.0 API version: 1.39 Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:48:22 2018 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 18.09.5 API version: 1.39 (minimum version 1.12) Go version: go1.10.8 Git commit: e8ff056 Built: Thu Apr 11 04:10:53 2019 OS/Arch: linux/amd64 Experimental: false &ensp;&ensp;Docker现在默认安全连接 过程中出现的错误 CA自签名证书默认路径为/root/.docker，服务器或客户端的CA证书和密钥也应该放在此目录下 12[root@docker-study ~]# docker --tlsverify -H 172.18.74.62 infocould not read CA certificate &quot;/root/.docker/ca.pem&quot;: open /root/.docker/ca.pem: no such file or directory info：x509: cannot validate certificate for 172.18.74.62 because it doesn’t contain any IP SANs 12[root@docker-study /]# docker --tlsverify -H 172.18.74.62 infoerror during connect: Get https://172.18.74.62:2376/v1.39/info: x509: cannot validate certificate for 172.18.74.62 because it doesn&apos;t contain any IP SANs &ensp;&ensp;在指定证书的过程中要指定IP地址，参照：https://stackoverflow.com/questions/42116783/x509-cannot-validate-certificate-because-it-doesnt-contain-any-ip-sans 或者可以按照Docker文档中所给出的步骤即上述中的过程。 在客户端连接Docker Daemon时未成功，在Docker Daemon端报出如下信息： 1234567客户端：[root@docker-study .docker]# docker --tlsverify --tlscacert=ca.pem --tlscert=server-cert.pem --tlskey=server-key.pem -H 172.18.74.62 infoThe server probably has client authentication (--tlsverify) enabled. Please check your TLS client certification settings: \Get https://172.18.74.62:2376/v1.39/info: remote error: tls: bad certificate服务端显示：2019-04-16 10:45:46.370039 I | http: TLS handshake error from 172.18.74.101:44292: tls: client didn&apos;t provide a certificate &ensp;&ensp;Docker Daemon 使用 dockerd –tlsverify –tlscacert=/root/CA/ca.pem –tlscert=server-cert.pem –tlskey=server-key.pem -H 0.0.0.0:2376 启动后仅接受来自提供CA信任的客户端的连接，所以客户端也需要进行CA认证，二者所使用的CA自签名证书是一样的。 &ensp;&ensp;当ca.pem不同时有如下报错： 12[root@docker-study .docker]# docker infoerror during connect: Get https://172.18.74.62:2376/v1.39/info: x509: certificate signed by unknown authority 报错为私钥和公钥不匹配 12[root@docker-study client]# docker --tlsverify --tlscacert=../ca.pem --tlscert=../server-cert.pem --tlskey=key.pem -H 172.18.74.62 infoCould not load X509 key pair: tls: private key does not match public key curl: (60) Peer’s Certificate issuer is not recognized. 1234567891011121314[root@docker-study ~]# curl https://172.18.74.62:2376/infocurl: (60) Peer&apos;s Certificate issuer is not recognized.More details here: http://curl.haxx.se/docs/sslcerts.htmlcurl performs SSL certificate verification by default, using a &quot;bundle&quot; of Certificate Authority (CA) public keys (CA certs). If the default bundle file isn&apos;t adequate, you can specify an alternate file using the --cacert option.If this HTTPS server uses a certificate signed by a CA represented in the bundle, the certificate verification probably failed due to a problem with the certificate (it might be expired, or the name might not match the domain name in the URL).If you&apos;d like to turn off curl&apos;s verification of the certificate, use the -k (or --insecure) option. &ensp;&ensp;报错为无法识别证书颁发者，因为是自己制作的证书，系统对CA没有认证，所以无法识别。&ensp;&ensp;解决办法是将签发该证书的私有CA公钥cacert.pem文件内容，追加到/etc/pki/tls/certs/ca-bundle.crt下。 1234#ubuntu下root@admin-dsq:~/.docker# cat ca.pem &gt;&gt; /etc/ssl/certs/ca-certificates.crt#centos下[root@docker-study .docker]# cat ca.pem &gt;&gt; /etc/pki/tls/certs/ca-bundle.crt curl: (58) NSS: client certificate not found (nickname not specified) 12[root@docker-study .docker]# curl https://172.18.74.62:2376/versioncurl: (58) NSS: client certificate not found (nickname not specified) 没有找到客户端认证，加–cert参数指定下路径就行了 NSS error -8178 (SEC_ERROR_BAD_KEY) 1234567891011121314[root@docker-study .docker]# curl --cert /root/.docker/cert.pem https://172.18.74.62:2376/versioncurl: (58) unable to load client key: -8178 (SEC_ERROR_BAD_KEY)[root@docker-study .docker]# curl -v --cert /root/.docker/cert.pem https://172.18.74.62:2376/version* About to connect() to 172.18.74.62 port 2376 (#0)* Trying 172.18.74.62...* Connected to 172.18.74.62 (172.18.74.62) port 2376 (#0)* Initializing NSS with certpath: sql:/etc/pki/nssdb* CAfile: /etc/pki/tls/certs/ca-bundle.crt CApath: none* unable to load client key: -8178 (SEC_ERROR_BAD_KEY)* NSS error -8178 (SEC_ERROR_BAD_KEY)* Peer&apos;s public key is invalid.* Closing connection 0curl: (58) unable to load client key: -8178 (SEC_ERROR_BAD_KEY) 参考：https://stackoverflow.com/questions/22499425/ssl-certificate-generated-with-openssl-not-working-on-nss?answertab=active#tab-top 我尝试了无密码和另外的des3 加密算法都没有成功，仍然是这个错误，待更新。]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker远程访问]]></title>
    <url>%2F2019%2F04%2F01%2FDocker%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[&ensp;&ensp;Docker目前采用了标准的C/S 架构，客户端和服务端既可以运行在一个机器上，也可以运行在不同的机器上并用过socket或者RESTful API来进行通信 12345678910111213141516171819root@admin-dsq:/var/lib/docker# docker versionClient: Version: 18.09.5 API version: 1.39 Go version: go1.10.8 Git commit: e8ff056 Built: Thu Apr 11 04:44:24 2019 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 18.09.5 API version: 1.39 (minimum version 1.12) Go version: go1.10.8 Git commit: e8ff056 Built: Thu Apr 11 04:10:53 2019 OS/Arch: linux/amd64 Experimental: false 1234567891011121314151617181920[root@docker-study ~]# docker version Client: Version: 18.09.0 API version: 1.39 Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:48:22 2018 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 18.09.0 API version: 1.39 (minimum version 1.12) Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:19:08 2018 OS/Arch: linux/amd64 Experimental: false[root@docker-study ~]# Server&ensp;&ensp;Docker Daemon 一般在宿主机后台运行，作为服务端接受来自客户的请求（bulid、pull、run……）。&ensp;&ensp;在设计上，Docker Daemon 是一个模块化的架构，通过专门的Engine模块来分发管理来自各个客户端的任务。&ensp;&ensp;Docker端默认监听本地的unix:///var/run/docker.sock，只允许本地的root 或者 位于Docker用户组的成员访问。 Client&ensp;&ensp;Docker客户端为用户提供一系列可执行命令，用户使用其与docker daemon 进行交互。&ensp;&ensp;同样客户端默认通过本地的unix:///var/run/docker.sock套接字向server发送命令，如果server没有在监听默认的地址，则需要客户端在执行命令的时候显式指定服务端地址 配置远程访问unix:///var/run/docker.sock方式（默认）&ensp;&ensp;可以直接通过docker daemon -H 0.0.0.0:2375来进行监听端口的修改，但是修改后本地无法访问 &ensp;&ensp;第一个问题，没有daemon命令 1234[root@docker-study ~]# docker daemon -H 0.0.0.0:2375docker: &apos;daemon&apos; is not a docker command.See &apos;docker --help&apos;[root@docker-study ~]# &ensp;&ensp;解决： 1234[root@docker-study ~]# man docker | grep daemon docker is a client for interacting with the daemon (see dockerd(8)) through the CLI. The socket(s) to bind to in daemon mode specified using one or more Use TLS and verify the remote (daemon: verify client, client: verify daemon). &ensp;&ensp;看到里面又指出dockerd，继续看帮助手册 123456789101112NAME dockerd - Enable daemon modeSYNOPSIS ………………………………DESCRIPTION dockerd is used for starting the Docker daemon (i.e., to command the daemon to manage images, containers etc). So dockerd is a server, as a daemon. To run the Docker daemon you can specify dockerd. You can check the daemon options using dockerd --help. Daemon options should be specified after the dockerd keyword in the following format. &ensp;&ensp;在描述中看到可以直接使用dockerd命令 &ensp;&ensp;又一个问题： 12[root@docker-study ~]# dockerd -H 0.0.0.0:2375Error starting daemon: pid file found, ensure docker is not running or delete /var/run/docker.pid &ensp;&ensp;linux系统中/var/run/目录下的*.pid文件是一个文本文件，其内容只有一行，即某个进程的PID。.pid文件的作用是防止进程启动多个副本，只有获得特定pid文件（固定路径和文件名）的写入权限（F_WRLCK）的进程才能正常启动并将自身的进程PID写入该文件，其它同一程序的多余进程则自动退出。 原文https://blog.csdn.net/qq_29344757/article/details/79875693 123456789101112131415161718192021222324[root@docker-study ~]# systemctl stop docker [root@docker-study ~]# dockerd -H 0.0.0.0:2375WARN[2019-04-01T15:37:42.169194593+08:00] [!] DON&apos;T BIND ON ANY IP ADDRESS WITHOUT setting --tlsverify IF YOU DON&apos;T KNOW WHAT YOU&apos;RE DOING [!] INFO[2019-04-01T15:37:42.243451549+08:00] parsed scheme: &quot;unix&quot; module=grpcINFO[2019-04-01T15:37:42.243544854+08:00] scheme &quot;unix&quot; not registered, fallback to default scheme module=grpcINFO[2019-04-01T15:37:42.243795794+08:00] parsed scheme: &quot;unix&quot; module=grpcINFO[2019-04-01T15:37:42.243845181+08:00] scheme &quot;unix&quot; not registered, fallback to default scheme module=grpcINFO[2019-04-01T15:37:42.243882171+08:00] ccResolverWrapper: sending new addresses to cc: [&#123;unix:///run/containerd/containerd.sock 0 &lt;nil&gt;&#125;] module=grpcINFO[2019-04-01T15:37:42.244259439+08:00] ClientConn switching balancer to &quot;pick_first&quot; module=grpcINFO[2019-04-01T15:37:42.244554066+08:00] ccResolverWrapper: sending new addresses to cc: [&#123;unix:///run/containerd/containerd.sock 0 &lt;nil&gt;&#125;] module=grpcINFO[2019-04-01T15:37:42.244639324+08:00] ClientConn switching balancer to &quot;pick_first&quot; module=grpcINFO[2019-04-01T15:37:42.244632164+08:00] pickfirstBalancer: HandleSubConnStateChange: 0xc42075c160, CONNECTING module=grpcINFO[2019-04-01T15:37:42.244733235+08:00] pickfirstBalancer: HandleSubConnStateChange: 0xc4208058f0, CONNECTING module=grpcINFO[2019-04-01T15:37:42.248230966+08:00] pickfirstBalancer: HandleSubConnStateChange: 0xc4208058f0, READY module=grpcINFO[2019-04-01T15:37:42.248916291+08:00] pickfirstBalancer: HandleSubConnStateChange: 0xc42075c160, READY module=grpcINFO[2019-04-01T15:37:42.328176882+08:00] [graphdriver] using prior storage driver: overlay2 INFO[2019-04-01T15:37:42.378297370+08:00] Graph migration to content-addressability took 0.00 seconds INFO[2019-04-01T15:37:42.381815767+08:00] Loading containers: start. INFO[2019-04-01T15:37:43.185355254+08:00] Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address INFO[2019-04-01T15:37:43.367934536+08:00] Loading containers: done. INFO[2019-04-01T15:37:43.461672778+08:00] Docker daemon commit=4d60db4 graphdriver(s)=overlay2 version=18.09.0INFO[2019-04-01T15:37:43.461917242+08:00] Daemon has completed initialization WARN[2019-04-01T15:37:43.476514418+08:00] Could not register builder git source: failed to find git binary: exec: &quot;git&quot;: executable file not found in $PATH INFO[2019-04-01T15:37:43.503134754+08:00] API listen on [::]:2375 &ensp;&ensp;此时另起一个终端 12345[root@docker-study ~]# netstat -antp | grep 2375 #查看端口tcp6 0 0 :::2375 :::* LISTEN 23099/dockerd [root@docker-study ~]# docker version # 访问本地Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?[root@docker-study ~]# &ensp;&ensp;回到上一个终端 123456INFO[2019-04-01T15:37:43.503014754+08:00] API listen on [::]:2375 ^CINFO[2019-04-01T16:14:40.215430655+08:00] Processing signal &apos;interrupt&apos; INFO[2019-04-01T16:14:40.224031663+08:00] stopping event stream following graceful shutdown error=&quot;&lt;nil&gt;&quot; module=libcontainerd namespace=moby[root@docker-study ~]# netstat -antp | grep 2375[root@docker-study ~]# &ensp;&ensp;这种方法只是起到运行时的配置，并没有对配置文件进行修改，Ctrl+c 后，处理信号中断，2375端口关闭 tcp://host:port方式&ensp;&ensp;admin-dsq为server，docker-study为client &ensp;&ensp;在Server端对docker.server作如下修改 12345678root@admin-dsq:/var/lib/docker# cat /lib/systemd/system/docker.service …………#ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sockExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock #监听本地及2375端口…………root@admin-dsq:/var/lib/docker#systemctl daemon-reloadroot@admin-dsq:/var/lib/docker#systemctl restart docker 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@docker-study ~]# docker -H 172.18.74.62 infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 18.09.5Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: bb71b10fd8f58240ca47fbb579b9d1028eea7c84runc version: 2b18fe1d885ee5083ef9f0838fee39b62d653e30init version: fec3683Security Options: apparmor seccomp Profile: defaultKernel Version: 4.4.0-145-genericOperating System: Ubuntu 16.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 4.031GiBName: admin-dsqID: 26JC:YRWW:2HL7:W5AA:6FGM:UZEZ:EXMR:IR6A:GA2Z:IJBS:S5OA:QYKADocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community EngineWARNING: API is accessible on http://0.0.0.0:2375 without encryption. Access to the remote API is equivalent to root access on the host. Refer to the &apos;Docker daemon attack surface&apos; section in the documentation for more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surfaceWARNING: No swap limit support &ensp;&ensp;现在使用命令docker info连接的就是服务端的docker了 &ensp;&ensp;关于第一个警告是此方法没有安全认证，任何对远程API的访问等同于对主机根目录的访问，在下一篇文章中在进行安全认证。 &ensp;关于第二个警告： 摘自http://www.talkwithtrend.com/Question/123541?order=asc &ensp;&ensp;根据错误提示，只是cgroups中的swap account没有开启。这个功能应该是用在 类似docker run -m=1524288 -it ubuntu /bin/bash 的命令，用来限制一个docker容器的内存使用上限，所以这里只是WARNING，不影响使用。 &ensp;&ensp;解决办法： 123456789101112When users run Docker, they may see these messages when working with an image:WARNING: Your kernel does not support cgroup swap limit. WARNING: Yourkernel does not support swap limit capabilities. Limitation discarded.To prevent these messages, enable memory and swap accounting on your system. To enable these on system using GNU GRUB (GNU GRand Unified Bootloader), do the following.Log into Ubuntu as a user with sudo privileges.Edit the /etc/default/grub file. # 编辑文件Set the GRUB_CMDLINE_LINUX value as follows:GRUB_CMDLINE_LINUX=&quot;cgroup_enable=memory swapaccount=1&quot; # 设置值Save and close the file. #保存退出Update GRUB.$ sudo update-grub #执行命令update-grubReboot your system. # 重启操作系统 RESTful API方式1[root@docker-study ~]# curl 172.18.74.62:2375/info 详情见: https://docs.docker.com/develop/sdk/ https://docs.docker.com/engine/api/ https://docs.docker.com/registry/spec/api/ https://docs.docker.com/reference/dtr/2.6/api/ https://docs.docker.com/reference/ucp/3.1/api/]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四种软件架构：单体架构、分布式架构、微服务架构、Serverless架构]]></title>
    <url>%2F2019%2F03%2F23%2F%E5%9B%9B%E7%A7%8D%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%EF%BC%9A%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E3%80%81%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E3%80%81Serverless%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[一、单体架构&ensp;&ensp;单体架构比较初级，典型的三级架构，前端(Web/手机端)+中间业务逻辑层+数据库层。这是一种典型的Java Spring mvc或者Python Django框架的应用。其架构图如下所示： &ensp;单体架构的应用比较容易部署、测试， 在项目的初期，单体应用可以很好地运行。然而，随着需求的不断增加， 越来越多的人加入开发团队，代码库也在飞速地膨胀。慢慢地，单体应用变得越来越臃肿，可维护性、灵活性逐渐降低，维护成本越来越高。下面是单体架构应用的一些缺点： 复杂性高： 以一个百万行级别的单体应用为例，整个项目包含的模块非常多、模块的边界模糊、 依赖关系不清晰、 代码质量参差不齐、 混乱地堆砌在一起。可想而知整个项目非常复杂。 每次修改代码都心惊胆战， 甚至添加一个简单的功能， 或者修改一个Bug都会带来隐含的缺陷。 技术债务： 随着时间推移、需求变更和人员更迭，会逐渐形成应用程序的技术债务， 并且越积 越多。“ 不坏不修”， 这在软件开发中非常常见， 在单体应用中这种思想更甚。 已使用的系统设计或代码难以被修改，因为应用程序中的其他模块可能会以意料之外的方式使用它。 部署频率低： 随着代码的增多，构建和部署的时间也会增加。而在单体应用中， 每次功能的变更或缺陷的修复都会导致需要重新部署整个应用。全量部署的方式耗时长、 影响范围大、 风险高， 这使得单体应用项目上线部署的频率较低。 而部署频率低又导致两次发布之间会有大量的功能变更和缺陷修复，出错率比较高。可靠性差： 某个应用Bug，例如死循环、内存溢出等， 可能会导致整个应用的崩溃。 扩展能力受限： 单体应用只能作为一个整体进行扩展，无法根据业务模块的需要进行伸缩。例如，应用中有的模块是计算密集型的，它需要强劲的CPU； 有的模块则是IO密集型的，需要更大的内存。 由于这些模块部署在一起，不得不在硬件的选择上做出妥协。 阻碍技术创新： 单体应用往往使用统一的技术平台或方案解决所有的问题， 团队中的每个成员 都必须使用相同的开发语言和框架，要想引入新框架或新技术平台会非常困难。 二、分布式应用&ensp;&ensp;中级架构，分布式应用，中间层分布式+数据库分布式，是单体架构的并发扩展，将一个大的系统划分为多个业务模块，业务模块分别部署在不同的服务器上，各个业务模块之间通过接口进行数据交互。数据库也大量采用分布式数据库，如redis、ES、solor等。通过LVS/Nginx代理应用，将用户请求均衡的负载到不同的服务器上。其架构图如下所示： &ensp;&ensp;该架构相对于单体架构来说，这种架构提供了负载均衡的能力，大大提高了系统负载能力，解决了网站高并发的需求。另外还有以下特点： 降低了耦合度：把模块拆分,使用接口通信,降低模块之间的耦合度。 责任清晰：把项目拆分成若干个子项目,不同的团队负责不同的子项目。 扩展方便：增加功能时只需要再增加一个子项目,调用其他系统的接口就可以。 部署方便:可以灵活的进行分布式部署。 提高代码的复用性：比如service层,如果不采用分布式rest服务方式架构就会在手机wap商城,微信商城,pc,android，ios每个端都要写一个service层逻辑,开发量大,难以维护一起升级,这时候就可以采用分布式rest服务方式,公用一个service层。 缺点 : 系统之间的交互要使用远程通信,接口开发增大工作量,但是利大于弊。 三、微服务架构微服务架构，主要是中间层分解，将系统拆分成很多小应用（微服务），微服务可以部署在不同的服务器上，也可以部署在相同的服务器不同的容器上。当应用的故障不会影响到其他应用，单应用的负载也不会影响到其他应用，其代表框架有Spring cloud、Dubbo等。 其架构图如下所示： 易于开发和维护： 一个微服务只会关注一个特定的业务功能，所以它业务清晰、代码量较少。 开发和维护单个微服务相对简单。而整个应用是由若干个微服务构建而成的，所以整个应用也会被维持在一个可控状态。 单个微服务启动较快： 单个微服务代码量较少， 所以启动会比较快。 局部修改容易部署： 单体应用只要有修改，就得重新部署整个应用，微服务解决了这样的问题。 一般来说，对某个微服务进行修改，只需要重新部署这个服务即可。 技术栈不受限：在微服务架构中，可以结合项目业务及团队的特点，合理地选择技术栈。例如某些服务可使用关系型数据库MySQL；某些微服务有图形计算的需求，可以使用Neo4j；甚至可根据需要，部分微服务使用Java开发，部分微服务使用Node.js开发。 &ensp;&ensp;微服务虽然有很多吸引人的地方，但它并不是免费的午餐，使用它是有代价的。使用微服务架构面临的挑战。 运维要求较高：更多的服务意味着更多的运维投入。在单体架构中，只需要保证一个应用的正常运行。而在微服务中，需要保证几十甚至几百个服务服务的正常运行与协作，这给运维带来了很大的挑战。 分布式固有的复杂性：使用微服务构建的是分布式系统。对于一个分布式系统，系统容错、网络延迟、分布式事务等都会带来巨大的挑战。 接口调整成本高：微服务之间通过接口进行通信。如果修改某一个微服务的API，可能所有使用了该接口的微服务都需要做调整。 重复劳动：很多服务可能都会使用到相同的功能，而这个功能并没有达到分解为一个微服务的程度，这个时候，可能各个服务都会开发这一功能，从而导致代码重复。尽管可以使用共享库来解决这个问题（例如可以将这个功能封装成公共组件，需要该功能的微服务引用该组件），但共享库在多语言环境下就不一定行得通了。 四、Serverless架构当我们还在容器的浪潮中前行时，已经有一些革命先驱悄然布局另外一个云计算战场：Serverless架构。 &ensp;&ensp;2014年11月14日，亚马逊AWS发布了新产品Lambda。当时Lambda被描述为：一种计算服务，根据时间运行用户的代码，无需关心底层的计算资源。从某种意义上来说，Lambda姗姗来迟，它像云计算的PaaS理念：客户只管业务，无需担心存储和计算资源。在此前不久，2014年10月22日，谷歌收购了实时后端数据库创业公司Firebase。Firebase声称开发者只需引用一个API库文件就可以使用标准REST API的各种接口对数据进行读写操作，只需编写HTML＋CSS＋JavaScrip前端代码，不需要服务器端代码（如需整合，也极其简单）。 &ensp;&ensp;相对于上两者，Facebook 在2014年二月收购的 Parse，则侧重于提供一个通用的后台服务。这些服务被称为Serverless或no sever。想到PaaS（平台即服务）了是吗？很像，用户不需要关心基础设施，只需要关心业务，这是迟到的PaaS，也是更实用的PaaS。这很有可能将会变革整个开发过程和传统的应用生命周期，一旦开发者们习惯了这种全自动的云上资源的创建和分配，或许就再也回不到那些需要微应用配置资源的时代里去了。 &ensp;&ensp;Serverless架构能够让开发者在构建应用的过程中无需关注计算资源的获取和运维，由平台来按需分配计算资源并保证应用执行的SLA（服务等级协议），按照调用次数进行计费，有效的节省应用成本。ServerLess的架构如上图所示。其优点如下所示： 低运营成本：在业务突发性极高的场景下，系统为了应对业务高峰，必须构建能够应对峰值需求的系统，这个系统在大部分时间是空闲的，这就导致了严重的资源浪费和成本上升。在微服务架构中，服务需要一直运行，实际上在高负载情况下每个服务都不止一个实例，这样才能完成高可用性；在Serverless架构下，服务将根据用户的调用次数进行计费，按照云计算pay-as-you-go原则，如果没有东西运行，你就不必付款，节省了使用成本。同时，用户能够通过共享网络、硬盘、CPU等计算资源，在业务高峰期通过弹性扩容方式有效的应对业务峰值，在业务波谷期将资源分享给其他用户，有效的节约了成本。 简化设备运维：在原有的IT体系中，开发团队即需要维护应用程序，同时还要维护硬件基础设施；Serverless架构中，开发人员面对的将是第三方开发或自定义的API 和URL，底层硬件对于开发人员透明化了，技术团队无需再关注运维工作，能够更加专注于应用系统开发。 提升可维护性：Serverless架构中，应用程序将调用多种第三方功能服务，组成最终的应用逻辑。目前，例如登陆鉴权服务，云数据库服务等第三方服务在安全性、可用性、性能方面都进行了大量优化，开发团队直接集成第三方的服务，能够有效的降低开发成本，同时使得应用的运维过程变得更加清晰，有效的提升了应用的可维护性。 更快的开发速度：这一点在现在互联网创业公司得到很好的体现，创业公司往往开始由于人员和资金等问题，不可能每个产品线都同时进行，这时候就可以考虑第三方的Baas平台，比如使用微信的用户认证、阿里云提供的RDS，极光的消息推送，第三方支付及地理位置等等，能够很快进行产品开发的速度，把工作重点放在业务实现上，把产品更快的推向市场。但ServerLess架构也有其缺点： 厂商平台绑定：平台会提供Serverless架构给大玩家，比如AWS Lambda，运行它需要使用AWS指定的服务，比如API网关，DynamoDB，S3等等，一旦你在这些服务上开发一个复杂系统，你会粘牢AWS，以后只好任由他们涨价定价或者下架等操作，个性化需求很难满足，不能进行随意的迁移或者迁移的成本比较大，同时不可避免带来一些损失。Baas行业内一个比较典型的事件，2016年1月19日Facebook关闭曾经花巨额资金收购的Parse，造成用户不得不迁移在这个平台中产生一年多的数据，无疑需要花费比较大的人力和时间成本。 成功案例比较少，没有行业标准：目前的情况也只适合简单的应用开发，缺乏大型成功案例的推动。对于Serverless缺乏统一的认知以及相应的标准，无法适应所有的云平台。 &ensp;&ensp;目前微服务架构在四种架构中处于主流地位，很多应用第一、第二种架构的企业也开始慢慢转向微服务架构。到目前为止微服务的技术相对于二三年前已经比较成熟，第四种架构将是未来发展的一种趋势。 原文链接：https://www.jianshu.com/p/e7b992a82dc0]]></content>
      <tags>
        <tag>架构</tag>
        <tag>收藏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式架构系列-负载均衡]]></title>
    <url>%2F2019%2F03%2F22%2F%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E7%B3%BB%E5%88%97-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[&ensp;&ensp;面对大量用户访问、高并发请求，海量数据，可以使用高性能的服务器、大型数据库，存储设备，高性能Web服务器，采用高效率的编程语言比如(Go，Scala)等，当单机容量达到极限时，我们需要考虑业务拆分和分布式部署，来解决大型网站访问量大，并发量高，海量数据的问题。 &ensp;&ensp;从单机网站到分布式网站，很重要的区别是业务拆分和分布式部署，将应用拆分后，部署到不同的机器上，实现大规模分布式系统。分布式和业务拆分解决了，从集中到分布的问题，但是每个部署的独立业务还存在单点的问题和访问统一入口问题，为解决单点故障，我们可以采取冗余的方式。将相同的应用部署到多台机器上。解决访问统一入口问题，我们可以在集群前面增加负载均衡设备，实现流量分发。 &ensp;&ensp;负载均衡（Load Balance），意思是将负载（工作任务，访问请求）进行平衡、分摊到多个操作单元（服务器，组件）上进行执行。是解决高性能，单点故障（高可用），扩展性（水平伸缩）的终极解决方案。本文是负载均衡详解的第一篇文章，介绍负载均衡的原理，负载均衡分类（DNS负载均衡,HTTP负载均衡，IP负载均衡，链路层负载均衡,混合型P负载均衡）。部分内容摘自读书笔记。 一、负载均衡原理&ensp;&ensp;系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。纵向扩展，是从单机的角度通过增加硬件处理能力，比如CPU处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。这就是典型的集群和负载均衡架构：如下图： &ensp;&ensp;应用集群：将同一应用部署到多台机器上，组成处理集群，接收负载均衡设备分发的请求，进行处理，并返回相应数据。 &ensp;&ensp;负载均衡设备：将用户访问的请求，根据负载均衡算法，分发到集群中的一台处理服务器。（一种把网络请求分散到一个服务器集群中的可用服务器上去的设备） 负载均衡的作用（解决的问题）： 解决并发压力，提高应用处理性能（增加吞吐量，加强网络处理能力）； 提供故障转移，实现高可用； 通过添加或减少服务器数量，提供网站伸缩性（扩展性）； 安全防护；（负载均衡设备上做一些过滤，黑白名单等处理） 二、负载均衡分类&ensp;&ensp;根据实现技术不同，可分为DNS负载均衡，HTTP负载均衡，IP负载均衡，链路层负载均衡等。 2.1 DNS负载均衡最早的负载均衡技术，利用域名解析实现负载均衡，在DNS服务器，配置多个A记录，这些A记录对应的服务器构成集群。大型网站总是部分使用DNS解析，作为第一级负载均衡。如下图： 优点 &ensp;&ensp;1. 使用简单：负载均衡工作，交给DNS服务器处理，省掉了负载均衡服务器维护的麻烦 &ensp;&ensp;2.提高性能：可以支持基于地址的域名解析，解析成距离用户最近的服务器地址，可以加快访问速度，改善性能； 缺点 &ensp;&ensp;1.可用性差：DNS解析是多级解析，新增/修改DNS后，解析时间较长；解析过程中，用户访问网站将失败； &ensp;&ensp;2.扩展性低：DNS负载均衡的控制权在域名商那里，无法对其做更多的改善和扩展； &ensp;&ensp;3.维护性差：也不能反映服务器的当前运行状态；支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载） 实践建议 &ensp;&ensp;将DNS作为第一级负载均衡，A记录对应着内部负载均衡的IP地址，通过内部负载均衡将请求分发到真实的Web服务器上。一般用于互联网公司，复杂的业务系统不合适使用。如下图： 2.2 IP负载均衡&ensp;&ensp;在网络层通过修改请求目标地址进行负载均衡。 &ensp;&ensp;用户请求数据包，到达负载均衡服务器后，负载均衡服务器在操作系统内核进程获取网络数据包，根据负载均衡算法得到一台真实服务器地址，然后将请求目的地址修改为，获得的真实ip地址，不需要经过用户进程处理。 &ensp;&ensp;真实服务器处理完成后，响应数据包回到负载均衡服务器，负载均衡服务器，再将数据包源地址修改为自身的ip地址，发送给用户浏览器。如下图： &ensp;&ensp;IP负载均衡，真实物理服务器返回给负载均衡服务器，存在两种方式：（1）负载均衡服务器在修改目的ip地址的同时修改源地址。将数据包源地址设为自身盘，即源地址转换（snat）。（2）将负载均衡服务器同时作为真实物理服务器集群的网关服务器。 优点： &ensp;&ensp;在内核进程完成数据分发，比在应用层分发性能更好； 缺点： &ensp;&ensp;所有请求响应都需要经过负载均衡服务器，集群最大吞吐量受限于负载均衡服务器网卡带宽； 2.3 链路层负载均衡&ensp;&ensp;在通信协议的数据链路层修改mac地址，进行负载均衡。 &ensp;&ensp;数据分发时，不修改ip地址，指修改目标mac地址，配置真实物理服务器集群所有机器虚拟ip和负载均衡服务器ip地址一致，达到不修改数据包的源地址和目标地址，进行数据分发的目的。 &ensp;&ensp;实际处理服务器ip和数据请求目的ip一致，不需要经过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。也称为直接路由模式（DR模式）。如下图： 优点：性能好； 缺点：配置复杂； 实践建议：DR模式是目前使用最广泛的一种负载均衡方式。 2.4 混合型负载均衡 &ensp;&ensp;由于多个服务器群内硬件设备、各自的规模、提供的服务等的差异，可以考虑给每个服务器群采用最合适的负载均衡方式，然后又在这多个服务器群间再一次负载均衡或群集起来以一个整体向外界提供服务（即把这多个服务器群当做一个新的服务器群），从而达到最佳的性能。将这种方式称之为混合型负载均衡。 &ensp;&ensp;此种方式有时也用于单台均衡设备的性能不能满足大量连接请求的情况下。是目前大型互联网公司，普遍使用的方式。 方式一，如下图： &ensp;&ensp;以上模式适合有动静分离的场景，反向代理服务器（集群）可以起到缓存和动态请求分发的作用，当时静态资源缓存在代理服务器时，则直接返回到浏览器。如果动态页面则请求后面的应用负载均衡（应用集群）。 方式二，如下图： &ensp;&ensp;以上模式，适合动态请求场景。 &ensp;&ensp;因混合模式，可以根据具体场景，灵活搭配各种方式，以上两种方式仅供参考。 三、负载均衡算法常用的负载均衡算法有，轮询，随机，最少链接，源地址散列，加权等方式； 3.1 轮询将所有请求，依次分发到每台服务器上，适合服务器硬件同相同的场景。 优点：服务器请求数目相同； 缺点：服务器压力不一样，不适合服务器配置不同的情况； 3.2 随机请求随机分配到各个服务器。 优点：使用简单； 缺点：不适合机器配置不同的场景； 3.3 最少链接将请求分配到连接数最少的服务器（目前处理请求最少的服务器）。 优点：根据服务器当前的请求处理情况，动态分配； 缺点：算法实现相对复杂，需要监控服务器请求连接数； 3.4 Hash（源地址散列）根据IP地址进行Hash计算，得到IP地址。 优点：将来自同一IP地址的请求，同一会话期内，转发到相同的服务器；实现会话粘滞。 缺点：目标服务器宕机后，会话会丢失； 3.5 加权在轮询，随机，最少链接，Hash’等算法的基础上，通过加权的方式，进行负载服务器分配。 优点：根据权重，调节转发服务器的请求数目； 缺点：使用相对复杂； 四、硬件负载均衡采用硬件的方式实现负载均衡，一般是单独的负载均衡服务器，价格昂贵，一般土豪级公司可以考虑，业界领先的有两款，F5和A10。使用硬件负载均衡，主要考虑一下几个方面： 功能考虑：功能全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡； 性能考虑：一般软件负载均衡支持到5万级并发已经很困难了，硬件负载均衡可以支持 稳定性：商用硬件负载均衡，经过了良好的严格的测试，从经过大规模使用，在稳定性方面高； 安全防护：硬件均衡设备除具备负载均衡功能外，还具备防火墙，防DDOS攻击等安全功能； 维护角度：提供良好的维护管理界面，售后服务和技术支持； 土豪公司：F5 Big Ip 价格：15w~55w不等；A10 价格：55w-100w不等； 缺点 价格昂贵； 扩展能力差； 小结 一般硬件的负载均衡也要做双机高可用，因此成本会比较高。 互联网公司一般使用开源软件，因此大部分应用采用软件负载均衡；部分采用硬件负载均衡。 &ensp;&ensp;比如某互联网公司，目前是使用几台F5做全局负载均衡，内部使用Nginx等软件负载均衡。 摘自： https://mp.weixin.qq.com/s/WG0oj-g8VuVfdIffgJhYWA 原作者：http://www.cnblogs.com/itfly8/p/5043435.html]]></content>
      <tags>
        <tag>架构</tag>
        <tag>收藏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[省科协高可用负载均衡集群]]></title>
    <url>%2F2019%2F03%2F20%2F%E7%9C%81%E7%A7%91%E5%8D%8F%E9%AB%98%E5%8F%AF%E7%94%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[整个集群的架构如下图，服务器是exsi虚拟化。 一、Firewall&nbsp;&nbsp;&nbsp;&nbsp;在集群的配置过程中，我们的Firewall和SElinux是一直处于关闭的，感觉还是先配置上比较方便，说来惭愧 SElinux我不会（setenforce 0），在这里我就只打开Firewall了。 第一层Nginx监听的是80端口（也可以自定义），再将请求反向代理到web服务器的80端口（也可以自定义） ，所以他们都需要在Firewall上允许80端口的流量通过，即： 123firewall-cmd --zone=public --add-port=80/tcpfirewall-cmd --zone=public --add-interface=ens160firewall-cmd --reload nginx高可用实现依靠的keepalived是以VRRP为基础，keepalived官方文档给出的组播地址是224.0.0.18，所以第一层和第三层的nginx的服务器上都需要在防火墙上允许vrrp组播的通过，即： 12firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 \ --in-interface ens160 --destination 224.0.0.18 --protocol vrrp -j ACCEPT MySQL集群必然要开启3306端口，第三层的Nginx也是在监听3306端口，即： 12firewall-cmd --zone=public --add-port=3306/tcpfirewall-cmd --zone=public --add-interface=ens160 建议先看第五步网络存储挂载。 二、nginx高可用集群nginx version: nginx/1.14.0，keepalived-2.0.7 编译安装nginxwget http://www.zlib.net/zlib-1.2.11.tar.gzwget https://jaist.dl.sourceforge.net/project/pcre/pcre/8.41/pcre-8.41.tar.gzwget https://www.openssl.org/source/openssl-1.0.2o.tar.gzwget http://labs.frickle.com/files/ngx_cache_purge-2.3.tar.gzwget http://nginx.org/download/nginx-1.14.0.tar.gz tar xvf …… 解压缩 1234567891011cd nginx-1.14.0.tar.gz./configure --add-module=../ngx_cache_purge-2.3--prefix=/usr/local/nginx --with-http_ssl_module--with-stream --with-pcre=../pcre-8.41--with-zlib=../zlib-1.2.11--with-openssl=../openssl-1.0.2o make&amp;&amp;make install ln -s /usr/local/nginx/sbin/nginx /usr/local/bin/ systemctl enable nginx 配置nginx.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream backend &#123; server 192.168.255.50 weight=100; server 192.168.255.53 weight=80; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; proxy_pass http://backend; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;nginx负载均衡功能实现依靠upstream模块，upstream模块应放于nginx.conf配置的http{}标签内，支持五种分配方式，轮询（默认）、weight、ip_hash三种原生方式，以及fair、url_hash两种第三方支持的方式。我用的是weight方式。 123456proxy_pass http://backend；指向upstream backend &#123; server 192.168.255.50 weight=100; server 192.168.255.53 weight=80; &#125; &nbsp;&nbsp;&nbsp;&nbsp;访问的是nginx服务器的地址即起到了反向代理的作用，代理web&nbsp;&nbsp;&nbsp;&nbsp;接下来安装keepalive实现nginx集群的高可用。 编译安装keepalived1234cd keepalived-2.0.7./configure --prefix=/data/keepalived make make install &nbsp;&nbsp;&nbsp;&nbsp;生成Makefile时有如下报错，需要另外安装libnl/libnl-3以支持IPv6，此处确实用不到，VRRP功能开启即可 配置keepalived123456789101112131415161718192021222324252627282930313233343536373839! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id keepalived01 vrrp_skip_check_adv_addr #vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 vrrp_mcast_group4 224.0.0.18 #vrrp组播，默认为224.0.0.18&#125;vrrp_script chk_nginx &#123; script &quot;/etc/keepalived/nginx_check.sh&quot; # 检查nginx状态的脚本 interval 2 weight 3 &#125; vrrp_instance VI_1 &#123; state MASTER #MASTER为主，BACKUP为从 interface ens160 #网卡，根据自己实际 virtual_router_id 51 #主从一致，用来区分多个instance的VRRP组播 priority 100 #优先级，BACKUP上为99 advert_int 1 #健康查检时间间隔 authentication &#123; #authentication 认证区域 auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 172.18.74.100 #设置vip &#125; track_script &#123; chk_nginx &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;keepalived是集群管理中保证集群高可用的一个服务软件，其功能类似于heartbeat，用来防止单点故障。以VRRP协议为实现基础，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip（该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。 1234567891011nginx_check.sh如下：#!/bin/bashA=ps -C nginx --no-header |wc -lif [ $A -eq 0 ];then /usr/local/nginx/sbin sleep 3 if [ ps -C nginx --no-header |wc -l -eq 0 ];then systemctl stop keepalived fifi 配置完成后Ngx-Master： Ngx-Backup： 宕掉Master的网卡，vip直接转移到了Backup上 重启网卡后，vip回归到Master 三、web 集群&nbsp;&nbsp;&nbsp;&nbsp;这一部分其实很简单，在安装操作系统的时候我选的”Basic web server”,为了能验证web能提交数据到MySQL，写了一个PHP页面。在连接数据库的时候，数据库地址是vip：192.168.255.200 123456789101112131415161718192021index.php&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;charset=UTF-8&quot; /&gt; &lt;title&gt;产品添加-JD产品管理系统&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;JD产品管理&lt;/h3&gt; &lt;form action=&quot;deal.php&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; 图书名称：&lt;input type=&apos;text&apos; name=&apos;title&apos; /&gt; &lt;hr /&gt; 销售价格：&lt;input type=&quot;text&quot; name=&apos;price&apos; /&gt; &lt;hr /&gt; 市场价格：&lt;input type=&quot;text&quot; name=&apos;market_price&apos; /&gt; &lt;hr /&gt; &lt;input type=&quot;submit&quot; name=&quot;submit&quot; value=&quot;添加&quot; /&gt; &lt;input type=&quot;reset&quot; name=&quot;reset&quot; value=&quot;重置&quot; /&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 12345678910111213141516171819202122deal.php&lt;?php //1、设置响应头信息 header(&apos;Content-type:text/html; charset=utf-8&apos;); //2、submit安全判断 if(isset($_POST[&apos;submit&apos;])) &#123; //3、接收数据 $title = $_POST[&apos;title&apos;]; $price = $_POST[&apos;price&apos;]; $market_price = $_POST[&apos;market_price&apos;]; include &apos;coon.php&apos;; //9、定义SQL语句 $sql = &quot;insert into tb_goods values (null,&apos;$title&apos;,&apos;$price&apos;,&apos;$market_price&apos;,&apos;$thumb&apos;)&quot;; //10、执行SQL语句 $result = mysql_query($sql); if($result) &#123; echo &apos;添加成功&apos;; &#125; else &#123; echo &apos;添加失败&apos;; &#125; &#125;?&gt; 123456789coon.php&lt;?php //1、连接数据库,内容根据实际 mysql_connect(&apos;192.168.255.200&apos;,&apos;web&apos;,&apos;123456&apos;); //2、选择数据库 mysql_select_db(&apos;db_jd&apos;); //3、指定数据库的编码格式 mysql_query(&apos;set names utf8&apos;);?&gt; 下面的代码用来测试从数据库读取内容 1234567891011121314151617181920212223&lt;?php// mysql_connect(&quot;数据库地址&quot;,&quot;数据库账号&quot;,&quot;数据库密码&quot;,&quot;连接数据库&quot;);$con = mysql_connect(&quot;192.168.255.200&quot;,&quot;web&quot;,&quot;123456&quot;,&quot;db_jd&quot;);//测试是否连接数据库if($con)&#123; echo &quot;连接成功&quot;;&#125;else&#123; echo &quot;连接失败 &quot;;&#125;mysql_select_db(&quot;db_jd&quot;,$con);$result1=mysql_query(&quot;SELECT * from tb_goods&quot;);echo &quot;&lt;table&gt;&lt;tr&gt;&lt;td&gt;id&lt;/td&gt;&lt;td&gt;title&lt;/td&gt;&lt;td&gt;price&lt;/td&gt;&lt;td&gt;market_price&lt;/td&gt;&lt;td&gt;thumb&lt;/td&gt;&lt;/tr&gt;&quot;;while($row=mysql_fetch_array($result1))&#123;echo &quot;&lt;tr&gt;&quot;;echo &quot;&lt;td&gt;&quot;.$row[&apos;id&apos;].&quot;&lt;/td&gt;&quot;;echo &quot;&lt;td&gt;&quot;.$row[&apos;title&apos;].&quot;&lt;/td&gt;&quot;;echo &quot;&lt;td&gt;&quot;.$row[&apos;price&apos;].&quot;&lt;/td&gt;&quot;;echo &quot;&lt;td&gt;&quot;.$row[&apos;market_price&apos;].&quot;&lt;/td&gt;&quot;;echo &quot;&lt;td&gt;&quot;.$row[&apos;thumb&apos;].&quot;&lt;/td&gt;&quot;;echo &quot;&lt;/tr&gt;&quot;;&#125;mysql_close($con);?&gt; 如果两个web服务器中的页面不同，在提交表单的时候回显示无法找到。 最终效果为： 四、nginx高可用集群nginx version: nginx/1.14.0，keepalived-2.0.7 &nbsp;&nbsp;&nbsp;&nbsp;与第一层原理相同，只不过反向代理的数据库，监听端口是3306&nbsp;&nbsp;&nbsp;&nbsp;这里也会有一个Vip：192.168.255.200 配置Nginx12345678910111213141516171819202122232425262728293031nginx.conf#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;stream &#123; upstream mysql &#123; server 192.168.255.52:3306 weight=5 max_fails=3 fail_timeout=30s; server 192.168.255.57:3306 weight=5 max_fails=3 fail_timeout=30s; &#125; server &#123; listen 3306; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass mysql; &#125; &#125; 配置keepalived1234567891011121314151617181920212223242526272829303132333435363738394041keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id nginx_mysql_s vrrp_skip_check_adv_addr #vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 vrrp_mcast_group4 224.0.0.18&#125;vrrp_script chk_nginx &#123; script &quot;/etc/keepalived/nginx_check.sh&quot; # 检查nginx状态的脚本 interval 2 weight 3 &#125; vrrp_instance VI_1 &#123; state BACKUP interface ens160 virtual_router_id 66 priority 100 # Backup是90 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.255.200 &#125; track_script &#123; chk_nginx.sh &#125;&#125; vip转移不再演示。 五、mysql双机热备集群Server version: 5.6.43-log MySQL Community Server 源码安装mysql，不再展开。 mysql1：my.cnf1234567891011121314151617181920212223242526272829303132333435363738# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.6/en/server-configuration-defaults.html[mysqld]## Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M## Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin## Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2Mdatadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockserver-id=1log-bin=mysql-binbinlog_format=mixedrelay-log=relay-binrelay-log-index=slave-relay-bin.index auto-increment-increment=2auto-increment-offset=1log-slave-updates# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Recommended in standard MySQL setupsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES [mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid mysql2:my.cnf1234567891011121314151617181920212223242526272829303132333435363738# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.6/en/server-configuration-defaults.html[mysqld]## Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M## Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin## Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2Mdatadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockserver-id=2log-bin=mysql-binbinlog_format=mixedrelay-log=relay-binrelay-log-index=slave-relay-bin.indexauto-increment-increment=2auto-increment-offset=2log-slave-updates# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Recommended in standard MySQL setupsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES [mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid &nbsp;&nbsp;&nbsp;&nbsp;web想要上传数据到数据库，首先需要使用web登录至数据库，然后MySQL中应当有已经创建好的数据库，库中要有表，用户权限等等。MySQL集群我们做的是双主，数据是同步的。 &nbsp;&nbsp;&nbsp;&nbsp;先配置双主吧，然后只用建一遍库就可以了。双主模型其实就是互为主从，主从同步复制原理分成三步：master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events ），slave将master的binary log events拷贝到它的中继日志(relay log)，slave重做中继日志中的事件，将改变反映它自己的数据。 首先在两台mysql上创建用户张三 ，允许对方远程连接 12grant all privileges on *.* to zhangsan@192.168.255.52(192.168.255.57) identified by &apos;123456&apos;;Query OK, 0 rows affected (0.12 sec) 先以MySQL1为主MySQL1上（192.168.255.52 主）： 1234567mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000008 | 1480 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.03 sec) MySQL2上（192.168.255.57 从）： 1234mysql&gt; change master to master_host=&apos;192.168.255.52&apos;,master_port=3306,master_user=&apos;zhangsan&apos;,master_password=&apos;123456&apos;,m aster_log_file=&apos;mysql-bin.000008&apos;,master_log_pos=120;Query OK, 0 rows affected, 2 warnings (0.30 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.03 sec) 再以MySQL2为主MySQL2上（192.168.255.57 主）: 1234567mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000006 | 1480 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.04 sec) MySQL1上（192.168.255.52从）; 1234mysql&gt; change master to master_host=&apos;192.168.255.57&apos;,master_port=3306,master_user=&apos;zhangsan&apos;,master_password=&apos;123456&apos;,m aster_log_file=&apos;mysql-bin.000006&apos;,master_log_pos=120;Query OK, 0 rows affected, 2 warnings (0.41 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.05 sec) &nbsp;&nbsp;&nbsp;&nbsp;查看状态， Slave_IO_State 为等待主机事件；MySQL1主机显示192.168.255.57(即MySQL2)为主，在MySQL2上查看则相反；Slave_IO_Running: Yes；Slave_SQL_Running: Yes 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061Mysql 1 ：mysql&gt; show slave status\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.255.57 Master_User: zhangsan Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000006 Read_Master_Log_Pos: 1480 Relay_Log_File: relay-bin.000003 Relay_Log_Pos: 856 Relay_Master_Log_File: mysql-bin.000006 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 1480 Relay_Log_Space: 1023 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 2 Master_UUID: fb80dcb2-409a-11e9-8823-000c29a992e7 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 01 row in set (0.00 sec)ERROR: No query specified 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061MySQL 2：mysql&gt; show slave status\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.255.52 Master_User: zhangsan Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000008 Read_Master_Log_Pos: 1480 Relay_Log_File: relay-bin.000003 Relay_Log_Pos: 1070 Relay_Master_Log_File: mysql-bin.000008 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 1480 Relay_Log_Space: 1237 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: e6c1eb80-40db-11e9-89cb-00505687a987 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 01 row in set (0.03 sec)ERROR: No query specified 创建数据库&nbsp;&nbsp;&nbsp;&nbsp;创建db-jd数据库，在库中创建tb_goods表，表中字段与PHP网页相对应，在mysql1中创建，mysql2中同步 1234567891011121314mysql&gt; create database db_jd;Query OK, 1 row affected (0.00 sec)mysql&gt; use db_jd;Database changedmysql&gt; create table tb_goods (id int(11) null, tltle VarChar(40), price Decimal(10), market_price Decimal(10));Query OK, 0 rows affected (0.13 sec)mysql&gt; show tables;+-----------------+| Tables_in_db_jd |+-----------------+| tb_goods |+-----------------+1 row in set (0.00 sec) 授权允许web登陆在两台MySQL服务器上创建web用户，允许远程登陆，并赋予db_jd数据库的权限12345678mysql&gt; create user web@192.168.255.50 identified by &apos;123456&apos;;Query OK, 0 rows affected (0.37 sec)mysql&gt; grant all privileges on db_jd.* to web@192.168.255.50;Query OK, 0 rows affected (0.12 sec)mysql&gt; create user web@192.168.255.53 identified by &apos;123456&apos;;Query OK, 0 rows affected (0.37 sec)mysql&gt; grant all privileges on db_jd.* to web@192.168.255.53;Query OK, 0 rows affected (0.12 sec) 关于为什么不直接将权限赋给VIP，以及给Nginx服务器赋权，我认为归根到底还是web服务器的Apache与MySQL服务器MySQL -server之间通过套接字进行进程间通信，无论是vip还是Nginx只不过是中间的一座连接桥而已，实质上还是Apache与MySQL-Server通信。 在web插入数据进行测试，如下是在web1界面添加数据 mysql1中可以看到插入的数据test mysql2中同样有 六、网络链接NAS存储&nbsp;&nbsp;&nbsp;&nbsp;输入ip访问NAS服务器的web页面，然后将nas中已经存在的文件夹挂载到mysql服务器的数据目录下即可。&nbsp;&nbsp;&nbsp;&nbsp;使用mount挂载后，格式化了mysql数据目录下的文件，很郁闷，建议先挂载后再去安装mysql。 &nbsp;&nbsp;&nbsp;&nbsp;在NAS上开启NFS协议（NetworkFileSystem）。自带数据备份操作很简单。 12mount -t nfs -o nolock 172.18.74.39:/home/admin /var/lib/mysql #nolock -- 禁用文件锁 -t 指定文件系统类型]]></content>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟化与云计算]]></title>
    <url>%2F2019%2F03%2F03%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%2F</url>
    <content type="text"><![CDATA[虚拟化&ensp;&ensp;虚拟化指对计算资源进行抽象的一个广义概念。虚拟化对上层应用或用户隐藏了计算资源的底层属性。它既包括使单个的资源（比如一个服务器，一个操作系统，一个应用程序，一个存储设备）划分成多个虚拟资源，也包括将多个资源（比如存储设备或服务器）整合成一个虚拟资源。 &ensp;&ensp;虚拟化技术是指实现虚拟化的具体的技术性手段和方法的集合性概念。虚拟化技术根据对象可以分成存储虚拟化、计算虚拟化、网络虚拟化等。计算虚拟化可以分为操作系统级虚拟化，应用程序级，和虚拟机管理器。虚拟机管理器分为宿主虚拟机和客户虚拟机。 虚拟化技术原理&ensp;&ensp;在操作系统中加入一个虚拟化层，一种位于物理机和操作系统之间的软件，允许多个操作系统共享一套基础硬件，也叫虚拟机监视器（Virtual Machine Monitor，即VMM）。该虚拟化层可以对主机的物理硬件资源（包括物理CPU、内存、磁盘、网卡、显卡等）进行封装和隔离，将其抽象为另一种形式的逻辑资源，然后提供给虚拟机使用。本质上，虚拟化层是联系主机和虚拟机的一个中间件。 &ensp;&ensp;虚拟机一般称为GuestOS（客户机），作为GuestOS载体的物理主机称为HostOS（宿主机）。 虚拟化技术的特点 同质：虚拟机的本质与物理机的本质相同。例如，二者CPU的ISA（指令集架构 Instruction Set Architecture）是相同的。 高效：虚拟机的性能与物理机接近，在虚拟机上执行的大多数指令有直接在硬件上执行的权限和能力，只有少数的敏感指令会由VMM来处理。 资源可控：VMM对物理机和虚拟机的资源都是绝对可控的。 移植方便：如果物理主机发生故障或者因为其他原因需要停机，虚拟机可以迅速移植到其他物理主机上，从而确保生产或者服务不会停止；物理主机故障修复后，还可以迅速移植回去，从而充分利用硬件资源。 虚拟化的实现层次&ensp;&ensp;一般而言，CPU都可以分为用户态和内核态两种基本状态，而X86 CPU更是可以细分为Ring3~0四种状态（如图）。 图片摘自http://www.cnblogs.com/pannengzhi/p/5790350.html Ring1和Ring2是驱动层，不涉及应用程序，与虚拟化的实现关系不大。 Ring3用户态（User Mode）：所有用户程序都运行在用户态，运行的代码受CPU的检查。程序调用硬件设备时，CPU通过专用接口调用核心态代码，然后对硬件设备进行操作。如果应用程序直接调用硬件设备，宿主机操作系统捕捉并触发异常报告。 Ring0核心态（Kernel Mode）：宿主机操作系统内核运行的模式，运行在核心态的代码可以无限制地对系统内存、设备驱动程序、网卡接口、显卡接口等外围设备进行访问。 虚拟化实现方式全虚拟化（Full virtualization）：&ensp;&ensp;GuestOS可直接在VMM上运行而不需要对其本身做任何修改。全虚拟化的GuestOS具有完全的物理机特性。 &ensp;&ensp;典型的全虚拟化软件有VMWare、Hyper-V、KVM-X86（复杂指令集）等。 半虚拟化（Paravirtualization）:&ensp;&ensp;半虚拟化需要GuestOS协助的虚拟化技术，因为在半虚拟化VMM中运行的GuestOS内核都经过了特别的修改，修改的主要是GuestOS内核指令集中包括敏感指令在内的内核态指令，从而高效地避免执行错误。 &ensp;&ensp;典型的半虚拟化软件如Xen、KVM-PowerPC（简易指令集）等。 &ensp;&ensp;除修改GuestOS内核以外，半虚拟化还有另一种实现方式，即在每一个GuestOS中安装特定的半虚拟化软件，如VMTools、RHEVTools等。 硬件辅助虚拟化（HVM） &ensp;&ensp;Intel提出并开发了由CPU直接支持的虚拟化技术，该技术引入了新的CPU运行模式和新的指令集，使VMM和GuestOS运行在不同的模式之下（VMM运行在Ring0之下的根模式；GuestOS运行在Ring0的非根模式），GuestOS运行于受控模式，其内核指令集中的敏感指令会全部陷入VMM，由VMM进行模拟。 &ensp;&ensp;CPU硬件辅助虚拟化技术解决了部分非内核态敏感指令的陷入模拟难题，模式切换时上下文的保存恢复工作也由硬件来完成，这样就大大提高了陷入模拟时上下文切换的效率。 目前，硬件辅助虚拟化技术的主要分类如下： Intel VT-x：Intel的CPU硬件辅助虚拟化技术，包括IntelVTFlexPriority（Intel灵活任务优先级）、IntelVTFlexMigration（Intel虚拟化灵活迁移技术）和ExtendedPageTables（IntelVT扩展页表）三大功能。 AMD-V：AMD的CPU硬件辅助虚拟化技术，是针对X86处理器系统架构开发的一组硬件扩展和硬件辅助虚拟化技术。 内存虚拟化&ensp;&ensp;内存虚拟化的映射（内存地址转换）涉及三类地址： 虚拟地址（VA）：GuestOS提供给其应用程序使用的线性地址空间。 物理地址（PA）：经VMM抽象的，虚拟机看到的伪物理地址。 机器地址（MA）：真实的机器物理地址，即地址总线上出现的地址信号。 &ensp;&ensp;宿主机到虚拟机的内存地址映射关系如下： GuestOS：GuestOS负责VA到PA的映射。 VMM：VMM负责PA到MA的映射。 总线虚拟化：&ensp;&ensp;总线虚拟化技术可以将一块网卡分给若干个GuestOS使用，每个虚拟机分得网卡性能的1/N，这种技术直接把物理设备划分给GuestOS，无须经过VMM，性能高，接近真机。 容器虚拟化：&ensp;&ensp;容器虚拟化是一种不同于虚拟机方式的虚拟化方法。容器虚拟化可以为应用程序提供隔离的运行空间，且一个容器内的变动不会影响其他容器。容器比虚拟机更轻量，效率更高，部署也更加快捷方便，但容器是将应用打包并以进程的形式运行在操作系统上的，应用和应用之间并非完全隔离，这是容器虚拟化的一个缺陷。 云计算&ensp;&ensp;云计算(Cloud Computing)是一种新兴的商业计算模型。它将计算任务分布在大量计算机构成的资源池上，使各种应用系统能够根据需要获取计算力、存储空间和各种软件服务。通过服务器集群，包括计算服务器、存储服务器、宽带资源等虚拟计算资源的自我维护和管理，降低整个系统的单位处理能力成本。 &ensp;&ensp;云计算（Cloud Computing）是一种基于互联网的相关服务的增加、使用和交付模式，它依赖于虚拟化，通常会涉及通过互联网来提供动态易扩展且经常是虚拟化的资源。通过虚拟化技术，把服务器等硬件资源构建成一个虚拟资源池，从而实现共同计算和共享资源，就实现了云计算。 云计算的实现模式IaaS–基础设施即服务：&ensp;&ensp;由一些硬件、网络和操作系统资源集成。此模式下，用户不必自行采购硬件设备，也不用担心安装OS、配置防火墙、网络升级、更换硬件等事务，只需选择自己所需的硬件配置，如操作系统、带宽等，就可以使用相应的硬件资源。 PaaS–平台即服务：&ensp;&ensp;PaaS在IaaS的基础上加入了中间件和数据库资源，用户选择PaaS时只要考虑习惯使用什么语言的数据库，然后关心程序的开发和部署即可。 SaaS–软件即服务：&ensp;&ensp;在SaaS模式下，用户使用的软件并不需自己安装，也不用自己维护，而是只需要登录即可使用。 FaaS&ensp;&ensp;可以广义的理解为功能服务化，也可以解释为函数服务化 见https://aws.amazon.com/cn/blogs/china/iaas-faas-serverless/ 云平台的主要特性可用性高：&ensp;&ensp;当一台主机的虚拟化层出现故障时，云平台自动将上面的虚拟机迁移到另一虚拟化层上。控制面板服务器离线时，虽然不能对虚拟机进行任何管理操作，但虚拟机依旧可以正常运行。 管理灵活：&ensp;&ensp;云平台具有高度的扩展性，可在云系统中任意添加和删除虚拟化层、数据存储设备和其他资源，如CPU和内存等。 用户管理方便：&ensp;&ensp;云平台为用户提供精细的控制选项，设置不同类型的用户和用户组，定制不同用户与用户组的访问和功能。 负载均衡：&ensp;&ensp;云平台的负载均衡功能，提高了应用程序的可用性和可扩展性。 安全可靠：&ensp;&ensp;基础设施的虚拟机之间完全隔离，各自访问自己的硬盘。存储虚拟机的服务器上安装有反欺骗防火墙。在控制面板中可以给用户设置不同的角色，并为其配置不同级别的访问权限。 计费功能完善：&ensp;&ensp;面向第三方的云平台有强大的计费功能，拥有完整的账单系统，支持多种货币类型，实现资源的计划使用和自动结算。 集成丰富的API：云平台集成了多种应用软件接口，允许用户自行在云端进行应用开发。 支持移动接入：&ensp;&ensp;云平台一般都支持iPhone/Android应用，用户可以通过移动设备连接云系统，管理自己的云资源和在云中的操作 虚拟化与云计算&ensp;&ensp;虚拟化是云计算的关键技术之一，实现云计算必须使用虚拟化技术，实现资源的动态弹性分配。任何一个云计算管理平台，都是构建在虚拟化管理平台的基础之上的。 &ensp;&ensp;虚拟化资源使用需要管理员进行管理和分配，云计算是用用户自助管理和使用。 &ensp;&ensp;云计算完全解除了的软件和硬件耦合度，所有基础设施资源均虚拟化后通过资源池进行配额衡量，与硬件无关。虚拟化虽然实现了资源池化，但资源的分配仍旧需要与硬件存在一定程度上的关联。]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP请求方法]]></title>
    <url>%2F2019%2F03%2F01%2FHTTP%E8%AF%B7%E6%B1%82%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[GET方法&ensp;&ensp;GET是最常用的方法，GET 方法意思是获取被请求 URI（Request-URI）指定的信息（以实体的格式），常用于请求服务器发送某个资源。GET请求中不会呈现数据。 &ensp;&ensp;最常用于向服务器查询某些信息。必要时，可以将查询字符串参数追加到URL末尾，以便将信息发送给服务器。 &ensp;&ensp;使用GET请求时经常会发生的一个错误，就是查询字符串的格式有问题。查询字符串中每个参数的名称和值都必须使用encodeURLComponent()进行编码，然后才能放到URL的末尾；而且所有的名-值对都必须由（&amp;）分离。 &ensp;&ensp;追踪HTTP流后，显示如下，响应报文中包含请求的页面 12345678910111213141516171819202122232425262728293031323334353637383940GET / HTTP/1.1Host: 172.18.74.92User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateDNT: 1Connection: keep-aliveUpgrade-Insecure-Requests: 1Cache-Control: max-age=0HTTP/1.1 200 OKDate: Sun, 07 Apr 2019 06:24:06 GMTServer: Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips mod_fcgid/2.3.9 PHP/5.4.16X-Powered-By: PHP/5.4.16Content-Length: 743Keep-Alive: timeout=5, max=100Connection: Keep-AliveContent-Type: text/html; charset=UTF-8&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;charset=UTF-8&quot; /&gt;&lt;title&gt;产品添加-JD产品管理系统&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;JD产品管理&lt;/h3&gt;&lt;form action=&quot;deal.php&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt;图书名称：&lt;input type=&apos;text&apos; name=&apos;title&apos; /&gt;&lt;hr /&gt;销售价格：&lt;input type=&quot;text&quot; name=&apos;price&apos; /&gt;&lt;hr /&gt;市场价格：&lt;input type=&quot;text&quot; name=&apos;market_price&apos; /&gt;&lt;hr /&gt;&lt;input type=&quot;submit&quot; name=&quot;submit&quot; value=&quot;添加&quot; /&gt;&lt;input type=&quot;reset&quot; name=&quot;reset&quot; value=&quot;重置&quot; /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;&gt; HEAD方法&ensp;&ensp;HEAD方法与GET方法的行为很类似，但在服务器响应中只会返回收首部，不会返回实体的主体部分。这就允许客户端在未获取实际资源的情况下，对资源首部进行检查。使用HEAD 可以： 在不获取资源的情况下了解资源的情况(例如，对类型的判断) 通过查看响应中的状态码，看看某个对象是否存在 通过查看首部，测试资源是否被修改 PUT方法&ensp;&ensp;与GET从服务器读取文档相反，PUT方法会向服务器写入文档。有些发布系统允许用户创建Web页面，并用PUT直接将其安装到Web服务器上去。 &ensp;&ensp;PUT方法的语义是让服务器用请求的主体部分来创建一个由所请求的URL命名的新文档，或者如果那个URL已经存在的话，就用这个主体来替代它。 &ensp;&ensp;我猜测，如果在某公司的招聘网站提交简历应该会用到PUT方法，因为PUT用于向服务器上的资源中存储数据。 1234567891011121314151617181920212223242526PUT /personal-center/resumeInfo HTTP/1.1Host: hr.某ya.comUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0Accept: application/jsonAccept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateReferer: http://hr.某ya.com/campus_apply/某ya/4112Content-Type: application/jsonX-Tingyun-Id: BuYww-5RqXA;r=619819948Content-Length: 331DNT: 1Connection: keep-aliveCookie: 略&#123;&quot;uploadInfo&quot;:&#123;&quot;resumeKey&quot;:&quot;&quot;,&quot;attachments&quot;:[]&#125;,&quot;basicInfo&quot;:&#123;&quot;name&quot;:&quot;netlab&quot;,&quot;phone&quot;:&quot;&quot;…………&quot;&#125;HTTP/1.1 200 OKServer: Tengine/2.1.2Date: Sun, 07 Apr 2019 06:50:19 GMTContent-Type: application/json; charset=utf-8Transfer-Encoding: chunkedConnection: keep-aliveETag: W/&quot;41c-l2UjHwiWvnbdwUn1PQuGkg&quot;set-cookie: 略Vary: Accept-EncodingContent-Encoding: gzip&#123;&quot;id&quot;:779573,&quot;name&quot;:&quot;netlab&quot;,&quot;email&quot;:null,&quot;phone&quot;:&quot;&quot;…………&#125; POST方法&ensp;&ensp;POST方法期初是用来向服务器输入数据的，实际上，通常会用他来支持HTML的表单。表单中填好的数据通常会被送给服务器，然后由服务器将其发送到它要去的地方(例如发送到数据库中存储)。POST用于向服务器发送数据。 &ensp;&ensp;追踪HTTP流后。可以看到使用POST方法提交的数据 12345678910111213141516171819202122232425262728293031323334353637383940POST /deal.php HTTP/1.1Host: 172.18.74.92User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateReferer: http://172.18.74.92/Content-Type: multipart/form-data; boundary=------------------25762159945006Content-Length: 446DNT: 1Connection: keep-aliveUpgrade-Insecure-Requests: 1-----------------------------25762159945006Content-Disposition: form-data; name=&quot;title&quot;10 #title中提交的内容 -----------------------------25762159945006Content-Disposition: form-data; name=&quot;price&quot;20 #price中提交的内容-----------------------------25762159945006Content-Disposition: form-data; name=&quot;market_price&quot;3 #market_price中提交的内容-----------------------------25762159945006Content-Disposition: form-data; name=&quot;submit&quot;添加-----------------------------25762159945006--HTTP/1.1 200 OKDate: Sun, 07 Apr 2019 05:55:36 GMTServer: Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips mod_fcgid/2.3.9 PHP/5.4.16X-Powered-By: PHP/5.4.16Content-Length: 12Keep-Alive: timeout=5, max=100Connection: Keep-AliveContent-Type: text/html; charset=utf-8添加成功 DELECT方法&ensp;&ensp;顾名思义，DELECT方法所做的就是请服务器删除请求URL所指定的资源。但是客户端应用程序无法保证删除操作一定会执行。因为HTTP规范允许服务器在不通知客户的端的情况下撤销操作。 &ensp;&ensp;如果响应里包含描述成功的实体，响应应该是 200（OK）；如果 DELETE 动作还没有执行，应该以 202（已接受）响应；如果 DELETE 请求方法已经执行但响应不包含实体，那么应该以204（无内容）响应。 TRACE方法&ensp;&ensp;客户端发起一个请求时，这个请求可能要穿过防火墙、代理、网关或其他一些应用程序。每个中间节点都可能会修改原始HTTP请求。TRACE方法允许客户端在最终将请求发送给服务器时看看它变成了什么样子。 &ensp;&ensp;TRACE请求会在目的服务器端发起一个”环回”诊断。行程最后一站的服务器会弹回一条TRACE响应，并在响应主体中携带它所收到的原始请求报文。这样客户端就可以查看在所有中间HTTP应用程序组成的请求/响应链上，原始报文是否以及如何被毁坏或修改过。 &ensp;&ensp;TRACE方法主要用于诊断，也就是说，用于验证请求是否如愿穿过了请求/响应链。它是一种很好的工具，可以用来查看代理和其他应用程序对客户请求所产生的效果。 &ensp;&ensp;尽管TRACE可以很方便的用于诊断，但它也存在缺点，他假定中间应用程序对各类不同的类型请求的处理方式是相同的。很多HTTP应用程序会根据方法的不同做出不同的事情，比如代理可能会将POST请求直接发给服务器，而将GET请求发送给另一个HTTP应用程序。TRACE并不提供区分这些方法的机制。通常中间应用程序会自行决定对TRACE 请求的处理方式。 OPTION方法&ensp;&ensp;OPTION方法请求Web服务器告知其支持的各种功能。可以询问服务器通常支持哪些方法，或者对某些特殊资源支持哪些方法。(有些服务器可能只支持对一些特殊类型对象使用特定操作) &ensp;&ensp;这为客户端应用程序提供了一种手段，使其不用实际访问那些资源就能判定访问各种资源的最优方式。 CONNECT方法&ensp;&ensp;HTTP1.1 协议规范保留了 CONNECT 方法，此方法是为了能用于能动态切换到隧道的代理 参考HTTP权威指南]]></content>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见查询示例]]></title>
    <url>%2F2019%2F02%2F15%2F%E5%B8%B8%E8%A7%81%E6%9F%A5%E8%AF%A2%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[常见查询示例&ensp;&ensp;假设有一个表格，是商店为某些交易员(经销商)保存每种商品(项目号)的价格。假设每个交易者的每件商品都有一个固定的价格，那么(商品，交易者)就是记录的主键 12345678910111213141516171819202122232425262728293031mysql&gt; create database shop;Query OK, 1 row affected (0.00 sec)mysql&gt; use shop;Database changedmysql&gt; create table shop_tab( -&gt; article int(4) unsigned zerofill default &apos;0000&apos; not null, -&gt; dealer char(20) default &apos;&apos; not null, -&gt; price double(16,2) default &apos;0.00&apos; not null, -&gt; primary key(article,dealer));Query OK, 0 rows affected (0.12 sec)mysql&gt; insert into shop_tab values -&gt; (1,&apos;A&apos;,3.45),(1,&apos;B&apos;,3.99),(2,&apos;A&apos;,10.99),(3,&apos;B&apos;,1.45),(3,&apos;C&apos;,1.69),(3,&apos;D&apos;,1.25),(4,&apos;D&apos;,19.95);Query OK, 7 rows affected (0.05 sec)Records: 7 Duplicates: 0 Warnings: 0mysql&gt; select * from shop_tab order by article;+---------+--------+-------+| article | dealer | price |+---------+--------+-------+| 0001 | A | 3.45 || 0001 | B | 3.99 || 0002 | A | 10.99 || 0003 | B | 1.45 || 0003 | C | 1.69 || 0003 | D | 1.25 || 0004 | D | 19.95 |+---------+--------+-------+7 rows in set (0.00 sec) 1.列的最大值1234567mysql&gt; select max(price) from shop_tab;+------------+| max(price) |+------------+| 19.95 |+------------+1 row in set (0.00 sec) 2.包含某一列的最大值的行&ensp;&ensp;使用子查询完成此操作 12345678mysql&gt; select * from shop_tab -&gt; where price=(select max(price) from shop_tab);+---------+--------+-------+| article | dealer | price |+---------+--------+-------+| 0004 | D | 19.95 |+---------+--------+-------+1 row in set (0.01 sec) &ensp;&ensp;按价格降序排序所有行，并使用特定于MySQL的LIMIT子句获取第一行 123456789mysql&gt; select * from shop_tab -&gt; order by price desc -&gt; limit 1;+---------+--------+-------+| article | dealer | price |+---------+--------+-------+| 0004 | D | 19.95 |+---------+--------+-------+1 row in set (0.00 sec) 3.每种商品的最高价格12345678910111213mysql&gt; select article,max(price) as price -&gt; from shop_tab -&gt; group by article -&gt; order by article;+---------+-------+| article | price |+---------+-------+| 0001 | 3.99 || 0002 | 10.99 || 0003 | 1.69 || 0004 | 19.95 |+---------+-------+4 rows in set (0.00 sec) 4.对于每种商品，找到价格最贵的经销商1234567891011121314151617181920212223242526271解：以price为条件，使用where s1.article = s2.article或者any操作符使主查询一条记录 对应子查询的一条记录。 ANY 关键字必须接在一个比较操作符的后面，表示与子查询返回的任何值比较为 TRUE 则返回 TRUE 主查询的一条记录对应子查询多条记录会产生错误 (ERROR 1242 (21000): Subquery returns more than 1 row)。mysql&gt; select article,dealer,price -&gt; from shop_tab as s1 -&gt; where price=(select max(s2.price) -&gt; from shop_tab as s2 -&gt; where s1.article = s2.article -&gt; order by article -&gt; ); 或者 mysql&gt; select article,dealer,price -&gt; from shop_tab as s1 -&gt; where price= any(select max(s2.price) -&gt; from shop_tab as s2 -&gt; order by article -&gt; );+---------+--------+-------+| article | dealer | price |+---------+--------+-------+| 0001 | B | 3.99 || 0002 | A | 10.99 || 0003 | C | 1.69 || 0004 | D | 19.95 |+---------+--------+-------+ 123456789101112131415162解：筛选出每件商品最贵的价格作为s2，与原表S1内连接，显示两边表同时有对应的数据，任何一边缺失数据就不显示mysql&gt; select s1.article,s1.dealer,s1.price -&gt; from shop_tab as s1 join( -&gt; select article,max(price) as price -&gt; from shop_tab group by article) as s2 -&gt; where s1.article = s2.article and s1.price = s2.price +---------+--------+-------+| article | dealer | price |+---------+--------+-------+| 0001 | B | 3.99 || 0002 | A | 10.99 || 0003 | C | 1.69 || 0004 | D | 19.95 |+---------+--------+-------+4 rows in set (0.00 sec) 12345678910111213141516171819202122232425262728293031323解：s2左连接s1，通过s1.article = s2.article 两张表进行价格比较mysql&gt; select * from shop_tab as s1 -&gt; left join shop_tab as s2 -&gt; on s1.article = s2.article and s1.price &lt; s2.price;+---------+--------+-------+---------+--------+-------+| article | dealer | price | article | dealer | price |+---------+--------+-------+---------+--------+-------+| 0001 | A | 3.45 | 0001 | B | 3.99 || 0001 | B | 3.99 | NULL | NULL | NULL || 0002 | A | 10.99 | NULL | NULL | NULL || 0003 | B | 1.45 | 0003 | C | 1.69 || 0003 | C | 1.69 | NULL | NULL | NULL || 0003 | D | 1.25 | 0003 | B | 1.45 || 0003 | D | 1.25 | 0003 | C | 1.69 || 0004 | D | 19.95 | NULL | NULL | NULL |+---------+--------+-------+---------+--------+-------+8 rows in set (0.00 sec)然后再选取s2中为NULL值的行mysql&gt; select s1.article,s1.dealer,s1.price -&gt; from shop_tab as s1 -&gt; left join shop_tab as s2 -&gt; on s1.article = s2.article AND s1.price &lt; s2.price -&gt; where s2.article is null;+---------+--------+-------+| article | dealer | price |+---------+--------+-------+| 0001 | B | 3.99 || 0002 | A | 10.99 || 0003 | C | 1.69 || 0004 | D | 19.95 |+---------+--------+-------+4 rows in set (0.00 sec) 5.用户自定义变量123456789101112131415161718192021mysql&gt; select @min_price:=min(price),@max_price:=max(price) -&gt; from shop_tab;+------------------------+------------------------+| @min_price:=min(price) | @max_price:=max(price) |+------------------------+------------------------+| 1.25 | 19.95 |+------------------------+------------------------+1 row in set (0.00 sec)mysql&gt; select * from shop_tab -&gt; where price = @min_price:=min(price) -&gt; \c mysql&gt; select * from shop_tab -&gt; where price = @min_price or price = @max_price;+---------+--------+-------+| article | dealer | price |+---------+--------+-------+| 0003 | D | 1.25 || 0004 | D | 19.95 |+---------+--------+-------+2 rows in set (0.00 sec) 6.使用外键12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879CREATE TABLE person ( id SMALLINT UNSIGNED NOT NULL AUTO_INCREMENT, name CHAR(60) NOT NULL, PRIMARY KEY (id));CREATE TABLE shirt ( id SMALLINT UNSIGNED NOT NULL AUTO_INCREMENT, style ENUM(&apos;t-shirt&apos;, &apos;polo&apos;, &apos;dress&apos;) NOT NULL, color ENUM(&apos;red&apos;, &apos;blue&apos;, &apos;orange&apos;, &apos;white&apos;, &apos;black&apos;) NOT NULL, owner SMALLINT UNSIGNED NOT NULL REFERENCES person(id), PRIMARY KEY (id));INSERT INTO person VALUES (NULL, &apos;Antonio Paz&apos;);SELECT @last := LAST_INSERT_ID();INSERT INTO shirt VALUES(NULL, &apos;polo&apos;, &apos;blue&apos;, @last),(NULL, &apos;dress&apos;, &apos;white&apos;, @last),(NULL, &apos;t-shirt&apos;, &apos;blue&apos;, @last);INSERT INTO person VALUES (NULL, &apos;Lilliana Angelovska&apos;);SELECT @last := LAST_INSERT_ID();INSERT INTO shirt VALUES(NULL, &apos;dress&apos;, &apos;orange&apos;, @last),(NULL, &apos;polo&apos;, &apos;red&apos;, @last),(NULL, &apos;dress&apos;, &apos;blue&apos;, @last),(NULL, &apos;t-shirt&apos;, &apos;white&apos;, @last);SELECT * FROM person;+----+---------------------+| id | name |+----+---------------------+| 1 | Antonio Paz || 2 | Lilliana Angelovska |+----+---------------------+SELECT * FROM shirt;+----+---------+--------+-------+| id | style | color | owner |+----+---------+--------+-------+| 1 | polo | blue | 1 || 2 | dress | white | 1 || 3 | t-shirt | blue | 1 || 4 | dress | orange | 2 || 5 | polo | red | 2 || 6 | dress | blue | 2 || 7 | t-shirt | white | 2 |+----+---------+--------+-------+SELECT s.* FROM person p INNER JOIN shirt s ON s.owner = p.id WHERE p.name LIKE &apos;Lilliana%&apos; AND s.color &lt;&gt; &apos;white&apos;;+----+-------+--------+-------+| id | style | color | owner |+----+-------+--------+-------+| 4 | dress | orange | 2 || 5 | polo | red | 2 || 6 | dress | blue | 2 |+----+-------+--------+-------+SHOW CREATE TABLE shirt\G*************************** 1. row ***************************Table: shirtCreate Table: CREATE TABLE `shirt` (`id` smallint(5) unsigned NOT NULL auto_increment,`style` enum(&apos;t-shirt&apos;,&apos;polo&apos;,&apos;dress&apos;) NOT NULL,`color` enum(&apos;red&apos;,&apos;blue&apos;,&apos;orange&apos;,&apos;white&apos;,&apos;black&apos;) NOT NULL,`owner` smallint(5) unsigned NOT NULL,PRIMARY KEY (`id`)) ENGINE=MyISAM DEFAULT CHARSET=latin1 7.使用两个键搜索&ensp;&ensp;逻辑运算符or 使用一个主键能够被很好的优化，就像处理and一样但是使用or去搜索两个不同的主键比较棘手 12SELECT field1_index, field2_index FROM test_tableWHERE field1_index = &apos;1&apos; OR field2_index = &apos;1&apos; &ensp;&ensp;可以使用union结合两个单独的select语句进行查询，会更加有效。每个select只搜索一个键则会很好的优化 12345SELECT field1_index, field2_index FROM test_table WHERE field1_index = &apos;1&apos;UNIONSELECT field1_index, field2_index FROM test_table WHERE field2_index = &apos;1&apos;; 8.计算每日访问量以下示例显示如何使用位组功能计算用户访问网页的每月天数。 1234CREATE TABLE t1 (year YEAR(4), month INT(2) UNSIGNED ZEROFILL, day INT(2) UNSIGNED ZEROFILL);INSERT INTO t1 VALUES(2000,1,1),(2000,1,20),(2000,1,30),(2000,2,2), (2000,2,23),(2000,2,23); &ensp;&ensp;示例表包含表示用户对页面的访问的年 - 月 - 日值。要确定这些访问每月发生的天数，请使用以下查询： 123456789SELECT year,month,BIT_COUNT(BIT_OR(1&lt;&lt;day)) AS days FROM t1 GROUP BY year,month;+------+-------+------+| year | month | days |+------+-------+------+| 2000 | 01 | 3 || 2000 | 02 | 2 |+------+-------+------+ &ensp;&ensp;该查询计算每个年/月组合在表中显示的天数，并自动删除重复的条目 9.使用AUTO_INCREMENT该AUTO_INCREMENT属性可用于为新行生成唯一标识： 12345678910111213141516171819202122mysql&gt; CREATE TABLE animals ( -&gt; id MEDIUMINT NOT NULL AUTO_INCREMENT, -&gt; name CHAR(30) NOT NULL, -&gt; PRIMARY KEY (id) -&gt; );Query OK, 0 rows affected (0.25 sec)mysql&gt; insert into animals(name) values (&apos;dog&apos;),(&apos;cat&apos;),(&apos;penguin&apos;),(&apos;lax&apos;),(&apos;bird&apos;);Query OK, 5 rows affected (0.04 sec)Records: 5 Duplicates: 0 Warnings: 0mysql&gt; select * from animals;+----+---------+| id | name |+----+---------+| 1 | dog || 2 | cat || 3 | penguin || 4 | lax || 5 | bird |+----+---------+5 rows in set (0.00 sec) &ensp;&ensp;AUTO_INCREMENT列没有指定值，因此MySQL自动分配序列号。也可以显式地为列分配0来生成序列号，除非启用了NO_AUTO_VALUE_ON_ZERO SQL模式（NO_AUTO_VALUE_ON_ZERO影响AUTO_INCREMENT列的处理。一般情况下可以向该列插入NULL或0生成下一个序列号）。例如 123456789101112131415mysql&gt; INSERT INTO animals (id,name) VALUES(0,&apos;groundhog&apos;);Query OK, 1 row affected (0.02 sec)mysql&gt; select * from animals;+----+-----------+| id | name |+----+-----------+| 1 | dog || 2 | cat || 3 | penguin || 4 | lax || 5 | bird || 6 | groundhog |+----+-----------+6 rows in set (0.01 sec) &ensp;&ensp;如果声明了列NOT NULL，则还可以分配NULL给列以生成序列号。例如： 12345678910111213141516mysql&gt; INSERT INTO animals (id,name) VALUES(NULL,&apos;squirrel&apos;);Query OK, 1 row affected (0.04 sec)mysql&gt; select * from animals;+----+-----------+| id | name |+----+-----------+| 1 | dog || 2 | cat || 3 | penguin || 4 | lax || 5 | bird || 6 | groundhog || 7 | squirrel |+----+-----------+7 rows in set (0.00 sec) &ensp;&ensp;将任何其他值插入AUTO_INCREMENT列时，列被设置为该值，序列被重置，以便下一个自动生成的值按照最大列值的顺序生成。例如: 12345678910111213141516171819mysql&gt;INSERT INTO animals (id,name) VALUES(100,&apos;rabbit&apos;);Query OK, 1 row affected (0.04 sec)mysql&gt;INSERT INTO animals (id,name) VALUES(NULL,&apos;mouse&apos;);Query OK, 1 row affected (0.04 sec)SELECT * FROM animals;+-----+-----------+| id | name |+-----+-----------+| 1 | dog || 2 | cat || 3 | penguin || 4 | lax || 5 | whale || 6 | ostrich || 7 | groundhog || 8 | squirrel || 100 | rabbit || 101 | mouse |+-----+-----------+ &ensp;&ensp;AUTO_INCREMENT使用LAST_INSERT_ID() SQL函数或mysql_insert_id() C API函数检索最新自动生成的值 。这些函数是特定于连接的，因此它们的返回值不受另一个执行插入的连接的影响。 1234567mysql&gt; select LAST_INSERT_ID();+------------------+| LAST_INSERT_ID() |+------------------+| 7 |+------------------+1 row in set (0.00 sec) 注意 对于多行插入，LAST_INSERT_ID()和mysql_insert_id()实际上从插入的第一行返回AUTO_INCREMENT键。 &ensp;&ensp;要从除1之外的AUTO_INCREMENT值开始，使用CREATE TABLE或ALTER TABLE设置该值，如下所示: 123mysql&gt; ALTER TABLE animals AUTO_INCREMENT = 100;Query OK, 0 rows affected (0.02 sec)Records: 0 Duplicates: 0 Warnings: 0]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL检索信息]]></title>
    <url>%2F2019%2F02%2F07%2FMySQL%E6%A3%80%E7%B4%A2%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[从表中检索信息&ensp;&ensp;该SELECT语句用于从表中提取信息。声明的一般形式是： 123SELECT what_to_selectFROM which_tableWHERE conditions_to_satisfy; &ensp;&ensp;what_to_select表示你想看到什么，这可以是列表中的一列， * 可以表示“ 所有列”。which_table表示要从中检索数据的表。该WHERE 条款是可选的。如果存在，则 conditions_to_satisfy指定行必须满足的一个或多个条件才有资格进行检索。 1234567891011mysql&gt; select name -&gt; from pet -&gt; where sex=&apos;m&apos;；+--------+| name |+--------+| Claws || Fang || Bowser |+--------+3 rows in set (0.00 sec) 1.选择所有数据&ensp;&ensp;SELECT最简单的形式从表中检索所有内容 123456789101112mysql&gt; select * from pet;+--------+--------+---------+------+------------+------------+| name | owner | species | sex | birth | death |+--------+--------+---------+------+------------+------------+| Fluffy | Harold | cat | f | 1999-02-04 | NULL || Claws | Gwen | cat | m | 1994-03-17 | NULL || Buffy | Harold | dog | f | 1989-05-13 | NULL || Fang | Benny | dog | m | 1990-08-27 | NULL || Bowser | Diane | dog | m | 1979-08-31 | 1995-07-29 || Chirpy | Genw | bird | f | 1998-09-11 | NULL |+--------+--------+---------+------+------------+------------+6 rows in set (0.00 sec) &ensp;&ensp;UPDATE语句修复错误记录 ： 1234567mysql&gt; update pet -&gt; set birth=&apos;1990-01-01&apos; -&gt; where name=&apos;Bowser&apos;;Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; 2.选择特定行&ensp;&ensp;例如，如果想验证刚才对Bowser出生日期所做的更改，请选择Bowser的记录，如下所示： 1234567891011mysql&gt; select * -&gt; from pet -&gt; where name=&apos;Bowser&apos;;+--------+-------+---------+------+------------+------------+| name | owner | species | sex | birth | death |+--------+-------+---------+------+------------+------------+| Bowser | Diane | dog | m | 1990-01-01 | 1995-07-29 |+--------+-------+---------+------+------------+------------+1 row in set (0.00 sec)mysql&gt; &ensp;&ensp;字符串比较通常不区分大小写，因此可以将名称指定为’bowser’， ‘BOWSER’等等。查询结果是一样的。 &ensp;&ensp;也可以在任何列上指定条件，例如想知道1997年或之后出生的动物： 12345678910mysql&gt; select * -&gt; from pet -&gt; where birth &gt;= &apos;1997-02-22&apos;;+--------+--------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+--------+--------+---------+------+------------+-------+| Fluffy | Harold | cat | f | 1999-02-04 | NULL || Chirpy | Genw | bird | f | 1998-09-11 | NULL |+--------+--------+---------+------+------------+-------+2 rows in set (0.00 sec) &ensp;&ensp;还可以使用 AND 进行组合条件进行查询 12345678910mysql&gt; select * -&gt; from pet -&gt; where species = &apos;dog&apos; and sex = &apos;m&apos;;+--------+-------+---------+------+------------+------------+| name | owner | species | sex | birth | death |+--------+-------+---------+------+------------+------------+| Fang | Benny | dog | m | 1990-08-27 | NULL || Bowser | Diane | dog | m | 1990-01-01 | 1995-07-29 |+--------+-------+---------+------+------------+------------+2 rows in set (0.00 sec) &ensp;&ensp;除了AND逻辑运算符还有OR。 123456789101112mysql&gt; select * -&gt; from pet -&gt; where species = &apos;dog&apos; or species = &apos;bird&apos;;+--------+--------+---------+------+------------+------------+| name | owner | species | sex | birth | death |+--------+--------+---------+------+------------+------------+| Buffy | Harold | dog | f | 1989-05-13 | NULL || Fang | Benny | dog | m | 1990-08-27 | NULL || Bowser | Diane | dog | m | 1990-01-01 | 1995-07-29 || Chirpy | Genw | bird | f | 1998-09-11 | NULL |+--------+--------+---------+------+------------+------------+4 rows in set (0.00 sec) &ensp;&ensp;AND和OR可以混合，但 AND优先级高于 OR。如果同时使用这两个运算符，最好使用括号明确指出条件应如何分组。 12345678910mysql&gt; select * -&gt; from pet -&gt; where (species=&apos;dog&apos; and sex=&apos;f&apos;) or (species=&apos;bird&apos; and sex=&apos;f&apos;);+--------+--------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+--------+--------+---------+------+------------+-------+| Buffy | Harold | dog | f | 1989-05-13 | NULL || Chirpy | Genw | bird | f | 1998-09-11 | NULL |+--------+--------+---------+------+------------+-------+2 rows in set (0.00 sec) 3.选择特定列&ensp;&ensp;如果不查看表中的整行，只需将感兴趣的列名进行逗号分隔。例如如果查询谁的动物什么时候出生，请选择name和 birth列： 123456789101112mysql&gt; SELECT name, birth FROM pet;+--------+------------+| name | birth |+--------+------------+| Fluffy | 1999-02-04 || Claws | 1994-03-17 || Buffy | 1989-05-13 || Fang | 1990-08-27 || Bowser | 1990-01-01 || Chirpy | 1998-09-11 |+--------+------------+6 rows in set (0.00 sec) &ensp;&ensp;要找出宠物属于谁，如下查询 123456789101112mysql&gt; select owner from pet;+--------+| owner |+--------+| Harold || Gwen || Harold || Benny || Diane || Genw |+--------+6 rows in set (0.00 sec) &ensp;&ensp;要最小化输出，请通过添加关键字 DISTINCT 去除重复输出： 1234567891011mysql&gt; select distinct owner from pet;+--------+| owner |+--------+| Harold || Gwen || Benny || Diane || Genw |+--------+5 rows in set (0.00 sec) &ensp;&ensp;使用WHERE子句将行选择与列选择组合在一起。例如，仅获取狗和猫的出生日期，如下查询： 12345678910111213mysql&gt; select name,species,birth -&gt; from pet -&gt; where species = &apos;dog&apos; or species = &apos;cat&apos;;+--------+---------+------------+| name | species | birth |+--------+---------+------------+| Fluffy | cat | 1999-02-04 || Claws | cat | 1994-03-17 || Buffy | dog | 1989-05-13 || Fang | dog | 1990-08-27 || Bowser | dog | 1990-01-01 |+--------+---------+------------+5 rows in set (0.00 sec) 4.对行排序&ensp;&ensp;当行以某种有意义的方式排序时，通常更容易查询输出。要对结果进行排序，请使用ORDER BY子句。&ensp;&ensp;默认排序顺序是升序。要按反向（降序）排序，请将DESC关键字添加到要排序 的列名称后面 1234567891011121314151617181920212223242526mysql&gt; select name, birth from pet order by birth;+--------+------------+| name | birth |+--------+------------+| Buffy | 1989-05-13 || Bowser | 1990-01-01 || Fang | 1990-08-27 || Claws | 1994-03-17 || Chirpy | 1998-09-11 || Fluffy | 1999-02-04 |+--------+------------+6 rows in set (0.00 sec)mysql&gt; select name, species, birth from pet -&gt; order by species,birth desc;+--------+---------+------------+| name | species | birth |+--------+---------+------------+| Chirpy | bird | 1998-09-11 || Fluffy | cat | 1999-02-04 || Claws | cat | 1994-03-17 || Fang | dog | 1990-08-27 || Bowser | dog | 1990-01-01 || Buffy | dog | 1989-05-13 |+--------+---------+------------+6 rows in set (0.00 sec) &ensp;&ensp;该DESC关键字仅适用于紧邻的列名（birth）; 它不会影响species列排序顺序。 &ensp;&ensp;LIMIT 子句用于限制由 SELECT 语句返回的数据数量。下面是 LIMIT 子句与 OFFSET 子句一起使用时的语法： 123SELECT column1, column2, columnN FROM table_nameLIMIT [no of rows] OFFSET [row num] &ensp;&ensp;引擎将返回从下一行开始直到给定的 OFFSET 为止的所有行。 5.日期计算&ensp;&ensp;要确定每只宠物的年龄，使用 TIMESTAMPDIFF()功能。它的参数是你所希望结果表达的 单位，以及取得差异的两个日期。以下查询显示了每只宠物的出生日期，当前日期和年龄。一个 别名（age）使得输出列更有意义。 1234567891011121314mysql&gt; SELECT name, birth, CURDATE(), -&gt; TIMESTAMPDIFF(YEAR,birth,CURDATE()) AS age -&gt; FROM pet;+--------+------------+------------+------+| name | birth | CURDATE() | age |+--------+------------+------------+------+| Fluffy | 1999-02-04 | 2019-02-19 | 20 || Claws | 1994-03-17 | 2019-02-19 | 25 || Buffy | 1989-05-13 | 2019-02-19 | 29 || Fang | 1990-08-27 | 2019-02-19 | 28 || Bowser | 1990-01-01 | 2019-02-19 | 29 || Chirpy | 1998-09-11 | 2019-02-19 | 20 |+--------+------------+------------+------+6 rows in set (0.00 sec) &ensp;&ensp;也可以使用order by 对age进行排序，不再演示 &ensp;&ensp;下面说明TIMESTAMPDIFF函数的语法。 1TIMESTAMPDIFF(unit,begin,end); &ensp;&ensp;TIMESTAMPDIFF函数返回begin-end的结果，其中begin和end是DATE或DATETIME表达式。 &ensp;&ensp;TIMESTAMPDIFF函数允许其参数具有混合类型，例如，begin是DATE值，end可以是DATETIME值。 如果使用DATE值，则TIMESTAMPDIFF函数将其视为时间部分为“00:00:00”的DATETIME值。 &ensp;&ensp;unit参数是确定(end-begin)的结果的单位，表示为整数。 以下是有效单位：MICROSECOND(微秒)、SECOND(秒)、MINUTE(分钟)、HOUR(小时)、DAY(天)、WEEK(星期)、MONTH(月)、QUARTER(季度)、YEAR(年) &ensp;&ensp;类似的查询可用于确定死亡动物的死亡年龄。可以通过检查death值是否为null 。然后，对于那些非NULL值的，计算death和 birth值之差： 1234567891011mysql&gt; select name,birth,death, -&gt; timestampdiff(year,birth,death) as age -&gt; from pet -&gt; where death is not null -&gt; order by age;+--------+------------+------------+------+| name | birth | death | age |+--------+------------+------------+------+| Bowser | 1990-01-01 | 1995-07-29 | 5 |+--------+------------+------------+------+1 row in set (0.00 sec) &ensp;&ensp;MySQL提供了用于提取日期的部分，如一些功能 YEAR()， MONTH()和 DAYOFMONTH()。如下一个简单的查询birth和 MONTH(birth)： 12345678910111213141516171819202122mysql&gt; select name,birth,month(birth) from pet; +--------+------------+--------------+| name | birth | month(birth) |+--------+------------+--------------+| Fluffy | 1999-02-04 | 2 || Claws | 1994-03-17 | 3 || Buffy | 1989-05-13 | 5 || Fang | 1997-02-22 | 2 || Bowser | 1990-01-01 | 1 || Chirpy | 1998-09-11 | 9 |+--------+------------+--------------+6 rows in set (0.00 sec)mysql&gt; select name,birth -&gt; from pet -&gt; where month(birth)=5;+-------+------------+| name | birth |+-------+------------+| Buffy | 1989-05-13 |+-------+------------+1 row in set (0.00 sec) &ensp;&ensp;DATE_ADD()可以将时间间隔添加到给定日期。如果将值添加到CURDATE()，然后提取月份部分MONTH()，结果将生成查找生日的月份： 12345678mysql&gt; select name,birth from pet -&gt; where month(birth)=month(date_add(curdate(),interval 2 month));+-------+------------+| name | birth |+-------+------------+| Buffy | 1989-05-13 |+-------+------------+1 row in set (0.00 sec) 6.null 值&ensp;&ensp;要测试NULL，请使用IS NULL 和 IS NOT NULL运算符，如下所示 12345678mysql&gt; SELECT 1 IS NULL, 1 IS NOT NULL -&gt; ;+-----------+---------------+| 1 IS NULL | 1 IS NOT NULL |+-----------+---------------+| 0 | 1 |+-----------+---------------+1 row in set (0.00 sec) &ensp;&ensp;任何算术比较NULL的结果 也是NULL，所以你不能从这种比较中获得任何有意义的结果。&ensp;&ensp;在MySQL中，0或NULL 为假，其他则为真。布尔运算的默认真值是1。 7.模式匹配&ensp;&ensp;MySQL提供标准的SQL模式匹配以及基于扩展正则表达式的模式匹配，类似于Unix实用程序（如vi，grep和 sed）使用的扩展正则表达式 。 &ensp;&ensp;SQL模式匹配可以使用 “_” 匹配任何单个字符并且%匹配任意数量的字符（包括零个字符）。在MySQL中，SQL模式默认情况下不区分大小写。使 用SQL模式时不要使用 =或&lt;&gt;，改用LIKE或 NOT LIKE比较运算符。 &ensp;&ensp;查找以b（b%）开头。%fy（以fy结尾），%w%（包含w字符） 12345678910mysql&gt; select * -&gt; from pet -&gt; where name like &apos;b%&apos;;+--------+--------+---------+------+------------+------------+| name | owner | species | sex | birth | death |+--------+--------+---------+------+------------+------------+| Buffy | Harold | dog | f | 1989-05-13 | NULL || Bowser | Diane | dog | m | 1990-01-01 | 1995-07-29 |+--------+--------+---------+------+------------+------------+2 rows in set (0.00 sec) &ensp;&ensp;要查找包含五个字符的名称： 12345678mysql&gt; select * from pet where name like &apos;_____&apos;;+-------+--------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+-------+--------+---------+------+------------+-------+| Claws | Gwen | cat | m | 1994-03-17 | NULL || Buffy | Harold | dog | f | 1989-05-13 | NULL |+-------+--------+---------+------+------------+-------+2 rows in set (0.00 sec) &ensp;&ensp;MySQL提供的另一种模式匹配使用扩展的正则表达式。当为这种类型的模式测试匹配时，使用 REGEXP和NOT REGEXP运算符（或 RLIKE和 NOT RLIKE，它们是同义词）。 &ensp;&ensp;以下列表描述了扩展正则表达式的一些特征： &ensp;&ensp;. 匹配任何单个字符。字符类[…]匹配括号内的任何字符。例如， [abc]匹配a， b或c。[a-z] 匹配任何字母，而[0-9] 匹配任何数字。 &ensp;&ensp;*匹配前面事物的零个或多个实例。例如，x 匹配任意数量的x字符， [0-9]匹配任意数量的数字，.*匹配任意数量的任何字符。 &ensp;&ensp;如果模式与测试值中的任何位置匹配，则正则表达式模式匹配成功 。（这与LIKE模式匹配不同，仅在模式与整个值匹配时才会成功。）使用锚定模式以使其与要测试的值的开头或结尾匹配，请使用模式^开头或$结尾。 12345678mysql&gt; select * from pet where name regexp &apos;^b&apos;;+--------+--------+---------+------+------------+------------+| name | owner | species | sex | birth | death |+--------+--------+---------+------+------------+------------+| Buffy | Harold | dog | f | 1989-05-13 | NULL || Bowser | Diane | dog | m | 1990-01-01 | 1995-07-29 |+--------+--------+---------+------+------------+------------+2 rows in set (0.00 sec) 8.计数行&ensp;&ensp;COUNT(*)计算行数，因此计算动物数量的查询如下所示： 1234567mysql&gt; select count(*) from pet;+----------+| count(*) |+----------+| 6 |+----------+1 row in set (0.00 sec) &ensp;&ensp;计算每个人拥有几个宠物 1234567891011mysql&gt; select owner,count(*) from pet group by owner;+--------+----------+| owner | count(*) |+--------+----------+| Benny | 1 || Diane | 1 || Genw | 1 || Gwen | 1 || Harold | 2 |+--------+----------+5 rows in set (0.00 sec) &ensp;&ensp;上述查询使用GROUP BY对每个owner进行分组。使用COUNT()结合 GROUP BY在各种分组表征数据时非常有用。 &ensp;&ensp;想要得到每种性别的动物数量仅适用于已知性别的动物： 1234567891011121314mysql&gt; select species,sex,count(*) -&gt; from pet -&gt; where sex is not null -&gt; group by species,sex;+---------+------+----------+| species | sex | count(*) |+---------+------+----------+| bird | f | 1 || cat | f | 1 || cat | m | 1 || dog | f | 1 || dog | m | 2 |+---------+------+----------+5 rows in set (0.00 sec) 9.使用多个表&ensp;&ensp;pet 表记录了宠物的基本信息，还需要一张表记录他们生活中的事件，如下所示 1234567891011121314mysql&gt; create table event (name varchar(20),date date,type varchar(20),remark varchar(250));Query OK, 0 rows affected (0.30 sec)mysql&gt; select * from event; +--------+------------+--------+-----------------+| name | date | type | remark |+--------+------------+--------+-----------------+| Fluffy | 1995-05-15 | litter | 4,3female,1male || Buffy | 1993-06-23 | litter | 4,3female,1male || Buffy | 1994-06-19 | litter | 4,3female,1male || Chirpy | 1999-03-19 | daily | go away || Fang | 1991-10-12 | kennel | NULL || Bowser | 1991-10-12 | kennel | NULL |+--------+------------+--------+-----------------+6 rows in set (0.00 sec) &ensp;&ensp;假设你想要得到宠物下崽的年龄。宠物的下崽日期在 event表格中，但要计算她在该日期的年龄，需要她的出生日期，该日期存储在 pet表格中。这意味着查询需要两个表： 123456789101112mysql&gt; select pet.name,timestampdiff(year,birth,date) as age,remark -&gt; from pet inner join event -&gt; on pet.name = event.name -&gt; where event.type=&apos;litter&apos;;+--------+------+-----------------+| name | age | remark |+--------+------+-----------------+| Fluffy | 3 | 4,3female,1male || Buffy | 4 | 4,3female,1male || Buffy | 5 | 4,3female,1male |+--------+------+-----------------+3 rows in set (0.00 sec) &ensp;&ensp;该FROM子句连接两个表，因为查询需要从两个表中提取信息 &ensp;&ensp;组合（连接）来自多个表的信息时，需要指定一个表中的记录如何与另一个表中的记录匹配。 &ensp;&ensp;该查询使用 INNER JOIN来组合表。只有当两个表都满足ON子句中指定的条件时，内部联接才允许其中一个表中的行出现在结果中。在这个例子中， ON子句指定 pet表中的name列必须的匹配 event表的name列 。如果名称出现在一个表中但不出现在另一个表中，则该行不会出现在结果中，因为该ON 子句中的条件失败。 &ensp;&ensp;由于该name列出现在两个表中，因此必须具体说明引用该列时的表。这是通过将表名添加到列名称来完成的。 &ensp;&ensp;如果要将表中的记录与同一表中的其他记录进行比较，有时将表连接到自身会很有用。例如，要在宠物中找到繁殖对，可以pet自身加入表格，以生成候选对： 123456789101112mysql&gt; select p1.name,p1.sex,p2.name,p2.sex,p1.species -&gt;from pet as p1 inner join pet as p2 -&gt;on p1.species = p2.species -&gt;and p1.sex = &apos;f&apos; and p1.death is null -&gt;and p2.sex = &apos;m&apos; and p2.death is null;+--------+------+-------+------+---------+| name | sex | name | sex | species |+--------+------+-------+------+---------+| Fluffy | f | Claws | m | cat || Buffy | f | Fang | m | dog |+--------+------+-------+------+---------+2 rows in set (0.00 sec) &ensp;&ensp;在此查询中，我们为表名指定别名以引用列，并保持每个列引用与表关联的表的实例。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL语句(菜鸟教程)]]></title>
    <url>%2F2019%2F02%2F02%2FMySQL%E8%AF%AD%E5%8F%A5(%E8%8F%9C%E9%B8%9F%E6%95%99%E7%A8%8B)%2F</url>
    <content type="text"><![CDATA[创建数据库语法为：CREATE DATABASE 数据库名; 12mysql&gt; create database dsq_mysql;Query OK, 1 row affected (0.01 sec) 删除数据库语法为:drop database &lt;数据库名&gt;; 12mysql&gt; drop database test;Query OK, 0 rows affected (0.00 sec) 选择数据库&ensp;&ensp;在你连接到 MySQL 数据库后，可能有多个可以操作的数据库，所以你需要选择你要操作的数据库。 123456789101112131415mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || 16netlab || dsq_mysql || mysql || performance_schema || shop |+--------------------+6 rows in set (0.00 sec)mysql&gt; use dsq_mysql;Database changed 创建数据表创建MySQL数据表需要 表名、表字段名、表字段定义:CREATE TABLE table_name (column_name column_type); 123456789101112131415161718192021mysql&gt; create table dsq_table( -&gt; dsq_id int unsigned auto_increment, -&gt; title varchar(100) not null, -&gt; name varchar(20) not null, -&gt; sex varchar(10) not null, -&gt; date DATE , -&gt; primary key(dsq_id)) -&gt; default charset=utf8;Query OK, 0 rows affected (0.14 sec)mysql&gt; desc dsq_table;+--------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+------------------+------+-----+---------+----------------+| dsq_id | int(10) unsigned | NO | PRI | NULL | auto_increment || title | varchar(100) | NO | | NULL | || name | varchar(20) | NO | | NULL | || sex | varchar(10) | NO | | NULL | || date | DATE | YES | | NULL | |+--------+------------------+------+-----+---------+----------------+5 rows in set (0.00 sec) 删除数据表语法为:DROP TABLE table_name ; 12mysql&gt; drop table test;Query OK, 0 rows affected (0.05 sec) 插入数据MySQL 表中使用 INSERT INTO SQL语句来插入数据。语法为： 123INSERT INTO table_name ( field1, field2,...fieldN ) VALUES ( value1, value2,...valueN )； 123456789mysql&gt; insert into dsq_table (title,name,sex,date) -&gt; values -&gt; (&apos;study&apos;,&apos;qwe&apos;,&apos;m&apos;,now());Query OK, 1 row affected, 1 warning (0.22 sec)mysql&gt; insert into dsq_table (title,name,sex,date) -&gt; values -&gt; (&apos;play&apos;,&apos;asd&apos;,&apos;f&apos;,&apos;2008-02-22&apos;);Query OK, 1 row affected (0.02 sec) 查询数据MySQL 数据库使用SQL SELECT语句来查询数据。 以下为在MySQL数据库中查询数据通用的 SELECT 语法： 1234SELECT column_name,column_nameFROM table_name[WHERE Clause][LIMIT N][ OFFSET M] 查询语句中可以使用一个或者多个表，表之间使用逗号(,)分割，并使用WHERE语句来设定查询条件。 SELECT 命令可以读取一条或者多条记录。 可以使用星号（*）来代替其他字段，SELECT语句会返回表的所有字段数据 可以使用 WHERE 语句来包含任何条件。 可以使用 LIMIT 属性来设定返回的记录数。 可以通过OFFSET指定SELECT语句开始查询的数据偏移量。默认情况下偏移量为0。 1234567891011121314151617mysql&gt; select * from dsq_table;+--------+-------+------+-----+------------+| dsq_id | title | name | sex | date |+--------+-------+------+-----+------------+| 1 | study | qwe | m | 2019-02-21 || 2 | play | asd | f | 2008-02-22 |+--------+-------+------+-----+------------+2 rows in set (0.00 sec)mysql&gt; select name,sex from dsq_table;+------+-----+| name | sex |+------+-----+| qwe | m || asd | f |+------+-----+2 rows in set (0.00 sec) where子句&ensp;&ensp;如需有条件地从表中选取数据，可将 WHERE 子句添加到 SELECT 语句中。语法如下: 12SELECT field1, field2,...fieldN FROM table_name1, table_name2...[WHERE condition1 [AND [OR]] condition2..... 查询语句中可以使用一个或者多个表，表之间使用逗号, 分割，并使用WHERE语句来设定查询条件。 可以在 WHERE 子句中指定任何条件。 可以使用 AND 或者 OR 指定一个或多个条件。 WHERE 子句也可以运用于 SQL 的 DELETE 或者 UPDATE 命令。 WHERE 子句类似于程序语言中的 if 条件，根据 MySQL 表中的字段值来读取指定的数据。 WHERE 子句的字符串比较是不区分大小写的。 使用 BINARY 关键字来设定 WHERE 子句的字符串比较是区分大小写的 123456789101112131415161718192021mysql&gt; select * from dsq_table -&gt; where sex = &apos;m&apos;;+--------+-------+------+-----+------------+| dsq_id | title | name | sex | date |+--------+-------+------+-----+------------+| 1 | study | qwe | m | 2019-02-21 |+--------+-------+------+-----+------------+1 row in set (0.01 sec)mysql&gt; select * from dsq_table -&gt; where binary sex = &apos;F&apos;;Empty set (0.00 sec)mysql&gt; select * from dsq_table -&gt; where dsq_id &gt; 1;+--------+-------+------+-----+------------+| dsq_id | title | name | sex | date |+--------+-------+------+-----+------------+| 2 | play | asd | f | 2008-02-22 |+--------+-------+------+-----+------------+1 row in set (0.00 sec) Update查询&ensp;&ensp;需要修改或更新 MySQL 中的数据，我们可以使用 SQL UPDATE 命令来操作 12UPDATE table_name SET field1=new-value1, field2=new-value2[WHERE Clause] 可以同时更新一个或多个字段。 可以在 WHERE 子句中指定任何条件。 可以在一个单独表中同时更新数据。 123456789101112mysql&gt; update dsq_table set name = &apos;zxc&apos;,date = &apos;2000-01-01&apos; -&gt; where dsq_id = 2;Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select * from dsq_table;+--------+-------+------+-----+------------+| dsq_id | title | name | sex | date |+--------+-------+------+-----+------------+| 1 | study | qwe | m | 2019-02-21 || 2 | play | zxc | f | 2000-01-01 |+--------+-------+------+-----+------------+2 rows in set (0.00 sec) 可以看到第二行已经更新 delect 语句&ensp;&ensp;使用 SQL 的 DELETE FROM 命令来删除 MySQL 数据表中的记录 1DELETE FROM table_name [WHERE Clause] &ensp;&ensp;如果没有指定 WHERE 子句，MySQL 表中的所有记录将被删除。 1234567891011mysql&gt; delete from dsq_table -&gt; where dsq_id = 1;Query OK, 1 row affected (0.03 sec)mysql&gt; select * from dsq_table;+--------+-------+------+-----+------------+| dsq_id | title | name | sex | date |+--------+-------+------+-----+------------+| 2 | play | zxc | f | 2000-01-01 |+--------+-------+------+-----+------------+1 row in set (0.00 sec) like子句&ensp;&ensp;有时候我们需要根据某个字符去匹配某个字段(field)中的所有记录,即模糊查询、模式匹配，这时我们就需要在 WHERE 子句中使用 SQL LIKE 子句。&ensp;&ensp; SQL LIKE 子句中使用百分号 %字符来表示任意字符，类似于UNIX或正则表达式中的星号 *。如果没有使用百分号 %, LIKE 子句与等号 = 的效果是一样的。语法为： 123SELECT field1, field2,...fieldN FROM table_nameWHERE field1 LIKE condition1 [AND [OR]] filed2 = &apos;somevalue&apos; 123456789mysql&gt; select * from dsq_table -&gt; where title like &apos;%lab&apos;;+--------+--------+------+-----+------------+| dsq_id | title | name | sex | date |+--------+--------+------+-----+------------+| 3 | netlab | dsq | f | 2019-03-25 || 4 | netlab | dsq | m | 2019-03-25 |+--------+--------+------+-----+------------+2 rows in set (0.00 sec) 排序(order by)&ensp;&ensp;如果我们需要对读取的数据进行排序，我们就可以使用 MySQL 的 ORDER BY 子句来设定按哪个字段哪种方式来进行排序，再返回搜索结果语法为： 123/*ASC 或 DESC 关键字来设置查询结果是按升序或降序排列。 默认情况下，它是按升序排列*/SELECT field1, field2,...fieldN table_name1, table_name2...ORDER BY field1, [field2...] [ASC [DESC]] &ensp;&ensp;下面读取dsq_table表，按照升序和降序的方式排列 123456789101112131415161718192021mysql&gt; select * from dsq_table -&gt; order by dsq_id;+--------+--------+------+-----+------------+| dsq_id | title | name | sex | date |+--------+--------+------+-----+------------+| 2 | play | zxc | f | 2000-01-01 || 3 | netlab | dsq | f | 2019-03-25 || 4 | netlab | dsq | m | 2019-03-25 |+--------+--------+------+-----+------------+3 rows in set (0.00 sec)mysql&gt; select * from dsq_table -&gt; order by dsq_id desc;+--------+--------+------+-----+------------+| dsq_id | title | name | sex | date |+--------+--------+------+-----+------------+| 4 | netlab | dsq | m | 2019-03-25 || 3 | netlab | dsq | f | 2019-03-25 || 2 | play | zxc | f | 2000-01-01 |+--------+--------+------+-----+------------+3 rows in set (0.00 sec) GROUP BY 语句&ensp;&ensp;GROUP BY 语句根据一个或多个列对结果集进行分组。在分组的列上我们可以使用 COUNT, SUM, AVG,等函数。&ensp;&ensp;语法为： 1234SELECT column_name, function(column_name)FROM table_nameWHERE column_name operator valueGROUP BY column_name; &ensp;&ensp;创建表emplotee_tbl，并插入数据，使用 GROUP BY 语句 将数据表按名字进行分组，并统计每个人有多少条记录 12345678910111213141516171819202122mysql&gt; SELECT * FROM employee_tbl;+----+------+---------------------+--------+| id | name | date | singin |+----+------+---------------------+--------+| 1 | ming | 2016-04-22 15:25:33 | 1 || 2 | wang | 2016-04-20 15:25:47 | 3 || 3 | li | 2016-04-19 15:26:02 | 2 || 4 | wang | 2016-04-07 15:26:14 | 4 || 5 | ming | 2016-04-11 15:26:40 | 4 || 6 | ming | 2016-04-04 15:26:54 | 2 |+----+------+---------------------+--------+6 rows in set (0.00 sec)mysql&gt; SELECT name, COUNT(*) FROM employee_tbl GROUP BY name;+------+----------+| name | COUNT(*) |+------+----------+| li | 1 || ming | 3 || wang | 2 |+------+----------+3 rows in set (0.00 sec) &ensp;&ensp;GROUP BY子句 WITH ROLLUP ，可以实现在分组统计数据基础上再进行相同的统计 123456789101112mysql&gt; select name,sum(singin) as singin_count -&gt; from employee_tbl -&gt; group by name with rollup;+------+--------------+| name | singin_count |+------+--------------+| li | 2 || ming | 7 || wang | 7 || NULL | 16 |+------+--------------+4 rows in set (0.00 sec) &ensp;&ensp;与上表相比多了一行对每人登录次数的统计,可以使用coalesce设置一个取代Null的名称语法为: 1select coalesce(a,b,c); &ensp;&ensp;返回第一个非零参数或者NULL（Returns the first non-NULL value in the list, or NULL if there are no non-NULL values.） 12345678910111213141516171819202122232425262728mysql&gt; SELECT COALESCE(NULL,1);+------------------+| COALESCE(NULL,1) |+------------------+| 1 |+------------------+1 row in set (0.03 sec)mysql&gt; SELECT COALESCE(NULL,null,null);+--------------------------+| COALESCE(NULL,NULL,NULL) |+--------------------------+| NULL |+--------------------------+1 row in set (0.00 sec)mysql&gt; select coalesce(name,&apos;total&apos;),sum(singin) as singin_count -&gt; from employee_tbl -&gt; group by name with rollup;+------------------------+--------------+| coalesce(name,&apos;total&apos;) | singin_count |+------------------------+--------------+| li | 2 || ming | 7 || wang | 7 || total | 16 |+------------------------+--------------+4 rows in set (0.00 sec) MySQL连接表&ensp;&ensp;可以在 SELECT, UPDATE 和 DELETE 语句中使用 Mysql 的 JOIN 来联合多表查询。&ensp;&ensp;JOIN 按照功能大致分为如下三类： INNER JOIN（内连接,或等值连接）：两边表同时有对应的数据，即任何一边缺失数据就不显示。 LEFT JOIN（左连接）：获取左表所有记录，即使右表没有对应匹配的记录。 RIGHT JOIN（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。 有如下两个表： 12345678910111213141516171819202122mysql&gt; select * from dsq_tbl;+----+-------+--------+------------+| id | title | author | date |+----+-------+--------+------------+| 1 | qwe | 1 | 2000-01-01 || 2 | rty | 2 | 2000-01-02 || 3 | uiop | 1 | 2000-01-03 || 4 | asd | 3 | 2000-01-04 || 5 | fghj | 2 | 2000-01-05 || 6 | kl | 4 | 2000-01-06 |+----+-------+--------+------------+6 rows in set (0.00 sec)mysql&gt; select * from dsq_tbl2;+--------+-------+| author | stars |+--------+-------+| 1 | 20 || 2 | 35 || 3 | 47 |+--------+-------+3 rows in set (0.00 sec) &ensp;&ensp;接下来使用 inner join(也可以省略 inner 使用 join，效果一样)来连接两张表并显示 12345678910111213mysql&gt; select * from dsq_tbl inner join dsq_tbl2 -&gt; on dsq_tbl.author = dsq_tbl2.author;+----+-------+--------+------------+--------+-------+| id | title | author | date | author | stars |+----+-------+--------+------------+--------+-------+| 1 | qwe | 1 | 2000-01-01 | 1 | 20 || 2 | rty | 2 | 2000-01-02 | 2 | 35 || 3 | uiop | 1 | 2000-01-03 | 1 | 20 || 4 | asd | 3 | 2000-01-04 | 3 | 47 || 5 | fghj | 2 | 2000-01-05 | 2 | 35 |+----+-------+--------+------------+--------+-------+5 rows in set (0.00 sec)以上语句等价于 select * from dsq_tbl,dsq_tbl2 WHERE dsq_tbl.author = dsq_tbl2.author; &ensp;&ensp;left join 与 join 有所不同。 left join 会读取左边数据表的全部数据，即便右边表无对应数据 12345678910111213mysql&gt; select * from dsq_tbl left join dsq_tbl2 -&gt; on dsq_tbl.author = dsq_tbl2.author;+----+-------+--------+------------+--------+-------+| id | title | author | date | author | stars |+----+-------+--------+------------+--------+-------+| 1 | qwe | 1 | 2000-01-01 | 1 | 20 || 3 | uiop | 1 | 2000-01-03 | 1 | 20 || 2 | rty | 2 | 2000-01-02 | 2 | 35 || 5 | fghj | 2 | 2000-01-05 | 2 | 35 || 4 | asd | 3 | 2000-01-04 | 3 | 47 || 6 | kl | 4 | 2000-01-06 | NULL | NULL |+----+-------+--------+------------+--------+-------+6 rows in set (0.00 sec) &ensp;&ensp;right join 会读取右边数据表的全部数据，即便左边边表无对应数据。 1234567891011mysql&gt; select * from dsq_tbl right join dsq_tbl2 on dsq_tbl.author = dsq_tbl2.author;+------+-------+--------+------------+--------+-------+| id | title | author | date | author | stars |+------+-------+--------+------------+--------+-------+| 1 | qwe | 1 | 2000-01-01 | 1 | 20 || 2 | rty | 2 | 2000-01-02 | 2 | 35 || 3 | uiop | 1 | 2000-01-03 | 1 | 20 || 4 | asd | 3 | 2000-01-04 | 3 | 47 || 5 | fghj | 2 | 2000-01-05 | 2 | 35 |+------+-------+--------+------------+--------+-------+5 rows in set (0.00 sec) 下面为一个left join 的应用场景 1234567891011121314151617181920查找所有员工的last_name和first_name以及对应部门编号dept_no，也包括展示没有分配具体部门的员工CREATE TABLE `dept_emp` (`emp_no` int(11) NOT NULL,`dept_no` char(4) NOT NULL,`from_date` date NOT NULL,`to_date` date NOT NULL,PRIMARY KEY (`emp_no`,`dept_no`));CREATE TABLE `employees` (`emp_no` int(11) NOT NULL,`birth_date` date NOT NULL,`first_name` varchar(14) NOT NULL,`last_name` varchar(16) NOT NULL,`gender` char(1) NOT NULL,`hire_date` date NOT NULL,PRIMARY KEY (`emp_no`));解：select e.last_name,e.first_name,d.dept_nofrom employees as e left join dept_emp as don e.emp_no = d.emp_no https://www.cnblogs.com/leochenliang/p/7364665.html（left join on and 与 left join on where的区别） 关于NULL值运算符操作： IS NULL: 当列的值是 NULL,此运算符返回 true。 IS NOT NULL: 当列的值不为 NULL, 运算符返回 true。 &lt;=&gt;: 比较操作符（不同于=运算符），当比较的的两个值为 NULL 时返回 true。 &ensp;&ensp;关于 NULL 的条件比较运算是比较特殊的。你不能使用 = NULL 或 != NULL 在列中查找 NULL 值 。在 MySQL 中，NULL 值与任何其它值的比较（即使是 NULL）永远返回 false，即 NULL = NULL 返回false 。MySQL 中处理 NULL 使用 IS NULL 和 IS NOT NULL 运算符。 12select * , columnName1 + ifnull(columnName2,0) from tableName;columnName1，columnName2 为 int 型，当 columnName2 中，有值为 null 时，columnName1+columnName2=null， ifnull(columnName2,0) 把 columnName2 中 null 值转为 0。 &ensp;&ensp;下面为一个left jion 与 null值判断的组合使用 123456789101112131415161718192021获取所有非manager的员工emp_noCREATE TABLE `dept_manager` (`dept_no` char(4) NOT NULL,`emp_no` int(11) NOT NULL,`from_date` date NOT NULL,`to_date` date NOT NULL,PRIMARY KEY (`emp_no`,`dept_no`));CREATE TABLE `employees` (`emp_no` int(11) NOT NULL,`birth_date` date NOT NULL,`first_name` varchar(14) NOT NULL,`last_name` varchar(16) NOT NULL,`gender` char(1) NOT NULL,`hire_date` date NOT NULL,PRIMARY KEY (`emp_no`));解：先使用LEFT JOIN连接两张表，再从此表中选出dept_no值为NULL对应的emp_no记录select e.emp_nofrom employees e left join dept_manager don e.emp_no = d.emp_nowhere d.emp_no is null; ALTER&ensp;&ensp;修改数据表名或者修改数据表字段时，需要使用到MySQL ALTER命令 1.删除，添加或修改表字段&ensp;&ensp;如果数据表中只剩余一个字段则无法使用DROP来删除字段 1234567891011121314151617181920212223242526mysql&gt; describe dsq_table;+--------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+------------------+------+-----+---------+----------------+| dsq_id | int(10) unsigned | NO | PRI | NULL | auto_increment || title | varchar(100) | NO | | NULL | || name | varchar(20) | NO | | NULL | || sex | varchar(10) | NO | | NULL | || date | date | YES | | NULL | |+--------+------------------+------+-----+---------+----------------+5 rows in set (0.00 sec)mysql&gt; alter table dsq_table drop sex;Query OK, 0 rows affected (0.56 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; describe dsq_table;+--------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+------------------+------+-----+---------+----------------+| dsq_id | int(10) unsigned | NO | PRI | NULL | auto_increment || title | varchar(100) | NO | | NULL | || name | varchar(20) | NO | | NULL | || date | date | YES | | NULL | |+--------+------------------+------+-----+---------+----------------+4 rows in set (0.00 sec) &ensp;&ensp;添加列，并定义字段数据类型 123456789101112131415mysql&gt; alter table dsq_table add sex varchar(5);Query OK, 0 rows affected (0.28 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; describe dsq_table;+--------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+------------------+------+-----+---------+----------------+| dsq_id | int(10) unsigned | NO | PRI | NULL | auto_increment || title | varchar(100) | NO | | NULL | || name | varchar(20) | NO | | NULL | || date | date | YES | | NULL | || sex | varchar(5) | YES | | NULL | |+--------+------------------+------+-----+---------+----------------+5 rows in set (0.00 sec) &ensp;&ensp;如果需要指定新增字段的位置，可以使用MySQL提供的关键字 FIRST (设定位第一列)， AFTER 字段名（设定位于某个字段之后） 12345678910111213141516mysql&gt; alter table dsq_table add hobby varchar(100) after name;Query OK, 0 rows affected (0.28 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; describe dsq_table;+--------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+------------------+------+-----+---------+----------------+| dsq_id | int(10) unsigned | NO | PRI | NULL | auto_increment || title | varchar(100) | NO | | NULL | || name | varchar(20) | NO | | NULL | || hobby | varchar(100) | YES | | NULL | || date | date | YES | | NULL | || sex | varchar(5) | YES | | NULL | |+--------+------------------+------+-----+---------+----------------+6 rows in set (0.01 sec) 2.修改字段类型及名称如果需要修改字段类型及名称, 你可以在ALTER命令中使用 MODIFY 或 CHANGE 子句语法为： 12ALTER TABLE testalter_tbl MODIFY c CHAR(10); #把字段 c 的类型从 CHAR(1) 改为 CHAR(10)ALTER TABLE testalter_tbl CHANGE j i INT; #把字段 j 的名称变为 i ，类型为 INT 3.关于Null 值和默认值&ensp;&ensp;如果不设置默认值，MySQL会自动设置该字段默认为 NULL，如下所示 12345678910mysql&gt; describe dsq_tbl;+--------+----------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+----------------------+------+-----+---------+----------------+| id | smallint(5) unsigned | NO | PRI | NULL | auto_increment || title | varchar(20) | YES | | NULL | || author | varchar(20) | YES | | NULL | || date | date | YES | | NULL | |+--------+----------------------+------+-----+---------+----------------+4 rows in set (0.00 sec) &ensp;&ensp;当进行修改字段时，可以指定是否包含值或者是否设置默认值。需要设置not null ，默认值才会有效。语法为 ： 12mysql&gt; ALTER TABLE tablename -&gt; MODIFY col_name column_definition NOT NULL DEFAULT ***; &ensp;&ensp;如下，将字段date 默认值更改为当前日期 1234567891011121314mysql&gt; alter table dsq_tbl modify date timestamp not null default CURRENT_timestamp;Query OK, 8 rows affected (0.34 sec)Records: 8 Duplicates: 0 Warnings: 0mysql&gt; describe dsq_tbl;+--------+----------------------+------+-----+-------------------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+----------------------+------+-----+-------------------+----------------+| id | smallint(5) unsigned | NO | PRI | NULL | auto_increment || title | varchar(20) | YES | | NULL | || author | varchar(20) | YES | | NULL | || date | timestamp | NO | | CURRENT_TIMESTAMP | |+--------+----------------------+------+-----+-------------------+----------------+4 rows in set (0.00 sec) 4.修改字段默认值语法为： 1ALTER TABLE tbl_name ALTER col_name &#123;SET DEFAULT literal | DROP DEFAULT&#125; 1234567891011121314151617181920212223242526272829mysql&gt; alter table dsq_tbl alter author set default 10;Query OK, 0 rows affected (0.03 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; describe dsq_tbl;+--------+----------------------+------+-----+-------------------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+----------------------+------+-----+-------------------+----------------+| id | smallint(5) unsigned | NO | PRI | NULL | auto_increment || title | varchar(20) | YES | | NULL | || author | varchar(20) | YES | | 10 | || date | timestamp | NO | | CURRENT_TIMESTAMP | |+--------+----------------------+------+-----+-------------------+----------------+4 rows in set (0.00 sec)mysql&gt; alter table dsq_tbl alter author drop default;Query OK, 0 rows affected (0.03 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; describe dsq_tbl;+--------+----------------------+------+-----+-------------------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+----------------------+------+-----+-------------------+----------------+| id | smallint(5) unsigned | NO | PRI | NULL | auto_increment || title | varchar(20) | YES | | NULL | || author | varchar(20) | YES | | NULL | || date | timestamp | NO | | CURRENT_TIMESTAMP | |+--------+----------------------+------+-----+-------------------+----------------+4 rows in set (0.01 sec) 5.修改表名&ensp;&ensp;如果需要修改表名，可以在 ALTER TABLE 语句中使用 RENAME 子句 ，或者RENAME TABLE语句 语法： 123RENAME TABLE tbl_name TO new_tbl_name [, tbl_name2 TO new_tbl_name2] ... &ensp;&ensp;RENAME TABLE重命名一个或多个表。但是必须具有ALTER与 DROP原始表的权限，以及CREATE与 INSERT新表的权限 123RENAME TABLE old_table TO new_table;等价于ALTER TABLE old_table RENAME new_table; &ensp;&ensp;RENAME TABLE 与 ALTER TABLE 的不同在于，RENAME TABLE 可以在一个语句中重命名多个表 1234交换两个表的名称RENAME TABLE old_table TO tmp_table, new_table TO old_table, tmp_table TO new_table； &ensp;&ensp;使用RENAME TABLE将表从一个数据库移动到另一个数据库： 1RENAME TABLE current_db.tbl_name TO other_db.tbl_name; 表的显示在进入MYSQL时，提示的第二行有这样一句话” Commands end with ; or \g.” 123456789mysql&gt; select * from dsq_table \g+--------+--------+------+-------+------------+------+| dsq_id | title | name | hobby | date | sex |+--------+--------+------+-------+------------+------+| 2 | play | zxc | NULL | 2000-01-01 | NULL || 3 | netlab | dsq | NULL | 2019-03-25 | NULL || 4 | netlab | dsq | NULL | 2019-03-25 | NULL |+--------+--------+------+-------+------------+------+3 rows in set (0.00 sec) 123456789101112131415161718192021222324使用 \G 是垂直显示结果(ego (\G) Send command to mysql server, display result vertically.)。mysql&gt; select * from dsq_table \G*************************** 1. row ***************************dsq_id: 2 title: play name: zxc hobby: NULL date: 2000-01-01 sex: NULL*************************** 2. row ***************************dsq_id: 3 title: netlab name: dsq hobby: NULL date: 2019-03-25 sex: NULL*************************** 3. row ***************************dsq_id: 4 title: netlab name: dsq hobby: NULL date: 2019-03-25 sex: NULL3 rows in set (0.00 sec)]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL建库建表、数据插入]]></title>
    <url>%2F2019%2F01%2F29%2FMySQL%E5%BB%BA%E5%BA%93%E5%BB%BA%E8%A1%A8%E3%80%81%E6%95%B0%E6%8D%AE%E6%8F%92%E5%85%A5%2F</url>
    <content type="text"><![CDATA[连接与断开服务器123456789101112131415[root@docker-study var]# mysql --host=hostname --user=user --passwordEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 37Server version: 5.6.43 MySQL Community Server (GPL)Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; 输入查询&ensp;&ensp;介绍几个输入查询的基本原则来熟悉mysql的工作原理。&ensp;&ensp;这是一个简单的查询，要求服务器说明它的版本号和当前日期。 123456789mysql&gt; SELECT VERSION(), CURRENT_DATE;+-----------+--------------+| VERSION() | CURRENT_DATE |+-----------+--------------+| 5.6.43 | 2019-02-18 |+-----------+--------------+1 row in set (0.00 sec)mysql&gt; &ensp;&ensp;关键字可以输入任何字母。以下查询是等效的，即不区分大小写： 123mysql&gt; SELECT VERSION(), CURRENT_DATE;mysql&gt; select version(), current_date;mysql&gt; SeLeCt vErSiOn(), current_DATE; &ensp;&ensp;这是另一个查询。它演示了您可以将 mysql用作简单的计算器： 1234567mysql&gt; SELECT SIN(PI()/4), (4+1)*5;+------------------+---------+| SIN(PI()/4) | (4+1)*5 |+------------------+---------+| 0.70710678118655 | 25 |+------------------+---------+1 row in set (0.02 sec) &ensp;&ensp;到目前为止显示的查询是相对较短的单行语句。也可以在一行中输入多个语句。用分号结束每一个： 1234567891011121314mysql&gt; SELECT VERSION(); SELECT NOW();+-----------+| VERSION() |+-----------+| 5.6.43 |+-----------+1 row in set (0.00 sec)+---------------------+| NOW() |+---------------------+| 2019-02-18 11:01:14 |+---------------------+1 row in set (0.00 sec) &ensp;&ensp;多行的冗长查询不是问题,mysql通过查找终止分号来确定语句的结束位置，而不是查找输入行的结尾。这是一个简单的多行语句： 12345678910mysql&gt; select -&gt; user() -&gt; , -&gt; current_date;+----------------+--------------+| user() | current_date |+----------------+--------------+| web@172.19.0.3 | 2019-02-18 |+----------------+--------------+1 row in set (0.00 sec) &ensp;&ensp;如果决定不想执行正在输入的查询，请键入\c以下命令取消它 ： 1234mysql&gt; SELECT -&gt; USER() -&gt; \cmysql&gt; &ensp;&ensp;在这里，也请注意提示。它会mysql&gt;在键入后切换回来 \c，提供反馈以指示mysql已为新查询做好准备。&ensp;&ensp;下表显示了可能看到的每个提示，并总结了它们对mysql所处状态的含义 。 提示 含义 mysql&gt; 准备好进行新查询 -&gt; 等待下一行的多行查询 ‘&gt; 等待下一行，以单引号（’）开头的字符串 “&gt; 等待下一行，以双引号开头的字符串（”） `&gt; 等待下一行，以反引号（`）开头的标识符 /*&gt; 等待下一行，以/*开头的描述 &ensp;&ensp;在MySQL中，可以编写由任一字符’或”字符包括的字符串（例如’hello’或”goodbye”),并且 mysql允许输入跨越多行的字符串。看到’&gt;或 “&gt;提示时，表示输入的行包含以a ‘ 或”quote字符开头的字符串，但没有输入终止字符串的匹配引号。这通常表明遗漏了引号字符。例如： 12mysql&gt; SELECT * FROM my_table WHERE name = &apos;Smith AND age &lt; 30; &apos;&gt; &ensp;&ensp;通过转义字符取消查询，如果只输入\c，会被认为是引号内的内容 123mysql&gt; SELECT * FROM my_table WHERE name = &apos;Smith AND age &lt; 30; &apos;&gt; &apos;\cmysql&gt; &ensp;&ensp;`&gt;提示类似于 ‘&gt;和”&gt;提示，但表示你已经开始但尚未完成反引号引用的标识符。 创建数据库12mysql&gt; CREATE DATABASE 16netlab;Query OK, 1 row affected (0.01 sec) &ensp;&ensp;在Unix下，数据库名称是区分大小写的（不像SQL关键字）。表名也是如此。（在Windows下，此限制不适用，但必须在给定查询中使用相同的字母表引用数据库和表。但是，出于各种原因，建议的最佳做法始终是使用相同字母。）注意 如果收到错误 ERROR 1044（42000）：ERROR 1044 (42000): Access denied for user ‘micah‘@’localhost’ to database ‘menagerie’，这意味着用户帐户没有必要的权限。 &ensp;&ensp;要使16netlab为当前数据库，请使用以下语句： 12mysql&gt; use 16netlab;Database changed &ensp;&ensp;数据库只需创建一次，但每次开始mysql 会话时都必须选择它才能使用。通过如上所示的语句来完成此操作。或者可以在调用mysql时在命令行上选择数据库。需要提供的所有连接参数之后指定其名称。例如： 123456789101112131415[root@docker-study ~]# docker exec -it web mysql -h mysql2 -u web -p 16netlabEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 348Server version: 5.6.43 MySQL Community Server (GPL)Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; &ensp;&ensp; SELECT DATABASE() 查看当前选择使用哪个数据库 123456789mysql&gt; SELECT DATABASE();+------------+| DATABASE() |+------------+| 16netlab |+------------+1 row in set (0.00 sec)mysql&gt; 创建表&ensp;&ensp;创建数据库很容易，但此时它是空的 12mysql&gt; SHOW TABLES;Empty set (0.00 sec) &ensp;&ensp;更难的部分是决定数据库的结构应该是什么：需要哪些表以及每个表中应该包含哪些列。&ensp;&ensp;例如一张包含每只宠物记录的表格。这可以称为pet表格，它应该包含每个动物名称以及长度限制值。如果家中有多个人饲养宠物，列出每只动物的主人，记录一些基本的描述性信息，如物种和性别，年龄。随着时间的推移，年龄会发生变化，这意味着必须经常更新记录。相反，最好存储固定值，如出生日期。如果需要年龄，可以将其计算为当前日期和出生日期之间的差异。MySQL提供了进行日期算术的功能。 &ensp;&ensp;你可能会想到在pet表格中有用的其他类型的信息，但到目前为止确定的信息是足够的：名称，所有者，物种，性别，出生和死亡日期。&ensp;&ensp;使用CREATE TABLE语句指定表的布局： 123mysql&gt; CREATE TABLE pet (name VARCHAR(20), owner VARCHAR(20), -&gt; species VARCHAR(20), sex CHAR(1), birth DATE, death DATE);Query OK, 0 rows affected (0.20 sec) &ensp;&ensp;VARCHAR数据类型对于name、 owner和species 列是不错的选择，因为列值的长度不同。定义列的长度时根据实际情况合理选择。通常，可以选择1-65535中的任何长度。 &ensp;&ensp;可以选择几种类型的值来表示动物记录中的性别，例如’m’和 ‘f’，或者可能’male’和 ‘female’。最简单的是使用单个字符’m’和’f’。DATE对于birth和death 列 使用数据类型是一个相当明显的选择。&ensp;&ensp;创建表后，SHOW TABLES应该产生一些输出： 1234567mysql&gt; SHOW TABLES;+--------------------+| Tables_in_16netlab |+--------------------+| pet |+--------------------+1 row in set (0.00 sec) &ensp;&ensp;要验证表是否按预期方式创建，使用DESCRIBE语句： 1234567891011121314mysql&gt; describe pet;+---------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------+-------------+------+-----+---------+-------+| name | varchar(20) | YES | | NULL | || owner | varchar(20) | YES | | NULL | || species | varchar(20) | YES | | NULL | || sex | char(1) | YES | | NULL | || birth | date | YES | | NULL | || death | date | YES | | NULL | |+---------+-------------+------+-----+---------+-------+6 rows in set (0.00 sec)mysql&gt; 添加数据到表&ensp;&ensp;创建表后需要填充它。使用LOAD DATA和 INSERT语句&ensp;&ensp;假设宠物记录可以如此处所示。 名字 主人 种类 性别 出生日期 死亡日期 Fluffy Harold cat f 1993-02-04 Claws Gwen cat m 1994-03-17 Buffy Harold dog f 1989-05-13 Fang Benny dog m 1990-08-27 Bowser Diane dog m 1979-08-31 1995-07-29 Chirpy Gwen bird f 1998-09-11 Whistler Gwen bird 1997-12-09 Slim Benny snake m 1996-04-29 &ensp;&ensp;因为从空表开始，所以填充它的一种简单方法是为每个动物创建一个包含行的文本文件，然后使用单个语句将文件内容加载到表中。 &ensp;&ensp;可以创建一个文本文件pet.txt，每行包含一个记录，其值由制表符分隔，并按照CREATE TABLE语句中列出的顺序给出 。对于缺失值（例如未知性别或仍然生活的动物的死亡日期），可以使用NULL 值。要在文本文件中表示这些，请使用 \N（反斜杠，大写-N）。例如，惠斯勒鸟的记录看起来像这样（值之间的空格是单个制表符）： 1Whistler Gwen bird \N 1997-12-09 \N &ensp;&ensp;要将文本文件加载pet.txt到 pet表中，请使用以下语句： 1mysql&gt; LOAD DATA LOCAL INFILE &apos;/path/pet.txt&apos; INTO TABLE pet; &ensp;&ensp;如果需要，可以在LOAD DATA语句中显式指定列值分隔符和行结束标记，但默认值为制表符和换行符。这些语句正确读取pet.txt。 &ensp;&ensp;如果语句失败，则默认情况下MySQL安装可能没有启用本地文件功能。 &ensp;&ensp;如果要一次添加一条新记录，该 INSERT语句很有用。在最简单的形式中，按照CREATE TABLE语句中列出的列的顺序为每列提供值 。假设黛安得到了一只名为“ Puffball ”的仓鼠。可以使用如下INSERT语句添加 ： 12345678910111213141516171819202122232425262728293031323334mysql&gt; INSERT INTO pet VALUES (&apos;Puffball&apos;,&apos;Diane&apos;,&apos;hamster&apos;,&apos;f&apos;,&apos;1999-03-30&apos;,NULL);字符串和日期值在此处指定为带引号的字符串。此外，可以直接插入NULL 以表示缺失值。mysql&gt; INSERT INTO pet -&gt; VALUES (&apos;Fluffy&apos;,&apos;Harold&apos;,&apos;cat&apos;,&apos;f&apos;,&apos;1999-02-04&apos;,NULL);Query OK, 1 row affected (0.02 sec)mysql&gt; INSERT INTO pet VALUES (&apos;Claws&apos;,&apos;Gwen&apos;,&apos;cat&apos;,&apos;m&apos;,&apos;1994-03-17&apos;,NULL);Query OK, 1 row affected (0.03 sec)mysql&gt; INSERT INTO pet VALUES (&apos;Buffy&apos;,&apos;Harold&apos;,&apos;dog&apos;,&apos;f&apos;,&apos;1989-05-13&apos;,NULL);Query OK, 1 row affected (0.03 sec)mysql&gt; INSERT INTO pet VALUES (&apos;Fang&apos;,&apos;Benny&apos;,&apos;dog&apos;,&apos;m&apos;,&apos;1990-08-27&apos;,NULL);Query OK, 1 row affected (0.06 sec)mysql&gt; INSERT INTO pet VALUES (&apos;Bowser&apos;,&apos;Diane&apos;,&apos;dog&apos;,&apos;m&apos;,&apos;1979-08-31&apos;,&apos;1995-07-29&apos;);Query OK, 1 row affected (0.03 sec)mysql&gt; INSERT INTO pet VALUES (&apos;Chirpy&apos;,&apos;Genw&apos;,&apos;bird&apos;,&apos;f&apos;,&apos;1998-09-11&apos;,null);Query OK, 1 row affected (0.42 sec)mysql&gt; SELECT * FROM pet;+--------+--------+---------+------+------------+------------+| name | owner | species | sex | birth | death |+--------+--------+---------+------+------------+------------+| Fluffy | Harold | cat | f | 1999-02-04 | NULL || Claws | Gwen | cat | m | 1994-03-17 | NULL || Buffy | Harold | dog | f | 1989-05-13 | NULL || Fang | Benny | dog | m | 1990-08-27 | NULL || Bowser | Diane | dog | m | 1979-08-31 | 1995-07-29 || Chirpy | Genw | bird | f | 1998-09-11 | NULL |+--------+--------+---------+------+------------+------------+6 rows in set (0.00 sec)]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Docker在linux上部署MySQL]]></title>
    <url>%2F2019%2F01%2F25%2F%E4%BD%BF%E7%94%A8Docker%E5%9C%A8linux%E4%B8%8A%E9%83%A8%E7%BD%B2MySQL%2F</url>
    <content type="text"><![CDATA[下载MySQL服务器Docker镜像使用命令下载MYSQL-Community： 1docker pull mysql/mysql-server:tag &nbsp;&nbsp;&nbsp;tag是你想拉的镜像版本的标签（例如5.5， 5.6，5.7， 8.0，或latest）。如果省略则会下载最新GA版本的MySQL-community-server的镜像。 12345678[root@docker-study ~]# docker pull mysql/mysql-server:5.65.6: Pulling from mysql/mysql-servera8d84c1f755a: Pull complete 36934cee5f0d: Pull complete 5a6871e55c04: Pull complete 7c67030deb6e: Pull complete Digest: sha256:5a1cfc50ab8d147cb163c32558c7334519f5bb69ea82587d480f9f7050b77047Status: Downloaded newer image for mysql/mysql-server:5.6 &nbsp;&nbsp;使用以下命令列出下载的Docker镜像： 1234[root@docker-study ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEmysql/mysql-server 5.6 ad62049ce4ab 6 weeks ago 217MB[root@docker-study ~]# 启动MySQL服务器实例&nbsp;&nbsp;&nbsp;将MySQL镜像启动为容器： 123[root@docker-study ~]# docker run --name=mysql1 -d mysql/mysql-server:5.6321d33b946e7eb8ebea4fe829d1cfb953c6dd5663021088fb9cff21bcea2a112[root@docker-study ~]# &nbsp;&nbsp;&nbsp;&nbsp;–name用于为容器提供自定义名称，该选项是可选的;，如果没有提供容器名称，则生成随机的名称。如果先前的docker pull或docker run 命令未下载指定名称和标记的镜像， 则现在下载该图像。下载完成后，开始初始化容器，并在运行docker ps命令时容器显示在正在运行的容器列表中 ; 例如： 1234[root@docker-study ~]# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES321d33b946e7 mysql/mysql-server:5.6 &quot;/entrypoint.sh mysq…&quot; 3 minutes ago Up 3 minutes (healthy) 3306/tcp mysql1[root@docker-study ~]# &nbsp;&nbsp;&nbsp;初始化完成后，命令的输出将包含为root用户生成的随机密码; 例如，使用以下命令检查密码： 123[root@docker-study ~]# docker logs mysql1 2&gt;&amp;1 | grep GENERATED[Entrypoint] GENERATED ROOT PASSWORD: mOkuHorEKBEh4plym@KYsXYk%Ih[root@docker-study ~]# 连接到Container内的MySQL服务器&nbsp;&nbsp;&nbsp;&nbsp;服务器准备就绪后，可以在刚刚启动的MySQL Server容器中运行 mysql客户端，并将其连接到MySQL服务器。使用docker exec -it命令在已启动的Docker容器中进入 mysql客户端，输入生成的root密码。因为MYSQL_ONETIME_PASSWORD 默认情况下该选项为true，所以在将mysql客户端连接 到服务器之后，重置服务器root密码，如下所示。 12345678910111213141516[root@docker-study ~]# docker exec -it mysql1 mysql -uroot -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 50Server version: 5.6.43Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; SET PASSWORD FOR &apos;root&apos;@&apos;localhost&apos; = PASSWORD(&apos;123456&apos;);Query OK, 0 rows affected (0.00 sec) 容器shell访问&nbsp;&nbsp;&nbsp;要使用shell访问MySQL Server容器，请使用 docker exec -it命令在容器内启动bash shell： 12[root@docker-study ~]# docker exec -it mysql1 bashbash-4.2# &nbsp;&nbsp;&nbsp;然后可以在容器内运行Linux命令。例如，要查看容器内server数据目录中的内容 123bash-4.2# ls /var/lib/mysqlauto.cnf ib_logfile0 ib_logfile1 ibdata1 mysql mysql.sock performance_schema testbash-4.2# 停止和删除MySQL容器&nbsp;&nbsp;&nbsp;使用以下命令停止创建的MySQL Server容器： 123[root@docker-study ~]# docker stop mysql1mysql1[root@docker-study ~]# &nbsp;&nbsp;&nbsp;docker stop向 mysqld进程发送SIGTERM信号 ，以便正常关闭服务器。 &nbsp;&nbsp;&nbsp;另请注意，当容器的主进程（MySQL服务器容器中的mysqld）停止时，Docker容器会自动停止。 123456789101112要再次启动MySQL Server容器：docker start mysql1使用单个命令停止并重新启动MySQL Server容器：docker restart mysql1要删除MySQL容器，请先将其停止，然后使用 docker rm命令：docker stop mysql1docker rm mysql1如果希望同时删除服务器数据目录的 Docker卷，请将该-v选项添加到 docker rm命令。docker rm -v mysql1 配置MySQL服务器&nbsp;&nbsp;&nbsp;启动MySQL Docker容器时，可以通过docker run命令将配置选项传递给服务器; 例如，对于MySQL服务器： 123[root@docker-study ~]# docker run --name mysql1 -d mysql/mysql-server:5.6 --character-set-server=utf8mb4 --collation-server=utf8mb4_colae491dde8ad07c8db420facc6a7b6546b3ae375d7e37430e4a01a6b4c34913f3[root@docker-study ~]# &nbsp;&nbsp;&nbsp;该命令启动MySQL服务器 utf8mb4作为默认字符集和 utf8mb4_col数据库的默认排序规则。 &nbsp;&nbsp;&nbsp;配置MySQL服务器的另一种方法是准备配置文件并将其安装在容器内的服务器配置文件的位置。 持久化数据和配置更改&nbsp;&nbsp;&nbsp;Docker容器原则上是短暂的，如果容器被删除或损坏，预计会丢失任何数据或配置。 但是，Docker卷提供了一种机制来保存在Docker容器中创建的数据。在初始化时，MySQL Server容器为服务器数据目录创建一个Docker卷。在容器上运行docker inspect命令的JSON输出有一个 Mount键，其值提供有关数据目录卷的信息： 123456789101112131415[root@docker-study ~]# docker inspect mysql1[………… &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;4ae57cb3823bf75c18b2212530fee42bc7d851446a5fee48406542c04df62221&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/4ae57cb3823bf75c18b2212530fee42bc7d851446a5fee48406542c04df62221/_data&quot;, &quot;Destination&quot;: &quot;/var/lib/mysql&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ],………… &nbsp;&nbsp;&nbsp;输出显示/var/lib/docker/volumes/4ae57cb3823bf75c18b2212530fee42bc7d851446a5fee48406542c04df62221/_data主机文件夹（主机上持有数据）已安装在 /var/lib/mysql容器内的服务器数据目录中。 &nbsp;&nbsp;&nbsp;保留数据的另一种方法是 在创建容器时 使用–mount绑定安装主机目录。可以使用相同的技术来持久保存服务器的配置。以下命令创建MySQL Server容器并绑定安装数据目录和服务器配置文件： 1234567891011121314151617181920212223[root@docker-study ~]# lsanaconda-ks.cfg datadir docker initial-setup-ks.cfg my.cnf src[root@docker-study ~]# cat my.cnf [client]default-character-set=utf8socket = /usr/local/mysql/mysql.sock[mysql]default-character-set=utf8[mysqld]basedir = /usr/local/mysqldatadir = /var/lib/mysqlport = 3306socket = /usr/local/mysql/mysql.sockcharacter-set-server=utf8sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES[root@docker-study ~]# docker run --name=mysql1 \--mount type=bind,src=/root/my.cnf,dst=/etc/my.cnf \--mount type=bind,src=/root/datadir,dst=/var/lib/mysql \-d mysql/mysql-server:5.658d707e7a9f75b38516d17dc54ee3685e00052969c01c887b40f0ac8f819a936[root@docker-study ~]# ls datadir/ibdata1 ib_logfile0 ib_logfile1 mysql performance_schema test[root@docker-study ~]# &nbsp;&nbsp;&nbsp;安装 path-on-host-machine/my.cnf 到/etc/my.cnf（容器内部的配置文件），同时 path-on-host-machine/datadir 到/var/lib/mysql（数据容器内的目录）。必须满足以下条件才能使绑定安装正常工作： &nbsp;&nbsp;&nbsp;配置文件 path-on-host-machine/my.cnf 必须已存在，并且必须包含使用用户启动mysql服务器的规范： 123[mysqld]user=mysql………… &nbsp;&nbsp;&nbsp;数据目录 path-on-host-machine/datadir 必须已存在。要进行服务器初始化，目录必须为空。还可以安装预先填充数据的目录并启动服务器; 但是必须确保使用与创建数据的服务器相同的配置来启动Docker容器，并在启动容器时装入所需的任何主机文件或目录。 运行其他初始化脚本如果在创建数据库后立即要在数据库上运行任何.sh或 .sql脚本，则可以将它们放入主机目录，然后将目录 /docker-entrypoint-initdb.d/挂载在容器内部。例如，对于MySQL Server容器： 123docker run --name=mysql1 \--mount type=bind,src=/path-on-host-machine/scripts/,dst=/docker-entrypoint-initdb.d/ \-d mysql/mysql-server:tag 从另一个Docker容器中的应用程序连接到MySQL&nbsp;&nbsp;&nbsp;通过设置Docker网络，您可以允许多个Docker容器相互通信，以便另一个Docker容器中的客户端应用程序可以访问服务器容器中的MySQL Server。首先，创建一个Docker网络： 123[root@docker-study ~]# docker network create my-custom-nete78c79012d0e865acc06f043f03e9a900a5a478780fc0d7fb30a82ae0c644303[root@docker-study ~]# &nbsp;&nbsp;&nbsp;然后，在创建和启动服务器和客户端容器时，使用该–network选项将它们放在您创建的网络上。例如： 12345[root@docker-study ~]# docker run --name=mysql2 --network=my-custom-net -d mysql/mysql-server:5.680415ae4ba16a3e89f3b7afc5d1f4ffde028fc65a66ff7f03810828070e6a17f[root@docker-study ~]# docker run --name=web --network=my-custom-net -d httpd264833168ac671eda95d0dd10547ce9bfa18bf83bc97531f85de202f72886088[root@docker-study ~]# &nbsp;&nbsp;在mysql容器中设置web用户 12345mysql&gt; create user web@172.19.0.3 identified by &apos;123456&apos;;Query OK, 0 rows affected (0.00 sec)mysql&gt; grant all privileges on *.* to web@172.19.0.3;Query OK, 0 rows affected (0.00 sec) &nbsp;&nbsp;&nbsp;然后，web容器可以使用mysql2主机名连接到mysql2容器， 反之亦然，因为Docker会自动为给定的容器名称设置DNS。 123456789101112131415[root@docker-study var]# docker exec -it web mysql --host=mysql2 --user=web --passwordEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 37Server version: 5.6.43 MySQL Community Server (GPL)Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; 服务器错误日志&nbsp;&nbsp;&nbsp;首次使用服务器容器启动MySQL服务器时， 如果满足以下任一条件，则不会生成服务器错误日志： 已装入主机的服务器配置文件，但该文件不包含系统变量 log_error。 尚未安装主机的服务器配置文件，但Docker环境变量 MYSQL_LOG_CONSOLE 是true（MySQL 5.6服务器容器的变量的默认状态false）。然后将MySQL服务器的错误日志重定向到 stderr，以便错误日志进入Docker容器的日志，并使用docker logs mysqld-container 命令查看 。 &nbsp;&nbsp;&nbsp;要使MySQL Server在两个条件之一为真时生成错误日志，请使用该 –log-error 选项 ，配置服务器以在容器内的特定位置生成错误日志。要保留错误日志，请将主机文件挂载到容器内错误日志的位置，如上文中所述。但是必须确保其容器内的MySQL Server具有对挂载的主机文件有写访问权。 Docker环境变量&nbsp;&nbsp;&nbsp;创建MySQL Server容器时，可以使用–env选项（-e简而言之）配置MySQL实例，并指定以下一个或多个环境变量。 注意&nbsp;&nbsp;&nbsp;如果挂载的数据目录不为空，则以下变量都不会产生任何影响，因为之后不会尝试进行服务器初始化。在容器启动期间，不会修改文件夹中任何预先存在的内容，包括任何旧服务器设置。 &nbsp;&nbsp;&nbsp;布尔变量包括 MYSQL_RANDOM_ROOT_PASSWORD, MYSQL_ONETIME_PASSWORD和MYSQL_ALLOW_EMPTY_PASSWORD， MYSQL_LOG_CONSOLE 通过使用任何非零长度的字符串设置它们来实现。例如”0”，”false”或 “no”不会使它们为假，但实际上使它们成立。这是MySQL Server容器的已知问题。 MYSQL_RANDOM_ROOT_PASSWORD：当此变量为true（这是默认状态，除非 MYSQL_ROOT_PASSWORD 或MYSQL_ALLOW_EMPTY_PASSWORD 设置为true）时，将在启动Docker容器时生成服务器root用户的随机密码。密码打印到stdout容器中，可以通过查看容器的日志找到。 MYSQL_ONETIME_PASSWORD：当变量为true（这是默认状态，除非 MYSQL_ROOT_PASSWORD 已设置或MYSQL_ALLOW_EMPTY_PASSWORD 设置为true）时，root用户的密码设置为expired，必须先更改才能正常使用MySQL。 MYSQL_DATABASE：此变量允许指定要在镜像启动时创建的数据库的名称。如果用户名和密码均由 MYSQL_USER 和MYSQL_PASSWORD提供，创建用户并授予该数据库（对应于超级用户权限GRANT ALL）。指定的数据库由 CREATE DATABASE IF NOT EXIST语句创建，因此如果数据库已存在，则该变量无效。 MYSQL_USER， MYSQL_PASSWORD：这些变量结合使用来创建用户并设置该用户的密码，并为该用户授予该MYSQL_DATABASE 变量指定的数据库的超级用户权限 。MYSQL_USER 和 MYSQL_PASSWORD 用于创建用户，如果这两个变量没有设置，则忽略。如果两个变量都已设置但未设置 MYSQL_DATABASE ，则创建用户时没有任何权限。 注意&nbsp;&nbsp;没有必要使用这种机制创建root用户，这是MYSQL_ROOT_PASSWORD 和 MYSQL_RANDOM_ROOT_PASSWORD两种机制默认创建的，除非 MYSQL_ALLOW_EMPTY_PASSWORD = ture。 MYSQL_ROOT_HOST：默认情况下，MySQL会创建 ‘root‘@’localhost’帐户。此帐户只能从容器内部连接。要允许来自其他主机的根连接，请设置此环境变量。例如，该值 为172.17.0.1允许来自运行容器的主机的连接。该选项仅接受一个参数，但允许使用通配符（例如， MYSQL_ROOT_HOST=172...*或MYSQL_ROOT_HOST=%）。 MYSQL_LOG_CONSOLE：当变量为true（变量的MySQL 5.6服务器容器的默认状态为false）时，MySQL服务器的错误日志被重定向到 stderr，以便错误日志进入Docker容器的日志，并且可以使用docker logs mysqld-container 命令查看 。 注意&nbsp;&nbsp;&nbsp;如果已挂载主机的服务器配置文件，则该变量无效。MYSQL_ROOT_PASSWORD：此变量指定为MySQL root帐户设置的密码。 警告&nbsp;&nbsp;&nbsp;在命令行上设置MySQL root用户密码是不安全的。作为显式指定密码的替代方法，可以使用容器文件路径为密码文件设置变量，然后从主机中装入包含容器文件路径密码的文件。这仍然不是很安全，因为密码文件的位置仍然暴露。最好使用默认设置， MYSQL_RANDOM_ROOT_PASSWORD=true 并且 MYSQL_ONETIME_PASSWORD=true。 MYSQL_ALLOW_EMPTY_PASSWORD。将其设置为true以允许使用root用户的空密码启动容器。 警告&nbsp;&nbsp;&nbsp;将此变量设置为true是不安全的，因为它会使MySQL实例完全不受保护，从而允许任何人获得完整的超级用户访问权限。最好使用默认设置， MYSQL_RANDOM_ROOT_PASSWORD=true 并且MYSQL_ONETIME_PASSWORD=true 。]]></content>
      <tags>
        <tag>MySQL</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL介绍]]></title>
    <url>%2F2019%2F01%2F23%2FMySQL%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[什么是MySQL&nbsp;&nbsp;&nbsp;&nbsp;MySQL 是最流行的关系型数据库管理系统，在 WEB 应用方面 MySQL 是最好的关系数据库管理系统(RDBMS)应用软件之一。 MySQL数据库是关系型的&nbsp;&nbsp;&nbsp;&nbsp;关系数据库将数据存储在单独的表中，而不是将所有数据放在一个大的库房中。数据库结构被组织成针对速度优化的物理文件。逻辑模型具有数据库，表，视图，行和列等对象，可提供灵活的编程环境。可以设置管理不同数据字段之间关系的规则，例如一对一，一对多，唯一，必需或可选，以及不同表之间的”指针”。数据库强制执行这些规则，因此使用设计良好的数据库，应用程序永远不会看到不一致，重复，孤立，过时或丢失的数据。 &nbsp;&nbsp;&nbsp;&nbsp;”MYSQL” 的SQL部分代表 “ 结构化查询语言 ”。SQL是用于访问数据库的最常用的标准化语言。根据编程环境，可以直接输入SQL（例如，生成报告），将SQL语句嵌入到用其他语言编写的代码中，或使用隐藏SQL语法的特定于语言的API。 MySQL数据库服务器非常快速，可靠，可扩展且易于使用&nbsp;&nbsp;&nbsp;&nbsp;MySQL Server最初是为了比现有解决方案更快地处理大型数据库而开发的，并且已经成功地在高要求的生产环境中使用了好几年。虽然在不断发展的今天，MySQL服务器提供了丰富而有用的功能集。它的连接性，速度和安全性使MySQL Server非常适合访问Internet上的数据库。 MySQL Server适用于客户端/服务器或嵌入式系统。&nbsp;&nbsp;&nbsp;&nbsp;MySQL数据库软件是一个C/S系统，由支持不同后端的多线程SQL服务器，几个不同的客户端程序和库，管理工具以及各种应用程序编程接口（API）组成。MySQL Server作为嵌入式多线程库，可以将其链接到应用程序，以获得更小，更快，更易于管理的独立产品。 MySQL特点 内部和可移植性 用C和C ++编写。 经过多种不同编译器的测试。 适用于许多不同的平台。 为了便于携带，在MySQL 5.5及更高版本中使用CMake。以前的系列使用GNU Automake，Autoconf和Libtool。 使用Purify（商业内存泄漏检测器）以及GPL工具Valgrind（http://developer.kde.org/~sewardj/）进行测试。 使用具有独立模块的多层服务器设计。 设计为使用内核线程完全多线程，以便在可用时轻松使用多个CPU。 提供事务性和非事务性存储引擎。 使用非常快的 B-tree 磁盘表 (MyISAM）实现索引压缩。 旨在使添加其他存储引擎相对容易。如果要为内部数据库提供SQL接口，这非常有用。 使用非常快速的基于线程的内存分配系统。 使用优化的嵌套循环连接执行速度非常快。 实现内存中的哈希表用作临时表。 使用应尽可能快的高度优化的类库实现SQL函数。通常在查询初始化之后根本没有内存分配。 将服务器作为单独的程序提供，用于客户端/服务器网络环境，以及作为可嵌入（链接）到独立应用程序的库。此类应用程序可以单独使用，也可以在没有网络的环境中使用。 数据类型 许多数据类型：有符号/无符号整数，8个字节长的数据，float(浮点型)， double(双精度型)， char(字符)， varchar(变长字符串)， binary(二进制)，varbinary(可变二进制)， text(文本)， blob， date， time， datetime， timestamp， year， set， enum，和开放GIS空间类型。 固定长度和可变长度的字符串类型。 函数和语句&nbsp;&nbsp;&nbsp;&nbsp;SELECT列表和 WHERE子句查询中的 完整运算符和函数支持 。例如： 123mysql&gt; SELECT CONCAT(first_name, &apos; &apos;, last_name) -&gt; FROM citizen -&gt; WHERE income/dependents &gt; 10000 AND age &gt; 30; 完全支持SQL GROUP BY和 ORDER BY子句。支持基函数（COUNT()， AVG()， STD()， SUM()， MAX()， MIN()，和GROUP_CONCAT()）。 支持LEFT OUTER JOIN和 RIGHT OUTER JOIN使用标准SQL和ODBC语法。 根据标准SQL的要求支持表和列上的别名。 支持DELETE， INSERT， REPLACE，和 UPDATE以返回更改（受影响）的行数，或返回通过连接到服务器时设置标志，而不是匹配的行的数量。 支持特定于MySQL的SHOW语句，用于检索有关数据库，存储引擎，表和索引的信息。支持 INFORMATION_SCHEMA数据库，根据标准SQL实现。 一个EXPLAIN语句来显示优化器如何解决一个查询。 表名或列名中函数名的独立性。例如，ABS是一个有效的列名。唯一的限制是，对于函数调用，函数名和它后面的“ (”之间不允许有空格 。 可以在同一语句中引用来自不同数据库的表。 安全 特权和密码系统，非常灵活和安全，可以进行基于主机的验证。 连接到服务器时加密所有密码流量的密码安全性。 可扩展性和限制 支持大型数据库。我们将MySQL Server与包含5000万条记录的数据库结合使用。 每个表最多支持64个索引。每个索引可以包含1到16列或部分列。InnoDB表的最大索引宽度为767字节或3072字节。MyISAM表的最大索引宽度为1000个字节。索引可使用的柱的前缀CHAR， VARCHAR， BLOB，或 TEXT列类型。 连接 客户端可以使用多种协议连接到MySQL Server: i. 客户端可以在任何平台上使用TCP / IP套接字进行连接。 ii. 在Windows系统上，如果使用该–enable-named-pipe选项启动服务器，则客户端可以使用命名管道进行连接。如果使用该–shared-memory选项启动，Windows服务器也支持共享内存连接。客户端可以使用该–protocol=memory选项通过共享内存进行连接。 iii. 在Unix系统上，客户端可以使用Unix域套接字文件进行连接。 MySQL客户端程序可以用多种语言编写。用C编写的客户端库可用于用C或C ++编写的客户端，或者用于提供C绑定的任何语言。 提供C，C ++，Eiffel，Java，Perl，PHP，Python，Ruby和Tcl的API，使MySQL客户端能够以多种语言编写。 客户端和工具 MySQL包括几个客户端和实用程序。这些包括命令行程序，如 mysqldump和 mysqladmin，以及图形程序，如 MySQL Workbench。 MySQL Server内置支持SQL语句来检查，优化和修复表。这些语句可以从命令行通过 mysqlcheck客户端获得。MySQL还包括myisamchk，这是一个非常快速的命令行实用程序，用于在MyISAM 表上执行这些操作。 可以使用–help 或-?选项调用MySQL程序以获取在线帮助。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cisco UCS B200 M2安装操作系统]]></title>
    <url>%2F2019%2F01%2F19%2FCisco-UCS-B200-M2%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[由于项目需要，要求把上图系统更换为 CentOS7. 踩了不少坑，折腾一天。 服务器的型号为UCS B200 M2 ,需要在网页登录他的管理器，本地的java环境为jdk-6u10。6版本的每一个我都试了，只有这个可以。在kvm manager的页面可以下载kvm console 的java程序，在本地运行就可以了 该刀片服务器重装\安装系统需要从本地映射镜像到服务器，也是在网上看的服务器配置指导才知道，我还想着拿个显示屏怼上呢。映射步骤如下： 1.点击virtual Medis （如果报错虚拟磁盘本地库无法加载，那就是java版本的问题了） 2.左侧有”Add Images”，选中需要安装的系统就可以了 3.勾选上第一列的Mapped ，即将本地镜像文件映射到 “Virtual CD/DVD” 4.重启 5.在该界面进入boot menu ，更改启动顺序 6.选择”Cisco Virtual CD/DVD 1.22”，不要选择EFI那一项 之后就是安装CentOS的步骤了，除了在分盘的时候把之前的分区先删除干净之外，其他步骤都相同了]]></content>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译安装mysql-server5.6.32]]></title>
    <url>%2F2019%2F01%2F16%2F%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85mysql-server5-6-32%2F</url>
    <content type="text"><![CDATA[摘自：http://www.cnblogs.com/yaohan/p/6288620.html 12wget http://downloads.mysql.com/archives/get/file/mysql-5.6.32.tar.gz tar -zxvf mysql-5.6.32.tar.gz 安装编译环境 123456yum install gcc gcc-c++yum install -y ncurses-develyum install -y cmakeyum install -y libaioyum install -y bisonyum install -y perl-Module-Install.noarch 编译 12345678910cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_UNIX_ADDR=/usr/local/mysql/mysql.sock -DDEFAULT_CHARSET=utf8-DDEFAULT_COLLATION=utf8_general_ci-DWITH_INNOBASE_STORAGE_ENGINE=1-DWITH_ARCHIVE_STORAGE_ENGINE=1-DWITH_BLACKHOLE_STORAGE_ENGINE=1-DMYSQL_DATADIR=/home/mysqldata-DMYSQL_TCP_PORT=3306-DENABLE_DOWNLOADS=1 若要重新运行配置，需要删除目录内CMakeCache.txt文件 1rm CMakeCache.txt 1make &amp;&amp; make install 使用下面的命令查看是否有mysql用户及用户组 12345678cat /etc/passwd #查看用户列表cat /etc/group #查看用户组列表如果没有就创建groupadd mysqluseradd -g mysql mysql修改/usr/local/mysql权限chown -R mysql:mysql /usr/local/mysql 修改配置文件 1234567891011121314151617181920212223242526272829303132333435363738cp support-files/my-default.cnf /etc/my.cnfvi /etc/my.cnf-----my.cnf begin------[client]default-character-set=utf8socket = /usr/local/mysql/mysql.sock[mysql]default-character-set=utf8[mysqld]# Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M# Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin# These are commonly set, remove the # and set as required.basedir = /usr/local/mysqldatadir = /home/mysqldata/port = 3306# server_id = .....socket = /usr/local/mysql/mysql.sockcharacter-set-server=utf8# Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2Msql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES-----my.cnf end------ 初始化数据库 12cd /usr/local/mysql/./scripts/mysql_install_db --user=mysql --datadir=/home/mysqldata 修改文件和目录权限，否则开启服务会报错 12chown -R mysql:root /usr/local/mysql/mysql.sockchown -R mysql:root /usr/local/mysql 测试开启编译安装的Mysql 1/usr/local/mysql/bin/mysqld_safe 运行正常则添加启动脚本 1234cp support-files/mysql.server /etc/init.d/mysqlchkconfig mysql onservice mysql start --启动MySQLln -s /usr/local/mysql/bin/mysql /usr/bin]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[harbor配置文件介绍]]></title>
    <url>%2F2019%2F01%2F15%2Fharbor%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[There are two categories of parameters in harbor.cfg, required parameters and optional parameters.在harbor.cfg中有两类参数，必需参数和可选参数。 required parameters: These parameters are required to be set in the configuration file. They will take effect if a user updates them in harbor.cfg and run the install.sh script to reinstall Harbor.required参数：需要在配置文件中设置这些参数。如果用户更新它们harbor.cfg 并运行 install.sh 脚本以重新安装Harbor，它们将生效。 optional parameters: These parameters are optional for updating, i.e. user can leave them as default and update them on Web Portal after Harbor is started. If they are set in harbor.cfg, they only take effect in the first launch of Harbor. Subsequent update to these parameters in harbor.cfg will be ignored.可选参数：这些参数对于更新是可选的，即用户可以将它们保留为默认值，并在启动Harbour后在Web Portal(门户网站)上更新它们。如果它们已经启用harbor.cfg，它们只会在首次启动Harbour时生效。harbor.cfg将忽略对这些参数的后续更新。 Note: If you choose to set these parameters via the Portal, be sure to do so right after Harbor is started. In particular, you must set the desired auth_mode before registering or creating any new users in Harbor. When there are users in the system (besides the default admin user), auth_mode cannot be changed.注意：如果你选择通过Portal设置这些参数，请务必在Harbour启动后立即执行此操作。特别是，你必须在Harbour中注册或创建任何新用户之前设置auth_mode。当系统中有用户时（除默认管理员用户外）， 无法更改auth_mode。 Required parameters: 必须参数hostname: The target host’s hostname, which is used to access the Portal and the registry service. It should be the IP address or the fully qualified domain name (FQDN) of your target machine, e.g., 192.168.1.10 or reg.yourdomain.com. Do NOT use localhost or 127.0.0.1 for the hostname - the registry service needs to be accessible by external clients!hostname：目标主机的主机名，用于访问Portal和registry服务。它应该是目标计算机的IP地址或完全限定的域名（FQDN），例如，192.168.1.10或reg.yourdomain.com。不要使用localhost或127.0.0.1作为主机名 - 外部客户端需要访问registry服务！ ui_url_protocol: (http or https. Default is http) The protocol used to access the Portal and the token/notification service. If Notary is enabled, this parameter has to be https. By default, this is http.ui_url_protocol :( http或https。默认为http）用于访问Portal和令牌/通知服务的协议。如果启用了公证，则此参数必须为https。默认情况下是http。 db_password: The root password for the PostgreSQL database used for db_auth. Change this password for any production use!db_password：用于db_auth的PostgreSQL数据库的root密码。生产环境中要修改密码！ max_job_workers: (default value is 10) The maximum number of replication workers in job service. For each image replication job, a worker synchronizes all tags of a repository to the remote destination. Increasing this number allows more concurrent replication jobs in the system. However, since each worker consumes a certain amount of network/CPU/IO resources, please carefully pick the value of this attribute based on the hardware resource of the host.max_job_workers :(默认值为10）作业服务中的最大复制工作数。对于每个镜像复制作业，工作程序将存储库的所有标记同步到远程目标。增加此数量可以在系统中实现更多并发复制作业。但是，由于每个工作者都消耗一定量的网络/ CPU / IO资源，请根据主机的硬件资源仔细选择该属性的值。 customize_crt: (on or off. Default is on) When this attribute is on, the prepare script creates private key and root certificate for the generation/verification of the registry’s token. Set this attribute to off when the key and root certificate are supplied by external sources.customize_crt：（开启或关闭，默认为开启），如果此属性开启，在准备脚本创建registry的令牌生成/验证私钥和根证书。当外部源提供密钥和根证书时，将此属性设置为off。 ssl_cert: The path of SSL certificate, it’s applied only when the protocol is set to https.ssl_cert：SSL证书的路径，仅在协议设置为https时应用。 ssl_cert_key: The path of SSL key, it’s applied only when the protocol is set to https.ssl_cert_key：SSL密钥的路径，仅在协议设置为https时应用。 secretkey_path: The path of key for encrypt or decrypt the password of a remote registry in a replication policy.secretkey_path：用于加密或解密复制策略中远程registry密码的密钥路径。 log_rotate_count: Log files are rotated log_rotate_count times before being removed. If count is 0, old versions are removed rather than rotated.log_rotate_count：日志文件在被删除之前会被轮换log_rotate_count次。如果count为0，则删除旧版本而不会轮转。 log_rotate_size: Log files are rotated only if they grow bigger than log_rotate_size bytes. If size is followed by k, the size is assumed to be in kilobytes. If the M is used, the size is in megabytes, and if G is used, the size is in gigabytes. So size 100, size 100k, size 100M and size 100G are all valid.log_rotate_size：仅当日志文件大于log_rotate_size字节时才会轮换日志文件。如果大小后跟k，则假定大小以千字节为单位。如果使用M，则大小以兆字节为单位，如果使用G，则大小为千兆字节。尺寸100，尺寸100k，尺寸100M和尺寸100G都是有效的。 http_proxy: Config http proxy for Clair, e.g. http://my.proxy.com:3128.http_proxy：为Clair配置http代理，例如http://my.proxy.com:3128。 https_proxy: Config https proxy for Clair, e.g. http://my.proxy.com:3128.https_proxy：为Clair配置https代理，例如http://my.proxy.com:3128。 no_proxy: Config no proxy for Clair, e.g. 127.0.0.1,localhost,core,registry.no_proxy：为Clair配置无代理，例如127.0.0.1,localhost,core,registry。 Optional parameters 可选参数Email settings: These parameters are needed for Harbor to be able to send a user a “password reset” email, and are only necessary if that functionality is needed. Also, do note that by default SSL connectivity is not enabled - if your SMTP server requires SSL, but does not support STARTTLS, then you should enable SSL by setting email_ssl = true. Setting email_insecure = true if the email server uses a self-signed or untrusted certificate.电子邮件设置：Harbor需要这些参数才能向用户发送“密码重置”电子邮件，并且仅在需要该功能时才需要。另外，请注意，在默认情况下SSL连接是禁用的，如果你的SMTP服务器需要SSL，但不支持STARTTLS，那么你应该通过设置启用SSL email_ssl = TRUE。如果电子邮件服务器使用自签名证书或不受信任证书，则设置email_insecure = true。 12345678email_server = smtp.mydomain.comemail_server_port = 25email_identity =email_username = sample_admin@mydomain.comemail_password = abcemail_from = admin sample_admin@mydomain.comemail_ssl = falseemail_insecure = false harbor_admin_password: The administrator’s initial password. This password only takes effect for the first time Harbor launches. After that, this setting is ignored and the administrator’s password should be set in the Portal. Note that the default username/password are admin/Harbor12345 .harbor_admin_password：管理员的初始密码。此密码仅在Harbor首次启动时生效。之后，将忽略此设置，并且应在Portal中设置管理员密码。请注意，默认用户名/密码为admin / Harbor12345。 auth_mode: The type of authentication that is used. By default, it is db_auth, i.e. the credentials are stored in a database. For LDAP authentication, set this to ldap_auth.auth_mode：使用的身份验证类型。默认情况下，它是db_auth，即凭据存储在数据库中。对于LDAP身份验证，请将其设置为ldap_auth.IMPORTANT: When upgrading from an existing Harbor instance, you must make sure auth_mode is the same in harbor.cfg before launching the new version of Harbor. Otherwise, users may not be able to log in after the upgrade.重要信息：从现有Harbor实例升级时，必须确保在启动新版本的Harbor之前harbor.cfg中的auth_mode相同。否则，用户可能无法在升级后登录。 ldap_url: The LDAP endpoint URL (e.g. ldaps://ldap.mydomain.com). Only used when auth_mode is set to ldap_auth .ldap_url：LDAP端点URL（例如ldaps://ldap.mydomain.com）。 仅在auth_mode设置为ldap_auth时使用。 ldap_searchdn: The DN of a user who has the permission to search an LDAP/AD server (e.g. uid=admin,ou=people,dc=mydomain,dc=com).ldap_searchdn：具有搜索LDAP/AD服务器权限的用户的DN（例如uid=admin,ou=people,dc=mydomain,dc=com）。 ldap_search_pwd: The password of the user specified by ldap_searchdn.ldap_search_pwd：ldap_searchdn指定的用户密码。 ldap_basedn: The base DN to look up a user, e.g. ou=people,dc=mydomain,dc=com. Only used when auth_mode is set to ldap_auth .ldap_basedn：查找用户的基本DN，例如ou=people,dc=mydomain,dc=com。 仅在auth_mode设置为ldap_auth时使用。 ldap_filter: The search filter for looking up a user, e.g. (objectClass=person).ldap_filter：用于查找用户的搜索过滤器，例如(objectClass=person) ldap_uid: The attribute used to match a user during a LDAP search, it could be uid, cn, email or other attributes.ldap_uid：用于在LDAP搜索期间匹配用户的属性，它可以是uid，cn，email或其他属性。 ldap_scope: The scope to search for a user, 0-LDAP_SCOPE_BASE, 1-LDAP_SCOPE_ONELEVEL, 2-LDAP_SCOPE_SUBTREE. Default is 2.ldap_scope：搜索用户的范围，0-LDAP_SCOPE_BASE，1-LDAP_SCOPE_ONELEVEL，2-LDAP_SCOPE_SUBTREE。默认值为2。 ldap_timeout: Timeout (in seconds) when connecting to an LDAP Server. Default is 5.ldap_timeout：连接LDAP服务器时超时（以秒为单位）。默认值为5。 ldap_verify_cert: Verify certificate from LDAP server. Default is true.ldap_verify_cert：验证来自LDAP服务器的证书。默认为true。 ldap_group_basedn: The base dn from which to lookup a group in LDAP/AD, e.g. ou=group,dc=mydomain,dc=com.ldap_group_basedn：在LDAP / AD中查找组的基本dn，例如ou=group,dc=mydomain,dc=com。 ldap_group_filter: The filter to search LDAP/AD group, e.g. objectclass=group.ldap_group_filter：搜索LDAP / AD组的过滤器，例如objectclass=group。 ldap_group_gid: The attribute used to name a LDAP/AD group, it could be cn, name.ldap_group_gid：用于命名LDAP / AD组的属性，它可以是cn，name。 ldap_group_scope: The scope to search for ldap groups. 0-LDAP_SCOPE_BASE, 1-LDAP_SCOPE_ONELEVEL, 2-LDAP_SCOPE_SUBTREE. Default is 2.ldap_group_scope：搜索ldap组的范围。0-LDAP_SCOPE_BASE，1-LDAP_SCOPE_ONELEVEL，2-LDAP_SCOPE_SUBTREE。默认值为2。 self_registration: (on or off. Default is on) Enable / Disable the ability for a user to register himself/herself. When disabled, new users can only be created by the Admin user, only an admin user can create new users in Harbor. NOTE: When auth_mode is set to ldap_auth, self-registration feature is always disabled, and this flag is ignored.self_registration :( 打开或关闭。默认打开）启用/禁用用户注册功能。禁用时，新用户只能由管理员用户创建，只有管理员用户可以在Harbor中创建新用户。注意：当auth_mode设置为ldap_auth时，始终禁用自注册功能，并忽略此标志。 token_expiration: The expiration time (in minutes) of a token created by token service, default is 30 minutes.token_expiration：令牌服务创建的令牌的到期时间（以分钟为单位），默认为30分钟。 project_creation_restriction: The flag to control what users have permission to create projects. By default everyone can create a project, set to “adminonly” such that only admin can create project.project_creation_restriction：用于控制用户有权创建项目的标志。默认情况下，每个人都可以创建一个项目；设置为“adminonly”，则只有管理员才能创建项目。 Configuring storage backend (optional) 配置存储后端（可选）By default, Harbor stores images on your local filesystem. In a production environment, you may consider using other storage backend instead of the local filesystem, like S3, OpenStack Swift, Ceph, etc. These parameters are configurations for registry.默认情况下，Harbor将镜像存储在本地文件系统中。在生产环境中，您可以考虑使用其他存储后端而不是本地文件系统，如S3，OpenStack Swift，Ceph等。这些参数是registry的配置。 registry_storage_provider_name: Storage provider name of registry, it can be filesystem, s3, gcs, azure, etc. Default is filesystem.registry_storage_provider_name：存储仓库名称，可以是filesystem，s3，gcs，azure等。默认为filesystem。 registry_storage_provider_config: Comma separated “key: value” pairs for storage provider config, e.g. “key1: value, key2: value2”. Default is empty string.registry_storage_provider_config：配置分隔键值对，例如“key1：value，key2：value2”。默认为空字符串。 registry_custom_ca_bundle: The path to the custom root ca certificate, which will be injected into the truststore of registry’s and chart repository’s containers. This is usually needed when the user hosts a internal storage with self signed certificate.registry_custom_ca_bundle：当用户使用自签名证书托管内部存储时，通常需要自定义根ca证书的路径，它将注入到registry和image存储库容器的信任库中。例如，如果使用Openstack Swift作为存储后端，则参数可能如下所示： 12registry_storage_provider_name = swiftregistry_storage_provider_config = “ username：admin，password：ADMIN_PASS，authurl：http：// kestone_addr：35357 / v3 / auth，tenant：admin，domain：default，region：regionOne，container：docker_images ” 对于LADP以及证书不理解，需要加入到后续的学习计划。]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[harbor 企业级docker registry]]></title>
    <url>%2F2019%2F01%2F12%2Fharbor-%E4%BC%81%E4%B8%9A%E7%BA%A7docker-registry%2F</url>
    <content type="text"><![CDATA[关于HarborHarbor is an an open source trusted cloud native registry project that stores, signs, and scans content. Harbor extends the open source Docker Distribution by adding the functionalities usually required by users such as security, identity and management. Having a registry closer to the build and run environment can improve the image transfer efficiency. Harbor supports replication of images between registries, and also offers advanced security features such as user management, access control and activity auditing.Harbor是一个开源的可信云本机registry项目，用于存储，签名和扫描内容。Harbor通过添加用户通常需要的功能（如安全性，身份和管理）来扩展开源Docker Distribution。使注册表更接近构建和运行环境可以提高图像传输效率。Harbor支持在注册表之间复制映像，还提供高级安全功能，如用户管理，访问控制和活动审计。 Features 特性Cloud native registry: With support for both container images and Helm charts, Harbor serves as registry for cloud native environments like container runtimes and orchestration platforms.云本机registry：Harbour支持容器镜像和Helm图表，可用作云本机环境（如容器运行时和业务流程平台）的registry。 Role based access control: Users and repositories are organized via ‘projects’ and a user can have different permission for images under a project.基于角色的访问控制：用户和存储库通过“项目”进行组织，用户可以对项目下的镜像拥有不同的权限。 Policy based image replication: Images can be replicated (synchronized) between multiple registry instances based on policies with multiple filters (repository, tag and label). Harbor will auto-retry to replicate if it encounters any errors. Great for load balancing, high availability, multi-datacenter, hybrid and multi-cloud scenarios.基于策略的镜像复制：可以基于具有多个过滤器（存储库，标记和标签）的策略在多个registry实例之间复制（同步）镜像。如果遇到任何错误，Harbor将自动重试进行复制。非常适合负载平衡，高可用性，多数据中心，混合和多云场景。 Vulnerability Scanning: Harbor scans images regularly and warns users of vulnerabilities.漏洞扫描：Harbor定期扫描镜像并警告用户漏洞。 LDAP/AD support: Harbor integrates with existing enterprise LDAP/AD for user authentication and management, and supports importing LDAP groups into Harbor and assigning proper project roles to them.LDAP / AD支持：Harbor与现有企业LDAP / AD集成以进行用户身份验证和管理，并支持将LDAP组导入Harbor并为其分配适当的项目角色。 Image deletion &amp; garbage collection: Images can be deleted and their space can be recycled.图像删除和垃圾收集：可以删除镜像，并可以回收它们的空间。 Notary: Image authenticity can be ensured.公证：可以确保镜像的真实性。 Graphical user portal: User can easily browse, search repositories and manage projects.用户图形界面：用户可以轻松浏览，搜索存储库和管理项目。 Auditing: All the operations to the repositories are tracked.审计：跟踪存储库的所有操作。 RESTful API: RESTful APIs for most administrative operations, easy to integrate with external systems.RESTful API：适用于大多数管理操作的RESTful API，易于与外部系统集成。 Easy deployment: Provide both an online and offline installer.易于部署：提供在线和离线安装程序。 企业级Registry项目Harbor是由Vmware公司开发的开源项目，其的目标是帮助用户迅速搭建一个企业级的Docker registry 服务。它以Docker公司开源的registry 为基础，提供了管理UI, 基于角色的访问控制(Role Based Access Control)，AD/LDAP集成、以及审计日志(Audit logging) 等企业用户需求的功能，同时还原生支持中文。 Harbor的每个组件都是以Docker 容器的形式构建的，因此很自然地，我们使用Docker Compose来对它进行部署。在源代码中(https://github.com/vmware/harbor), 用于部署Harbor的Docker Compose 模板位于 /Deployer/docker-compose.yml. 打开这个模板文件，会发现Harbor由5个容器组成： proxy: 由Nginx 服务器构成的反向代理。 registry:由Docker官方的开源registry 镜像构成的容器实例。 ui: 即架构中的core services, 构成此容器的代码是Harbor项目的主体。 mysql: 由官方MySql镜像构成的数据库容器。 log: 运行着rsyslogd的容器，通过log-driver的形式收集其他容器的日志。 这几个容器通过Docker link的形式连接在一起，这样，在容器之间可以通过容器名字互相访问。对终端用户而言，只需要暴露proxy （即Nginx）的服务端口。（摘自 http://dockone.io/article/1179） 安装及配置(参考 https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md 下载harbor软件包：https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-offline-installer-v1.7.1.tgzharbor软件包较大，建议科学上网 解压后如下 123[root@Web2 harbor]# lscommon docker-compose.clair.yml docker-compose.yml harbor.v1.7.1.tar.gz LICENSE preparedocker-compose.chartmuseum.yml docker-compose.notary.yml harbor.cfg install.sh open_source_license 12345678910111213141516171819202122232425262728293031323334[root@Web2 ~]# yum info docker-compose已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.neusoft.edu.cn * epel: mirrors.tuna.tsinghua.edu.cn * extras: mirrors.nwsuaf.edu.cn * updates: mirrors.tuna.tsinghua.edu.cn已安装的软件包名称 ：docker-compose架构 ：noarch版本 ：1.18.0发布 ：2.el7大小 ：1.1 M源 ：installed来自源：epel简介 ： Multi-container orchestration for Docker网址 ：https://github.com/docker/compose协议 ： ASL 2.0描述 ： Compose is a tool for defining and running multi-container Docker : applications. With Compose, you use a Compose file to configure your : application&apos;s services. Then, using a single command, you create and : start all the services from your configuration. : : Compose is great for development, testing, and staging environments, : as well as CI workflows. : : Using Compose is basically a three-step process. : : 1. Define your app&apos;s environment with a Dockerfile so it can be : reproduced anywhere. : 2. Define the services that make up your app in docker-compose.yml so : they can be run together in an isolated environment: : 3. Lastly, run docker-compose up and Compose will start and run your : entire app. 还需要docker-compose 编排工具，该工具在epel源中提供，所以需要先配置epel源；然后再安装即可 123yum install epel-releaseyum repolistyum install docker-compose python和openssl 1234567[root@Web2 ~]# opensslOpenSSL&gt; versionOpenSSL 1.0.2k-fips 26 Jan 2017OpenSSL&gt; exit[root@Web2 ~]# python --versionPython 2.7.5[root@Web2 ~]# 修改harbor配置文件 123[root@Web2 ~]# vim /usr/local/harbor/harbor.cfg hostname = 172.18.74.101 //IP地址或域名max_job_workers = 3 //CPU数减一 Harbor has integrated with Notary and Clair (for vulnerability scanning). However, the default installation does not include Notary or Clair service.Harbor已与Notary和Clair集成（用于漏洞扫描）。但是，默认安装不包括Notary或Clair服务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135执行脚本安装harbor[root@Web2 harbor]# ./install.sh [Step 0]: checking installation environment ...Note: docker version: 18.09.0Note: docker-compose version: 1.18.0[Step 1]: loading Harbor images ...ae18db924eef: Loading layer [==================================================&gt;] 32.92MB/32.92MB1c06074dba9c: Loading layer [==================================================&gt;] 8.955MB/8.955MB7a719a639e34: Loading layer [==================================================&gt;] 3.072kB/3.072kB49f7bca05da9: Loading layer [==================================================&gt;] 2.56kB/2.56kBe86d69bef97e: Loading layer [==================================================&gt;] 2.56kB/2.56kB81e122d773f5: Loading layer [==================================================&gt;] 2.048kB/2.048kB5fe5adb8cf31: Loading layer [==================================================&gt;] 22.8MB/22.8MBd760045419e4: Loading layer [==================================================&gt;] 22.8MB/22.8MBLoaded image: goharbor/registry-photon:v2.6.2-v1.7.1c0f668a21621: Loading layer [==================================================&gt;] 133.2MB/133.2MBf8cb0bf39ff2: Loading layer [==================================================&gt;] 684MB/684MB444ac38a117b: Loading layer [==================================================&gt;] 7.68kB/7.68kB2e16f24ac8bc: Loading layer [==================================================&gt;] 212kB/212kBLoaded image: goharbor/harbor-migrator:v1.7.1fa2dcaba747a: Loading layer [==================================================&gt;] 8.955MB/8.955MBeeaaf4c760eb: Loading layer [==================================================&gt;] 15.6MB/15.6MB98ffd6175b61: Loading layer [==================================================&gt;] 18.94kB/18.94kBfc1db6c4f652: Loading layer [==================================================&gt;] 15.6MB/15.6MBLoaded image: goharbor/harbor-adminserver:v1.7.18d55a6a034d6: Loading layer [==================================================&gt;] 8.955MB/8.955MB01ef68a17913: Loading layer [==================================================&gt;] 27.24MB/27.24MBf9258cfa4b48: Loading layer [==================================================&gt;] 5.632kB/5.632kBdcf5c61ede76: Loading layer [==================================================&gt;] 27.24MB/27.24MBLoaded image: goharbor/harbor-core:v1.7.11f65d10893c9: Loading layer [==================================================&gt;] 50.39MB/50.39MB358f40be2091: Loading layer [==================================================&gt;] 3.584kB/3.584kBc7f3ef058d0b: Loading layer [==================================================&gt;] 3.072kB/3.072kB154caf7c7173: Loading layer [==================================================&gt;] 4.096kB/4.096kB42c7764aa777: Loading layer [==================================================&gt;] 3.584kB/3.584kB023f3a96f324: Loading layer [==================================================&gt;] 10.24kB/10.24kBLoaded image: goharbor/harbor-log:v1.7.1a1b528067504: Loading layer [==================================================&gt;] 8.955MB/8.955MB2d3d34f3ba5b: Loading layer [==================================================&gt;] 21.51MB/21.51MBa5da70777097: Loading layer [==================================================&gt;] 21.51MB/21.51MBLoaded image: goharbor/harbor-jobservice:v1.7.1ab31dfc84e9d: Loading layer [==================================================&gt;] 8.954MB/8.954MBb130423af762: Loading layer [==================================================&gt;] 13.43MB/13.43MB357c059d0598: Loading layer [==================================================&gt;] 17.3MB/17.3MBfabc6edfac55: Loading layer [==================================================&gt;] 11.26kB/11.26kBcfaa3b5d445a: Loading layer [==================================================&gt;] 3.072kB/3.072kB12c73a4b2c7a: Loading layer [==================================================&gt;] 30.72MB/30.72MBLoaded image: goharbor/notary-server-photon:v0.6.1-v1.7.150a6467bd619: Loading layer [==================================================&gt;] 113MB/113MB6ae61fc91943: Loading layer [==================================================&gt;] 11.46MB/11.46MB5c840c272f78: Loading layer [==================================================&gt;] 2.048kB/2.048kB077d16ebcba8: Loading layer [==================================================&gt;] 48.13kB/48.13kBb822f5ff7858: Loading layer [==================================================&gt;] 3.072kB/3.072kB4548140152fd: Loading layer [==================================================&gt;] 11.51MB/11.51MBLoaded image: goharbor/clair-photon:v2.0.7-v1.7.1232024be30e3: Loading layer [==================================================&gt;] 3.39MB/3.39MBa73624ae3fad: Loading layer [==================================================&gt;] 4.721MB/4.721MB96b8c5c532c3: Loading layer [==================================================&gt;] 3.584kB/3.584kBLoaded image: goharbor/harbor-portal:v1.7.1e2fd12afe6e8: Loading layer [==================================================&gt;] 63.31MB/63.31MBe973513bcb58: Loading layer [==================================================&gt;] 40.74MB/40.74MB4f45af643b2b: Loading layer [==================================================&gt;] 6.656kB/6.656kB54a84094f024: Loading layer [==================================================&gt;] 2.048kB/2.048kB2d78cf8a687b: Loading layer [==================================================&gt;] 7.68kB/7.68kBe96067b83a72: Loading layer [==================================================&gt;] 2.56kB/2.56kB38a7d304147f: Loading layer [==================================================&gt;] 2.56kB/2.56kBa36c0cb6a35a: Loading layer [==================================================&gt;] 2.56kB/2.56kBLoaded image: goharbor/harbor-db:v1.7.1b0c31ad64c85: Loading layer [==================================================&gt;] 65.01MB/65.01MB22fbab41769e: Loading layer [==================================================&gt;] 3.072kB/3.072kB7f28bf5373b2: Loading layer [==================================================&gt;] 59.9kB/59.9kBabb9969cff2a: Loading layer [==================================================&gt;] 61.95kB/61.95kBLoaded image: goharbor/redis-photon:v1.7.1933cd9a15fc5: Loading layer [==================================================&gt;] 3.39MB/3.39MBLoaded image: goharbor/nginx-photon:v1.7.16ee16a137af2: Loading layer [==================================================&gt;] 8.955MB/8.955MB954443cb7d20: Loading layer [==================================================&gt;] 22.8MB/22.8MB302a998137db: Loading layer [==================================================&gt;] 3.072kB/3.072kBe342723aef9b: Loading layer [==================================================&gt;] 7.465MB/7.465MB4eeb61ed730b: Loading layer [==================================================&gt;] 30.26MB/30.26MBLoaded image: goharbor/harbor-registryctl:v1.7.15b40d957fafd: Loading layer [==================================================&gt;] 12.11MB/12.11MB63489681dd6c: Loading layer [==================================================&gt;] 17.3MB/17.3MB696209dcd336: Loading layer [==================================================&gt;] 11.26kB/11.26kB8dc53997aa1f: Loading layer [==================================================&gt;] 3.072kB/3.072kBcb6d560a9958: Loading layer [==================================================&gt;] 29.41MB/29.41MBLoaded image: goharbor/notary-signer-photon:v0.6.1-v1.7.1dc1e16790c89: Loading layer [==================================================&gt;] 8.96MB/8.96MB046c7e7a0100: Loading layer [==================================================&gt;] 35.08MB/35.08MB8c8428e3d6c6: Loading layer [==================================================&gt;] 2.048kB/2.048kBebb477ee35a2: Loading layer [==================================================&gt;] 3.072kB/3.072kB19636f39e29d: Loading layer [==================================================&gt;] 35.08MB/35.08MBLoaded image: goharbor/chartmuseum-photon:v0.7.1-v1.7.1[Step 2]: preparing environment ...Generated and saved secret to file: /data/secretkeyGenerated configuration file: ./common/config/nginx/nginx.confGenerated configuration file: ./common/config/adminserver/envGenerated configuration file: ./common/config/core/envGenerated configuration file: ./common/config/registry/config.ymlGenerated configuration file: ./common/config/db/envGenerated configuration file: ./common/config/jobservice/envGenerated configuration file: ./common/config/jobservice/config.ymlGenerated configuration file: ./common/config/log/logrotate.confGenerated configuration file: ./common/config/registryctl/envGenerated configuration file: ./common/config/core/app.confCreating harbor-log ... doneThe configuration files are ready, please use docker-compose to start the service.[Step 3]: checking existing instance of Harbor ...Creating registry ... doneCreating harbor-core ... done[Step 4]: starting Harbor ...Creating harbor-portal ... doneCreating nginx ... doneCreating harbor-adminserver ... Creating harbor-db ... Creating redis ... Creating registry ... Creating registryctl ... Creating harbor-core ... Creating harbor-jobservice ... Creating harbor-portal ... Creating nginx ... ✔ ----Harbor has been installed and started successfully.----Now you should be able to visit the admin portal at http://172.18.74.101. For more details, please visit https://github.com/goharbor/harbor . 在安装 脚本执行过程过程中看到下拉了很多镜像，Harbor的每个组件都是以Docker 容器的形式构建的。 1234567891011121314151617181920212223242526272829[root@Web2 ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEgoharbor/chartmuseum-photon v0.7.1-v1.7.1 f61c186d5b1b 6 days ago 111MBgoharbor/harbor-migrator v1.7.1 9ec6467899b6 6 days ago 799MBgoharbor/redis-photon v1.7.1 c7aa92fb1c26 6 days ago 96.3MBgoharbor/clair-photon v2.0.7-v1.7.1 832461eef7dd 6 days ago 165MBgoharbor/notary-server-photon v0.6.1-v1.7.1 382cd390eaff 6 days ago 102MBgoharbor/notary-signer-photon v0.6.1-v1.7.1 76486e1aa1a2 6 days ago 99.6MBgoharbor/harbor-registryctl v1.7.1 aefea98e6f92 6 days ago 101MBgoharbor/registry-photon v2.6.2-v1.7.1 13b348ffd0c9 6 days ago 86.4MBgoharbor/nginx-photon v1.7.1 9b9520572494 6 days ago 35.5MBgoharbor/harbor-log v1.7.1 0744800d7a4c 6 days ago 81MBgoharbor/harbor-jobservice v1.7.1 db96ce6ed531 6 days ago 83.8MBgoharbor/harbor-core v1.7.1 8f253c0f9d50 6 days ago 95.2MBgoharbor/harbor-portal v1.7.1 b50162ab177a 6 days ago 40.2MBgoharbor/harbor-adminserver v1.7.1 22d66cccedba 6 days ago 72MBgoharbor/harbor-db v1.7.1 c2a95254c0bf 6 days ago 133MB[root@Web2 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf007d1aae3fa goharbor/nginx-photon:v1.7.1 &quot;nginx -g &apos;daemon of…&quot; About a minute ago Up About a minute (healthy) 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:4443-&gt;4443/tcp nginxbf48e808d152 goharbor/harbor-portal:v1.7.1 &quot;nginx -g &apos;daemon of…&quot; About a minute ago Up About a minute (healthy) 80/tcp harbor-portal0d78ea5ff51f goharbor/harbor-jobservice:v1.7.1 &quot;/harbor/start.sh&quot; About a minute ago Up About a minute harbor-jobservicec07ca8d7cf72 goharbor/harbor-core:v1.7.1 &quot;/harbor/start.sh&quot; About a minute ago Up About a minute (healthy) harbor-cored6ce992225e9 goharbor/harbor-adminserver:v1.7.1 &quot;/harbor/start.sh&quot; About a minute ago Up About a minute (healthy) harbor-adminserver86200773e6fc goharbor/harbor-registryctl:v1.7.1 &quot;/harbor/start.sh&quot; About a minute ago Up About a minute (healthy) registryctla496f40a1d95 goharbor/harbor-db:v1.7.1 &quot;/entrypoint.sh post…&quot; About a minute ago Up About a minute (healthy) 5432/tcp harbor-dbbecbead56360 goharbor/redis-photon:v1.7.1 &quot;docker-entrypoint.s…&quot; About a minute ago Up About a minute 6379/tcp redisb66044203146 goharbor/registry-photon:v2.6.2-v1.7.1 &quot;/entrypoint.sh /etc…&quot; About a minute ago Up About a minute (healthy) 5000/tcp registryd6f266aa5a49 goharbor/harbor-log:v1.7.1 &quot;/bin/sh -c /usr/loc…&quot; About a minute ago Up About a minute (healthy) 127.0.0.1:1514-&gt;10514/tcp harbor-log 以admin/Harbor12345 默认登录名密码进行登录 将镜像推送至registryHarbor的默认安装使用HTTP协议，需要将 –insecure-registry 参数添加进客户端的daemon.json 。 12345root@ubuntu16:~# vim /etc/docker/daemon.json&#123; &quot;insecure-registries&quot;:[&quot;172.18.74.101&quot;]&#125;root@ubuntu16:~# systemctl restart docker 然后以admin身份登录 1234root@ubuntu16:~# docker login 172.18.74.101Username: adminPassword: Login Succeeded 对镜像进行打标 ，使用docker tag 命令 12345root@ubuntu16:~# docker tag alpine 172.18.74.101/library/alpine:latestroot@ubuntu16:~# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEalpine latest 196d12cf6ab1 4 months ago 4.41MB172.18.74.101/library/alpine latest 196d12cf6ab1 4 months ago 4.41MB 推送镜像 1234root@ubuntu16:~# docker push 172.18.74.101/library/alpineThe push refers to a repository [172.18.74.101/library/alpine]df64d3292fd6: Pushed latest: digest: sha256:76ebd8b93b384fe8121d87be22c2089843f663fb342f1e6345a0a0bd6424c5c2 size: 528 推送后在Harbor中即可看到alpine镜像 Harbor管理使用docker-compose命令可以用来管理Harbor，但是必须与docker-compose.yml在同一目录中运行，否则报错如下。 12345ERROR: Can&apos;t find a suitable configuration file in this directory or any parent. Are you in the right directory? Supported filenames: docker-compose.yml, docker-compose.yaml 使用 docker-compose stop 来关闭Harbor和docker-compose start 关闭后进行重启。 123456789101112131415161718192021222324[root@Web2 harbor]# docker-compose stopStopping nginx ... doneStopping harbor-portal ... doneStopping harbor-jobservice ... doneStopping harbor-core ... doneStopping harbor-adminserver ... doneStopping registryctl ... doneStopping harbor-db ... doneStopping redis ... doneStopping registry ... doneStopping harbor-log ... done[root@Web2 harbor]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@Web2 harbor]# docker-compose startStarting log ... doneStarting redis ... doneStarting adminserver ... doneStarting registryctl ... doneStarting registry ... doneStarting core ... doneStarting portal ... doneStarting jobservice ... doneStarting postgresql ... doneStarting proxy ... done 要更改Harbour的配置，要停止现有的Harbor实例并更新 harbor.cfg。然后运行 prepare 脚本以填充配置。最后重新创建并启动Harbor 1234sudo docker-compose down -vvim harbor.cfgsudo preparesudo docker-compose up -d 默认情况下，注册表数据保留在主机的/data/目录中。即使Harbor的容器被移除和/或重新创建，此数据仍保持不变。 1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@Web2 data]# lsca_download config database job_logs psc redis registry secretkey[root@Web2 data]# cd registry/[root@Web2 registry]# tree.└── docker └── registry └── v2 ├── blobs │ └── sha256 │ ├── 19 │ │ └── 196d12cf6ab19273823e700516e98eb1910b03b17840f9d5509f03858484d321 │ │ └── data │ ├── 76 │ │ └── 76ebd8b93b384fe8121d87be22c2089843f663fb342f1e6345a0a0bd6424c5c2 │ │ └── data │ └── c4 │ └── c432c1aab6335df5a9ff6237f8d19627f95ea7dc3f5709c555b2a28cd8df4d0a │ └── data └── repositories └── library └── alpine ├── _layers │ └── sha256 │ ├── 196d12cf6ab19273823e700516e98eb1910b03b17840f9d5509f03858484d321 │ │ └── link │ └── c432c1aab6335df5a9ff6237f8d19627f95ea7dc3f5709c555b2a28cd8df4d0a │ └── link ├── _manifests │ ├── revisions │ │ └── sha256 │ │ └── 76ebd8b93b384fe8121d87be22c2089843f663fb342f1e6345a0a0bd6424c5c2 │ │ └── link │ └── tags │ └── latest │ ├── current │ │ └── link │ └── index │ └── sha256 │ └── 76ebd8b93b384fe8121d87be22c2089843f663fb342f1e6345a0a0bd6424c5c2 │ └── link └── _uploads29 directories, 8 files 此外，Harbor使用 rsyslog 来收集每个容器的日志。默认情况下，这些日志文件存储在/var/log/harbor/目标主机上的目录中以进行故障排除。 123[root@Web2 registry]# cd /var/log/harbor/[root@Web2 harbor]# lsadminserver.log core.log jobservice.log portal.log postgresql.log proxy.log redis.log registryctl.log registry.log 删除Harbor的容器，同时将图像数据和Harbor的数据库文件保存在文件系统上： 1sudo docker-compose down -v 删除Harbor的数据库和图像数据（用于重新安装）： 12rm -r / data / database rm -r / data / registry 自定义配置Harbor监听端口1.修改docker-compose.yml将默认的80:80 修改为8888:80，访问主机8888端口nginx容器就可以代理至harbor-portal容器的80端口 1234567891011121314151617181920proxy: image: goharbor/nginx-photon:v1.6.0 container_name: nginx restart: always volumes: - ./common/config/nginx:/etc/nginx:z ports: - 8888:80 //将默认的80:80 修改为8888:80 - 443:443 depends_on: - postgresql - registry - core - portal - log logging: driver: &quot;syslog&quot; options: syslog-address: &quot;tcp://127.0.0.1:1514&quot; tag: &quot;proxy&quot; 2. 修改harbor.cfg1hostname = 172.18.74.101:8888 3.重新部署Harbor见上文]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker私有仓库docker-registry搭建]]></title>
    <url>%2F2019%2F01%2F09%2Fdocker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93docker-registry%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[关于docker-registryThe Registry is a stateless, highly scalable server side application that stores and lets you distribute Docker images. The Registry is open-source, under the permissive Apache license.（docker documents） docker-registry是一个无状态的、可高度伸缩的服务器端应用程序，可以存储并允许您分发docker 镜像。docker-registry是开源的，是Apache许可证所允许的。 使用互联网上的的registry会受到网络因素的跟大影响，在pull 和push 时速度会不尽人意，在生产环境中并行启动的容器不会只有一两个会是几十上百个，而且并不能保证docker host 本地拥有所需要的所有镜像，所以通过互联网去下载就无法做到快速启动了很明显违背了容器轻量快速部署的初衷，此时就要自己在本地搭建私有registry。如果运维的系统环境托管在云服务上例如阿里云，那我们就去使用阿里的registry服务，也就是说将其建在生产环境的服务器的局域网中以达到更快的目的。 在Docker Hub中有registry镜像，pull下来即可使用，用法在上一篇博客中已经说到 docker-registry安装还有一种简单的方法就是Docker 提供了一个docker-distribution程序包 我们直接yum安装即可查看其安装生成的文件config.yml 是配置文件，registry是主程序，启动服务是docker-distribution.services, 数据存储在/var/lib/registry 在config.yml中可以修改缓存、存储路径、监听端口等，如果作为专门的rigistry应该把端口改成80或者https的443 1systemctl start docker-distribution //启动服务 然后就可以push镜像了 在另外一台主机上向刚搭建好的registry推送镜像推送之前还应该说一下docker镜像的命名规则 The Docker Registry is a component of Docker’s ecosystem. A registry is a storage and content delivery system, holding named Docker images, available in different tagged versions. For example, the image distribution/registry, with tags 2.0 and latest. Users interact with a registry by using docker push and pull commands such as docker pull myregistry.com/stevvooe/batman:voice.Docker Hub is an instance of a Docker Registry. Docker仓库是Docker生态系统的一部分。registry是一个存储和交付系统，支持命名镜像，存在不同的标记版本。例如一个镜像 distribution/registry 拥有2.0 和latest标记。用户和registry交互使用docker push 和docker pull命令例如:docker pull myregistry.com/stevvooe/batman:voice.Docker Hub是docker registry的一个实例。 也就是说用仓库名加标签来唯一标识一个镜像，只不过平常我们使用docker pull centos 时，docker.io为默认域名，latest为默认标签即docker pull docker.io/library/centos:latest 所以在我们docke push 镜像时，同样也要遵守命名规则 我们使用docker tag 进行打标 1docker tag hadoop web1:5000/hadoop:1.0 这里使用顶层仓库 123root@ubuntu16:~# docker push web1:5000/hadoop:1.0The push refers to a repository [web1:5000/hadoop]Get https://web1:5000/v1/_ping: http: server gave HTTP response to HTTPS client 报错为 http服务器响应https客户端，docker push 默认基于https协议工作，服务器端支持http ，二者不兼容。 我们搭建的是内网的仓库使用http协议就可以，修改客户端的docker daemon 1234vim /etc/docker/daemon.json&#123; &quot;insecure-registries&quot; : [&quot;web1:5000&quot;]&#125;systemctl restart docker 再去docker push 就可以了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071[root@Web2 registry]# tree /var/lib/registry//var/lib/registry/└── docker └── registry └── v2 ├── blobs │ └── sha256 │ ├── 09 │ │ └── 09d6e0703b59972f3832b563f62afeb0a4d952d79724c933543b4ecd389ac7c3 │ │ └── data │ ├── 53 │ │ └── 5301edc7ec17551bb197f15b3e9708231924392df6d403ac22cc897da75c6c5b │ │ └── data │ ├── 7c │ │ └── 7cab4876127f1e8ad7460cc656f61e7203cf8a04cebb5585c1e29f1c097266e9 │ │ └── data │ ├── 89 │ │ └── 8916107b7faec7a28f9bfb0d59579a51b8b9f80835b0ed134f5f511deae095be │ │ └── data │ ├── 95 │ │ └── 95acc0e10968e9babf3a942a085279db4269728c4c77f8f3a7d5e208108908c6 │ │ └── data │ ├── 96 │ │ └── 967a799109e4d74670438c51aba1b270c0f72caca675342acc955512f11e7459 │ │ └── data │ ├── a1 │ │ └── a185367e7bddc7bb3f22e43f388c0e9aefb2e6b679d2cbed1a3c7ff1f584dbf1 │ │ └── data │ ├── a4 │ │ └── a4dd3fbaa1db732a34a7ecf2e1f40a095aab3dab94109fd7c628c8966071944e │ │ └── data │ └── f4 │ └── f4236122778c0399bad22e265f9c017b5eb6aaead18ea21a21f5c0d9c97e907f │ └── data └── repositories └── hadoop ├── _layers │ └── sha256 │ ├── 09d6e0703b59972f3832b563f62afeb0a4d952d79724c933543b4ecd389ac7c3 │ │ └── link │ ├── 5301edc7ec17551bb197f15b3e9708231924392df6d403ac22cc897da75c6c5b │ │ └── link │ ├── 7cab4876127f1e8ad7460cc656f61e7203cf8a04cebb5585c1e29f1c097266e9 │ │ └── link │ ├── 8916107b7faec7a28f9bfb0d59579a51b8b9f80835b0ed134f5f511deae095be │ │ └── link │ ├── 95acc0e10968e9babf3a942a085279db4269728c4c77f8f3a7d5e208108908c6 │ │ └── link │ ├── 967a799109e4d74670438c51aba1b270c0f72caca675342acc955512f11e7459 │ │ └── link │ ├── a4dd3fbaa1db732a34a7ecf2e1f40a095aab3dab94109fd7c628c8966071944e │ │ └── link │ └── f4236122778c0399bad22e265f9c017b5eb6aaead18ea21a21f5c0d9c97e907f │ └── link ├── _manifests │ ├── revisions │ │ └── sha256 │ │ └── a185367e7bddc7bb3f22e43f388c0e9aefb2e6b679d2cbed1a3c7ff1f584dbf1 │ │ └── link │ └── tags │ └── 1.0 │ ├── current │ │ └── link │ └── index │ └── sha256 │ └── a185367e7bddc7bb3f22e43f388c0e9aefb2e6b679d2cbed1a3c7ff1f584dbf1 │ └── link └── _uploads46 directories, 20 files[root@Web2 registry]# 使用tree 命令完整的看到了/var/lib/registry/ 下的目录结构，hadoop镜像已经存在，镜像的每一层都是单独推送单独存放。再找一台服务器 执行docker pull 命令， 同样需要修改daemon.json中的内容，使用http协议。 docker-registry搭建完成。 上一篇博客感觉很粗糙，做的很仓促，本篇博客再重新梳理一下。]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[上传镜像至docker Hub，以及搭建本地私有仓库]]></title>
    <url>%2F2019%2F01%2F08%2F%E4%B8%8A%E4%BC%A0%E9%95%9C%E5%83%8F%E8%87%B3docker-Hub%EF%BC%8C%E4%BB%A5%E5%8F%8A%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[仓库（Repository）是集中存放镜像的地方，分为公共仓库和私有仓库注册服务器（Registry）是存放仓库的具体服务器，一个注册服务器上可以有多个仓库，每个仓库下面有多个镜像 首先要说的是docker Hub 公共镜像市场本地执行docker iogin 登陆 官方给出的命令 1docker pull 注册仓库/仓库名 这里需要将要上传的镜像改名，在名称前加上自己dockerHub的ID 速度很慢，需要配置镜像加速器，我配置的是阿里的配置镜像加速器 里面会有自己专用的加速连接 1234567891011mkdir -p /etc/dockervim daemon.json&#123; &quot;registry-mirrors&quot;: [&quot;your accelerate address&quot;]&#125; systemctl daemon-reload systemctl restart docker 再次上传就很快了 来到docker hub就可以看到了 可以通过官方提供的registry 镜像来搭建本地私有仓库环境 1docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry 可以看到容器已经启动了，映射主机5000端口，容器的/tmp/registry 挂载到主机/opt/data/registry目录，地址为172.17.0.2:5000docker tag 将要上传的镜像进行标记（docker tag Image[:tag] [Registryhost/] [Username/] Name [:Tag]） 1docker tag centos 172.17.0.2:5000/test 配置对仓库进行的安全性检查 在/etc/docker/daemon.json1&#123;&quot;insecure-registries&quot;:[&quot;172.17.0.2:5000&quot;]&#125; 123systemctl restart dockerdocker restart e46 重启registry 容器netstat -ntl 查看5000端口是否开放 1docker push 172.17.0.2：5000/test 1curl -XGET http://172.17.0.2:5000/v2/_catalog 可以看到镜像存在 删除本地镜像 1docker pull 172.17.0.2:500/test 可以看到镜像被拉下来了]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPv6（RIP、OSPF、EIGRP、DHCP、双栈、隧道）]]></title>
    <url>%2F2019%2F01%2F07%2FIPv6%EF%BC%88RIP%E3%80%81OSPF%E3%80%81EIGRP%E3%80%81DHCP%E3%80%81%E5%8F%8C%E6%A0%88%E3%80%81%E9%9A%A7%E9%81%93%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本篇博客介绍了Ipv6 的各种基本配置，也是本学期本门课的一个总结，使用Cisco Packet Tracer7.0 和GNS3 0.8 模拟器进行的以下实验 ，路由器选型为cisco 2911，Gns3中是c2691。 实验一 IPv6 IP地址配置方法（2911） 设备 接口 IP地址 &emsp;Router0&emsp; &emsp;g0/0 &emsp; &emsp;&emsp;2001:0db8:cafe:A001::2/64&emsp;&emsp; &emsp; &emsp;g0/1 &emsp;&emsp;2001:0db8:cafe:A002::2/64 &emsp; &emsp;g0/2 &emsp;&emsp;2001:0db8:cafe:0002::1/64 &emsp;Router1 &emsp;g0/0 &emsp;&emsp;2001:0db8:cafe:A001::1/64 &nbsp; &emsp;g0/1 &emsp;&emsp;2001:0db8:cafe:A003::1/64 &nbsp; &emsp;g0/2 &emsp;&emsp;2001:0db8:cafe:0001::1/64 &emsp;Router2 &emsp;g0/0 &emsp;&emsp;2001:0db8:cafe:A003::2/64 &nbsp; &emsp;g0/1 &emsp;&emsp;2001:0db8:cafe:A002::1/64 &nbsp; &emsp;g0/2 &emsp;&emsp;2001:0db8:feed:0001::1/64 &emsp;Router3 &emsp;g0/0 &emsp;&emsp;2001:0db8:feed:0001::2/64 &nbsp; &emsp;g0/1 &emsp;&emsp;2001:0db8:face:c0de::1/64 &emsp;PC 0 &nbsp; &emsp;&emsp;2001:0db8:cafe:0001::2/64 &emsp;PC 1 &nbsp; &emsp;&emsp;2001:0db8:face:c0de::2/64 &emsp;PC2 &nbsp; &emsp;&emsp;2001:0db8:cafe:0002::2/64 123456789101112131415161718192021222324252627Route1Router&gt;enableRouter#config terminalRouter(config)#ipv6 unicast-routing // 开启 IPV6流量转发Router(config)#int g0/0Router(config)#no shutdownRouter(config-if)#ipv6 add 2001:0db8:cafe:A001::1/64 //前64位为网络地址；后64位为主机位Router#show ipv6 interface brief使用EUI-64格式配置静态地址：Router(config)#int g0/1Router(config)#no shutdownRouter(config-if)#ipv6 address 2001:0db8:cafe:A003::1/64 euRouter(config-if)#ipv6 address 2001:0db8:cafe:A003::1/64 eui-64仅启用接口IPv6功能Router#conf tRouter(config)#int g0/2Router(config)#no shutdownRouter(config-if)#ipvRouter(config-if)#ipv6 enable //会自动分配Ipv6地址配置无编号地址Router(config)#interface f0/3/0Router(config)#no shutdownRouter(config-if)#ipv6 unnumbered g0/0 // 结果显示为接口f0/3/0借用g0/0的地址 实验二 静态路由配置 1. 直连静态路由12r1(config)#ipv6 route 2022:2:2:22::/64 e1/1到达目标网络2022:2:2:22::/64 的数据包从接口e1/1发出去 2.递归静态路由12r1(config)#ipv6 route 2022:2:2:22::/64 2012:1:1:11::2 到达目标网络2022:2:2:22::/64 的数据包发给下一跳地址2012:1:1:11::2 3.完全静态路由12r1(config)#ipv6 route 2022:2:2:22::/64 f0/0 2012:1:1:11::2 到达目标网络2022:2:2:22::/64 的数据包从接口F0/0发出去，并且交给下一跳地址2012:1:1:11::2 1234567891011配置递归路由(pc0 ping pc1)pc0至pc1Router1(config)#ipv6 unicast-routingRouter1(config)#ipv6 route 2001:0db8:face:c0de::/64(pc1网段) 2001:0db8:cafe:A003::2(Route2g0/0)Router2(config)#ipv6 unicast-routingRouter2(config)#ipv6 route 2001:0db8:face:c0de::/64(pc1网段) 2001:0db8:feed:0001::2(Route3g0/0)pc1 至PC0Router3(config)#ipv6 unicast-routingRouter3(config)#ipv6 route 2001:0db8:cafe:1::/64(pc0网段) 2001:0db8:feed:0001::1(Route2g0/2)Router3(config)#ipv6 unicast-routingRouter(config)#ipv6 route 2001:0db8:cafe:1::/64(pc0网段) 2001:0db8:cafe:A003::1(Route1g0/1)** PC0 ping PC1 实验三 IPv6 RIP (RIPng)基础实验 以Route2为例12345678910111213Router2&gt;enRouter2#conf tRouter1(config)#ipv6 unicast-routing // 开启IPv6路由转发Router2(config)#ipv6 router rip test //启动IPv6 RIPng进程，RIP进程名字为testRouter2(config-rtr)#int g0/0Router2(config-if)#no shutdownRouter2(config-if)#ipv6 rip test enableRouter2(config-if)#int g0/1Router2(config-if)#no shutdownRouter2(config-if)#ipv6 rip test enableRouter2(config-if)#int g0/2Router2(config-if)#no shutdownRouter2(config-if)#ipv rip test enable 所有路由器的所有接口都要进行配置! 下面查看Route2的RIP数据库 1234567891011121314151617181920Router2#show ipv6 rip database //查看IPv6数据库RIP process &quot;test&quot; local RIB2001:DB8:CAFE:1::/64, metric 2, installed // 路由条目装入路由表GigabitEthernet0/0/FE80::2E0:F7FF:FE48:CB02, expires in 151 sec2001:DB8:CAFE:2::/64, metric 2, installedGigabitEthernet0/1/FE80::2E0:8FFF:FE67:C502, expires in 161 sec2001:DB8:CAFE:A001::/64, metric 2, installedGigabitEthernet0/0/FE80::2E0:F7FF:FE48:CB02, expires in 151 sec2001:DB8:CAFE:A001::/64, metric 2, installedGigabitEthernet0/0/FE80::2E0:F7FF:FE48:CB02, expires in 151 sec2, installedGigabitEthernet0/1/FE80::2E0:8FFF:FE67:C502, expires in 161 sec2001:DB8:CAFE:A002::/64, metric 2GigabitEthernet0/1/FE80::2E0:8FFF:FE67:C502, expires in 161 sec2001:DB8:CAFE:A003::/64, metric 2GigabitEthernet0/0/FE80::2E0:F7FF:FE48:CB02, expires in 151 sec2001:DB8:FACE:C0DE::/64, metric 2, installedGigabitEthernet0/2/FE80::2D0:BAFF:FE71:9201, expires in 166 sec2001:DB8:FEED:1::/64, metric 2GigabitEthernet0/2/FE80::2D0:BAFF:FE71:9201, expires in 166 secRouter2# 在Pc0上进行检测 实验四 OSPFv3基础实验 1234567891011121314151617181920212223242526272829303132以Route1为例Router1&gt;enRouter1#conf tRouter1(config)#ipv6 unicast-routing // 开启Ipv6路由转发Router1(config)#ipv6 router ospf 2 // 启动OSPFv3进程%OSPFv3-4-NORTRID: OSPFv3 process 2 could not pick a router-id,please configure manually //要求手工指定router-idRouter1(config-rtr)#router-id 1.1.1.1 //给OSPF路由器指定身份，每个路由器的route-id都是唯一的Router1(config-rtr)#int g0/0Router1(config-if)#no shutdownRouter1(config-if)#ipv6 ospf 2 area 0Router1(config-if)#int g0/1Router1(config-if)#no shutdownRouter1(config-if)#ipv6 ospf 2 area 0Router1(config-if)#int g0/2Router1(config-if)#no shutdownRouter1(config-if)#ipv6 ospf 2 area 0在Route 0 路由器Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routingRouter(config)#ipv6 router ospf 2%OSPFv3-4-NORTRID: OSPFv3 process 2 could not pick a router-id,please configure manuallyRouter(config-rtr)#router-id 4.4.4.4Router(config-rtr)#int g0/0Router(config-if)#no shutdownRouter(config-if)#ipv6 ospf 2 area 0Router(config-if)#int g0/1Router(config-if)#no shutdownRouter(config-if)#ipv6 ospf 2 area 0Router(config-if)#int g0/2Router(config-if)#no shutdownRouter(config-if)#ipv6 ospf 2 area 0 Route2，Route3同理 实验五 IPv6 EIGRP实验 1234567891011121314151617181920212223242526272829303132333435363738394041R1 // R2 同理，此处不再进行配置演示R1#conf t // R1初始配置R1(config)#ipv6 unicast-routingR1(config)#int g0/0R1(config-if)#no shutdownR1(config-if)#ipv6 add 2012:1:1:11::1/64R1(config-if)#exitR1(config)#int loopback 1R1(config-if)#no shutdownR1(config-if)#ipv6 add 3001:1:1:11::1/64R1(config-if)#exitR1(config)#int loopback 2R1(config-if)#no shutdownR1(config-if)#ipv6 add 3002:1:1:11::1/64R1(config-if)#exitR1(config)#int loopback 3R1(config-if)#no shR1(config-if)#ipv6 add 3003:1:1:11::1/64R1#show ipv6 interface briFastEthernet0/0 [up/up] FE80::C204:8FF:FEB8:0 2012:1:1:11::1FastEthernet0/1 [administratively down/down] unassignedLoopback1 [up/up] FE80::C204:8FF:FEB8:0 3001:1:1:11::1Loopback2 [up/up] FE80::C204:8FF:FEB8:0 3002:1:1:11::1Loopback3 [up/up] FE80::C204:8FF:FEB8:0 3003:1:1:11::1R1(config)#ipv6 router eigrp 10 // 在R1上启动EIGRP v6进程R1(config-rtr)#no shutdown //EIGRP v6进程默认是shutdown的，必须手工开启R1(config-rtr)#eigrp router-id 1.1.1.1R1(config)#int g0/0 //将 R1上的接口放进EIGRP v6进程R1(config-if)#ipv6 eigrp 10 R1(config-if)#exitR1(config)#int loopback 1R1(config-if)#ipv6 eigrp 10 重分布IPv6网段 将R1上的剩余网段重分布进EIGRP v6 123456789101112131415161718192021222324r1(config)#route-map con permit 10 //在R1上配置重分布剩余网段进EIGRP v6r1(config-route-map)#match interface loopback 2r1(config-route-map)#exitr1(config)#route-map con permit 20 r1(config-route-map)#match interface loopback 3 r1(config)#ipv6 router eigrp 10r1(config-rtr)#redistribute connected route-map conr1(config-rtr)#exit在R2上查看重分布进EIGRP v6的剩余网段r2#sh ipv6 route eigrp IPv6 Routing Table - 9 entriesCodes: C - Connected, L - Local, S - Static, R - RIP, B - BGP U - Per-user Static route I1 - ISIS L1, I2 - ISIS L2, IA - ISIS interarea, IS - ISIS summary O - OSPF intra, OI - OSPF inter, OE1 - OSPF ext 1, OE2 - OSPF ext 2 ON1 - OSPF NSSA ext 1, ON2 - OSPF NSSA ext 2 D - EIGRP, EX - EIGRP externalD 3001:1:1:11::/64 [90/409600] via FE80::C200:9FF:FE54:0, FastEthernet0/0EX 3002:1:1:11::/64 [170/409600] via FE80::C200:9FF:FE54:0, FastEthernet0/0EX 3003:1:1:11::/64 [170/409600] via FE80::C200:9FF:FE54:0, FastEthernet0/0r2# 过滤IPv6路由 在R2上过滤掉IPv6路由，只留想要的网段，使用distribute-list过滤 1234567891011121314r2(config)#ipv6 prefix-list abc permit 3002:1:1:11::/64 //配置只留3002:1:1:11::/64网段r2(config)#ipv6 router eigrp 10r2(config-rtr)#distribute-list prefix-list abc in f0/0r2#sh ipv6 route eigrp IPv6 Routing Table - 7 entriesCodes: C - Connected, L - Local, S - Static, R - RIP, B - BGP U - Per-user Static route I1 - ISIS L1, I2 - ISIS L2, IA - ISIS interarea, IS - ISIS summary O - OSPF intra, OI - OSPF inter, OE1 - OSPF ext 1, OE2 - OSPF ext 2 ON1 - OSPF NSSA ext 1, ON2 - OSPF NSSA ext 2 D - EIGRP, EX - EIGRP externalEX 3002:1:1:11::/64 [170/409600] via FE80::C200:9FF:FE54:0, FastEthernet0/0r2# 实验七 IPv6地址SLAAC与有状态自动配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344451.配置无状态自动获得IP地址（SLAAC）R1Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routingRouter(config)#int g0/0Router(config-if)#ipv6 address 2023::2/64Router(config-if)#no shutdownR2Router&gt;enRouter#conf tRouter(config)#int g0/0Router(config-if)#ipv6 address autoconfigRouter(config-if)#no shRouter#show ipv6 int g0/0GigabitEthernet0/0 is up, line protocol is upIPv6 is enabled, link-local address is FE80::230:F2FF:FEC9:1D01No Virtual link-local address(es):Global unicast address(es):2023::230:F2FF:FEC9:1D01, subnet is 2023::/64Joined group address(es):FF02::1FF02::1:FFC9:1D01MTU is 1500 bytesICMP error messages limited to one every 100 millisecondsICMP redirects are enabledICMP unreachables are sentND DAD is enabled, number of DAD attempts: 1ND reachable time is 30000 millisecondsRouter#2.调整NDRouter1：interface g0/0ipv6 address 2023::2/64no shutdownipv6 nd ra-interval 5 //每5s通告一次RAipv6 nd ra-lifetime 1000 //RA的lifetimeipv6 nd prefix 2023::/64 5000 4000 //修改valid time和preferred time3.不希望SLAAC抑制RA消息：ipv6 nd ra suppress //对IOS版本有要求 实验八.DHCPv6分配 123456789101112131415161718192021222324252627282930313233343536373839401.无状态自动配置注：此时地址是EUI/64获取的，而其他信息是由DHCP获取的Router1:Ipv6 unicast-routingipv6 dhcp pool cafe-1dns-server 2022::2domain-name www.heuet.edu.cninterface G0/0ipv6 address 2023::2/64ipv6 dhcp server café-1ipv6 nd other-config-flag //O置位Router2:interface g0/0ipv6 address autoconfig2.有状态自动配置Router1:Ipv6 unicast-routeipv6 dhcp pool cafe-1dns-server 2022::2domain-name www.heuet.edu.cnaddress prefix 2023:2323::/64interface g0/0ipv6 address 2023::2/64ipv6 dhcp server cafe-1ipv6 nd other-config-flagipv6 nd managed-config-flag //M置位Router2:interface g0/0ipv6 enable //让接口获得link-local地址作为DHCP源来发送DHCP报文ipv6 address dhcp查看：Router1#sh ipv6 dhcp poolDHCPv6 pool: cafe-1DNS server: 2022::2Domain name: www.heuet.edu.cnActive clients: 1 //一个client 实验九 DHCPv6前缀代表 1234567891011121314151617181920DHCP SERVERRouter&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#ipv6 dhcp pool dhcpv6 //定义DHCP服务的名字Router(config-dhcpv6)#prefix-delegation pool dhcpv6-pool lifetime 1800 600 //创建DHCPV6-pool的前缀代//表地址池，并定义有效期Router(config-dhcpv6)#dns-server 2001:db8:3000:3000::42Router(config-dhcpv6)#domain-name www.heuet.edu.cnRouter(config-dhcpv6)#exit lRouter(config)#int g0/0Router(config-if)#ipv6 dhcp server dhcpv6 //在接口上启动DHCP服务对象Router(config-if)#exit Router(config)#ipv6 local pool dhcpv6-pool 2001:db8:1200::/40 48 //定义一个前缀长度为40的本地前缀代表//地址池,并且定义分配给DHCPv6-PD Client的前缀长度是48位Router(config)#int g0/0Router(config-if)#ipv6 add 2010:AB8::1/64Router(config-if)#ipv6 enable Router(config-if)#no shutdown 12345678910111213141516171819DHCP ClientRouter&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#int g0/0Router(config-if)#no shRouter(config-if)#ipv6 add autoconfig //无状态自动配置IPv6地址Router(config-if)#ipv6 enable Router(config-if)#ipv6 dhcp client pd prefix-from-pr //在接口上启用PD，将PD命名为prefix-from-prRouter(config-if)#Router(config-if)#int g0/1Router(config-if)#no shRouter(config-if)#ipv6 address prefix-from-pr ::1:0:0:0:1/64 配置接口从名字prefix-from-pr那里取得前缀，然后附加上1:0:0:0:1，最后形成接口的地址是2001：DB8:1200:1::1/64Router(config-if)#int g0/2Router(config-if)#no shRouter(config-if)#ipv6 address prefix-from-pr ::1/64 //接口地址为2001：DB8:1200:::1/64Router(config-if)# 123456789Client1Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#Router(config)#int g0/0Router(config-if)#no shRouter(config-if)#ipv6 address autoconfig //启用无状态自动获得IP地址Router#show ipv6 interface brief 12345678Client2Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#int g0/0Router(config-if)#no shRouter(config-if)#ipv6 add autoconfig //启用无状态自动获得IP地址Router#show ipv6 inter bri 实验十 IPv6、IPv4双栈实验 12345678910111213141516171819202122232425262728293031323334353637383940R0Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#ipv6 router ospf 1Router(config-rtr)#router-id 10.1.1.1Router(config-rtr)#int g0/0Router(config-if)#no shRouter(config-if)#ip add 10.10.10.1 255.255.255.252Router(config-if)#duplex auto Router(config-if)#speed auto Router(config-if)#Router(config-if)#ipv6 add 2001:DB8:CAFE:A001::1/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#exit Router(config)#int g0/1Router(config-if)#no shRouter(config-if)#ip add 10.10.10.9 255.255.255.252Router(config-if)#duplex auto Router(config-if)#speed auRouter(config-if)#ipv6 address 2001:DB8:CAFE:A003::1/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#exit Router(config)#int g0/2Router(config-if)#no shRouter(config-if)#ip add 10.1.0.1 255.255.0.0Router(config-if)#duplex auto Router(config-if)#speed auto Router(config-if)#ipv6 add 2001:DB8:CAFE::1/64Router(config-if)#ipv6 address 2001:DB8:CAFE:1::1/64Router(config-if)#ipvRouter(config-if)#ipv6 osRouter(config-if)#ipv6 ospf 1 arRouter(config-if)#ipv6 ospf 1 area 0Router(config-if)#router ospf 2Router(config-router)#log-adjacency-changes Router(config-router)#network 10.1.0.0 0.0.255.255 area 0Router(config-router)#network 10.10.10.0 0.0.0.3 area 0Router(config-router)#network 10.10.10.8 0.0.0.3 area 0Router(config-router)# 12345678910111213141516171819202122232425262728293031323334R1Router&gt;enRouter#conf tRouter(config)#ipv unicast-routing Router(config)#ipv6 router ospf 1Router(config-rtr)#router-id 10.3.3.3Router(config-rtr)#log-adjacency-changes Router(config-rtr)#int g0/0Router(config-if)#no shRouter(config-if)#ip address 10.10.10.6 255.255.255.252Router(config-if)#duplex auRouter(config-if)#speed auRouter(config-if)#ipv6 address 2001:DB8:CAFE:A002::2/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#int g0/1Router(config-if)#no shRouter(config-if)#ip address 10.10.10.10 255.255.255.252Router(config-if)#duplex auto Router(config-if)#speed auto Router(config-if)#ipv6 address 2001:DB8:CAFE:A003::2/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#int g0/2Router(config-if)#no shRouter(config-if)#ip address 10.3.0.1 255.255.0.0Router(config-if)#duplex auto Router(config-if)#speed auto Router(config-if)#ipv6 address 2001:DB8:CAFE:3::1/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#router ospf 2Router(config-router)#log-adjacency-changesRouter(config-router)#network 10.10.10.8 0.0.0.3 area 0Router(config-router)#network 10.10.10.4 0.0.0.3 area 0Router(config-router)#network 10.3.0.0 0.0.255.255 area 0Router(config-router)# 1234567891011121314151617181920212223242526272829303132R2Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#ipv6 router ospf 1Router(config-rtr)#router-id 10.2.2.2Router(config-rtr)#int g0/0Router(config-if)#no shRouter(config-if)#ip address 10.10.10.2 255.255.255.252Router(config-if)#duplex autoRouter(config-if)#speed autoRouter(config-if)#ipv6 address 2001:DB8:CAFE:A001::2/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#interface g0/1Router(config-if)#no shRouter(config-if)#ip address 10.10.10.5 255.255.255.252Router(config-if)#duplex autoRouter(config-if)#speed autoRouter(config-if)#ipv6 address 2001:DB8:CAFE:A002::1/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#int g0/2Router(config-if)#no shRouter(config-if)#ip address 10.2.0.1 255.255.0.0Router(config-if)#duplex auRouter(config-if)#speed autoRouter(config-if)#ipv6 address 2001:DB8:CAFE:2::1/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#router ospf 2Router(config-router)#log-adjacency-changesRouter(config-router)#network 10.10.10.0 0.0.0.3 area 0Router(config-router)#network 10.10.10.4 0.0.0.3 area 0Router(config-router)#network 10.2.0.0 0.0.255.255 area 0 实验十一 手工隧道 123456789101112131415161718R0Router&gt;enRouter#conf tRouter(config)#ipv6 UNicast-routing Router(config)#int g0/0Router(config-if)#no shRouter(config-if)#ipv6 address 2001:DB8:CAFE:1::1/64Router(config-if)#int g0/1Router(config-if)#no shRouter(config-if)#ip add 192.168.1.1 255.255.255.0Router(config-if)#int t0Router(config-if)#ipv6 address 2001:DB8:CAFF:1::1/64Router(config-if)#ipv6 enRouter(config-if)#tunnel source g0/1Router(config-if)#tunnel destination 192.168.1.2Router(config-if)#tunnel mode ipv6ipRouter(config-if)#ipv6 route 2001:DB8:ACE:2::/64 2001:DB8:CAFF:1::2Router(config)# 1234567891011121314151617R1Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#int g0/0Router(config-if)#ip address 192.168.1.2 255.255.255.0Router(config-if)#no shRouter(config-if)#int g0/1Router(config-if)#ipv6 address 2001:DB8:ACE:2::1/64Router(config-if)#no shRouter(config-if)#int t0Router(config-if)#ipv6 address 2001:DB8:CAFF:1::2/64Router(config-if)#ipv6 enRouter(config-if)#tunnel source g0/0Router(config-if)#tunnel destination 192.168.1.1Router(config-if)#tunnel mode ipv6ip Router(config-if)#i 实验十二 6to4隧道的配置 需要特别说明的是由于6to4隧道原理的特殊性，隧道端口的IPv4地址与IPv6网络的Ipv6地址有关联，所以分配IPv6网络的IP地址应该注意符合6to4隧道的编码要求。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970R1R1#conf tR1(config)#ipv6 unicast-routing //启用路由器的Ipv6转发功能R1(config)#int loopback 0R1(config-if)#ipv add 2002:0a01:0101:1::1/64R1(config-if)#int f0/1R1(config-if)#no shR1(config-if)#ip add 10.1.1.1 255.255.255.0R1(config)#router ospf 1 //配置IPv4网络的动态路由协议OSPFR1(config-router)#network 10.1.1.0 0.0.0.255 area 0R1(config)#int t0 创建隧道，并配置隧道的IPv6地址及隧道模式R1(config-if)#no shR1(config-if)#ipv enR1(config-if)#ipv6 address 2002:A01:101::1/64R1(config-if)#tunnel source f0/1R1(config-if)#tunnel mode ipv6ip 6to4R1(config)#ipv6 route 2002::/16 Tunnel0 //配置IPv6路由R2R2#conf tR2(config)#ipv6 unicast-routing //启用路由器的Ipv6转发功能R2(config)#int loopback 0R2(config-if)#ipv6 add 2002:0a03:0303:1::1/64R2(config-if)#int f0/1R2(config-if)#ip add 10.3.3.3 255.255.255.0R2(config-if)#no shR2(config)#router ospf 1 //配置IPv4网络的动态路由协议OSPFR2(config-router)#network 10.3.3.0 0.0.0.255 area 0R2(config)#int t0 创建隧道，并配置隧道的IPv6地址及隧道模式R2(config-if)#no shR2(config-if)#ipv enR2(config-if)#ipv6 address 2002:A03:303::1/64R2(config-if)# tunnel source f0/1R2(config-if)# tunnel mode ipv6ip 6to4R2(config)#ipv6 route 2002::/16 Tunnel0 //配置IPv6路由R3R3#conf tR3(config)#ipv6 unicast-routing //启用路由器的Ipv6转发功能R3(config)#int loopback 0R3(config-if)#ipv add 2002:0a02:0202:1::1/64R3(config-if)#int f0/1R3(config-if)#no shR3(config-if)#ip add 10.2.2.2 255.255.255.0R3(config)#router ospf 1 //配置IPv4网络的动态路由协议OSPFR3(config-router)#network 10.2.2.0 0.0.0.255 area 0R3(config)#int t0 创建隧道，并配置隧道的IPv6地址及隧道模式R3(config-if)#no shR3(config-if)#ipv6 address 2002:A02:202::1/64R3(config-if)#ipv enR3(config-if)# tunnel source f0/1R3(config-if)# tunnel mode ipv6ip 6to4R3(config)#ipv6 route 2002::/16 Tunnel0 //配置IPv6路由R4R4#conf tR4(config)#ipv un //启用路由器的Ipv6转发功能R4(config)#int f0/0R4(config-if)#no shR4(config-if)#ip add 10.1.1.10 255.255.255.0R4(config-if)#int f0/1R4(config-if)#ip add 10.3.3.10 255.255.255.0R4(config-if)#no shR4(config-if)#int f1/0R4(config-if)#no shR4(config-if)#ip add 10.2.2.10 255.255.255.0R4(config)#router ospf 1 //配置IPv4网络的动态路由协议OSPFR4(config-router)#network 10.1.1.0 0.0.0.255 area 0R4(config-router)#network 10.2.2.0 0.0.0.255 area 0R4(config-router)#network 10.3.3.0 0.0.0.255 area 0 实验十三 ISATAP隧道 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475R1R1#CONF TR1(config)#int loopback 0R1(config-if)#ipv add 2002:303:301::1/64R1(config-if)#int f0/0R1(config-if)#no shR1(config-if)#ip add 3.3.30.1 255.255.255.0R1(config-if)#exitR1(config)#ip route 2.2.20.0 255.255.255.0 3.3.30.2R1(config)#int t0R1(config-if)#no shR1(config-if)#ipv enR1(config-if)#tunnel source f0/0R1(config-if)# tunnel mode ipv6ip isatapR1(config-if)#exiR1(config)#ipv unicast-routingR1(config)#ipv6 router ospf 1R1(config-rtr)#router-id 1.1.1.1R1(config-rtr)#int t0 //创建ISATAP隧道，并配置隧道相关参数R1(config-if)#ipv6 ospf network point-to-multipoint non-broadcastR1(config-if)#ipv6 ospf neighbor FE80::5EFE:202:1401 //手工指定邻居使用本地链路地址R1(config-if)#ipv6 ospf 1 area 0R1(config-if)#exitR1(config)#int lo 0R1(config-if)#ipv6 ospf 1 area 0R2R2#conf tR2(config)#int f0/0R2(config-if)#no shR2(config-if)# ip address 3.3.30.2 255.255.255.0R2(config-if)#int f0/1R2(config-if)#no shR2(config-if)# ip address 2.2.20.2 255.255.255.0R3R3#conf tR3(config)#ipv unicast-routingR3(config)#int f0/0R3(config-if)#no shR3(config-if)#ip add 2.2.20.1 255.255.255.0R3(config-if)#int f0/1R3(config-if)#no shR3(config-if)#ipv6 add 2002:202:201::1/64R3(config-if)#exiR3(config)#ip route 3.3.30.0 255.255.255.0 2.2.20.2R3(config)#int t0R3(config-if)#no shR3(config-if)#ipv enR3(config-if)#tunnel source f0/0R3(config-if)#tunnel mode ipv6ip isatapR3(config-if)#exiR3(config)#ipv6 router ospf 1R3(config-rtr)# router-id 3.3.3.3R3(config-rtr)#int t0 //创建ISATAP隧道，并配置隧道相关参数R3(config-if)#ipv6 ospf network point-to-multipoint non-broadcast //为简化OSPF的运行，//避免DR和BDR的选举，在隧道接口上把网络类型改为点到多点广播R3(config-if)#ipv6 ospf neighbor FE80::5EFE:303:1E01 //手工指定邻居使用本地链路地址R3(config-if)# ipv6 ospf 1 area 0R3(config-if)#int f0/1R3(config-if)#ipv6 ospf 1 area 0R3(config-if)#R4R4#conf tR4(config)#ipv unR4(config)#int f0/0R4(config-if)#no shR4(config-if)#ipv6 address 2002:202:201::2/64R4(config-if)#exitR4(config)#ipv6 router ospf 1R4(config-rtr)#router-id 4.4.4.4R4(config-rtr)#int f0/0R4(config-if)#ipv6 ospf 1 area 0R4(config-if)# 实验十四 ISATAP隧道（二） C1 桥接本机网卡 ，路由器为C7200 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647R1R1#conf tR1(config)#int f0/0R1(config-if)#ip address 192.168.10.10 255.255.255.0R1(config-if)#no shR1(config-if)#exiR1(config)#int s2/0R1(config-if)#clock rate 64000R1(config-if)#ip add 131.107.0.1 255.255.255.0R1(config-if)#no shR2R2#conf tR2(config)#ipv unR2(config)#int s2/0R2(config-if)#ip address 131.107.0.2 255.255.255.0R2(config-if)#no shR2(config-if)#exiR2(config)#int s2/1R2(config-if)#clock rate 64000R2(config-if)#ipv6 address 2001:2::1/64R2(config-if)#no shR2(config-if)#exiR2(config)#ip route 192.168.10.0 255.255.255.0 131.107.0.1R2(config)#ipv6 route 2001:1::/64 2001:2::2R2(config)#int t0R2(config-if)#ipv6 address 2001:3::/64 eui-64R2(config-if)#no ipv6 nd suppress-raR2(config-if)#tunnel source 131.107.0.2R2(config-if)#tunnel mode ipv6ip isatapR2(config-if)#no shR3R3#conf tR3(config)#ipv unR3(config)#int s2/1R3(config-if)#ipv6 address 2001:2::2/64R3(config-if)#no shR3(config-if)#exiR3(config)#int f0/0R3(config-if)#ipv6 address 2001:1::1/64R3(config-if)#no shR3(config-if)#exiR3(config)#ipv6 route 2001:3::/64 2001:2::1 以管理员身份运行cmd。执行以下命令： 1netsh interface ipv6 isatap set route 131.107.0.2 （Win10操作系统要先运行：netsh interface isatap set state enable命令）执行以下命令查看结果： 1234567891011121314151617181920212223242526C:\WINDOWS\system32&gt; ipconfig /all 无线局域网适配器 本地连接* 2: 媒体状态 . . . . . . . . . . . . : 媒体已断开连接 连接特定的 DNS 后缀 . . . . . . . : 描述. . . . . . . . . . . . . . . : Microsoft Wi-Fi Direct Virtual Adapter #2 物理地址. . . . . . . . . . . . . : BC-A8-A6-EB-A1-CD DHCP 已启用 . . . . . . . . . . . : 是 自动配置已启用. . . . . . . . . . : 是 隧道适配器 isatap.&#123;331437F1-5F3E-436E-8E71-36228471287E&#125;: 连接特定的 DNS 后缀 . . . . . . . : 描述. . . . . . . . . . . . . . . : Microsoft ISATAP Adapter 物理地址. . . . . . . . . . . . . : 00-00-00-00-00-00-00-E0 DHCP 已启用 . . . . . . . . . . . : 否 自动配置已启用. . . . . . . . . . : 是 IPv6 地址 . . . . . . . . . . . . : 2001:3::5efe:192.168.10.20(首选) 本地链接 IPv6 地址. . . . . . . . : fe80::5efe:192.168.10.20%22(首选) 默认网关. . . . . . . . . . . . . : fe80::5efe:131.107.0.2%22 DNS 服务器 . . . . . . . . . . . : fec0:0:0:ffff::1%1 fec0:0:0:ffff::2%1 fec0:0:0:ffff::3%1 TCPIP 上的 NetBIOS . . . . . . . : 已禁用 执行ping命令测试是否能够互通。 123456789101112PS C:\WINDOWS\system32&gt; ping 2001:1::1 正在 Ping 2001:1::1 具有 32 字节的数据:来自 2001:1::1 的回复: 时间=74ms来自 2001:1::1 的回复: 时间=81ms来自 2001:1::1 的回复: 时间=99ms来自 2001:1::1 的回复: 时间=61ms 2001:1::1 的 Ping 统计信息: 数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，往返行程的估计时间(以毫秒为单位): 最短 = 61ms，最长 = 99ms，平均 = 78ms 特别说明：1、如果你的操作系统是win10，请下载win10关于IPv6的补丁.2、为了用ping命令测试是否互通，请暂时关闭计算机防火墙或者通过设置防火墙规则允许ping命令数据包通过。]]></content>
      <tags>
        <tag>IPv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-端口映射与容器互联]]></title>
    <url>%2F2018%2F12%2F17%2Fdocker-%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E4%B8%8E%E5%AE%B9%E5%99%A8%E4%BA%92%E8%81%94%2F</url>
    <content type="text"><![CDATA[端口映射 当容器中运行一些应用，可以通过-p ，-P 参数来指定端口映射使用-P时，Docker会随机映射一个49000~49900的端口到内部容器开放的端口如果一个镜像中没有可以对外提供的服务，使用-P参数基于该镜像启动容器后，不会有端口的映射 12例如：docker run -idt -P centos /bin/bash docker run -idt -P httpd /bin/bash 另外几种查看端口映射的方法 12docker port IDdocker inspect -f &#123;&#123;.NetworkSettings.Ports&#125;&#125; ID 使用-p(小写)可以指定要映射的端口使用HostPort : ContainPort将本地的5000映射到容器的5000，会默认绑定本地所有接口上的所有地址 可以多次使用-p参数绑定多个端口 12docker run -d -p 80:80 httpd docker run -d -p 80:80 -p 8080:8080 httpd 使用IP:HostPort:ContainPort格式指定映射使用一个特定地址 1docker run -d -p 127.0.0.1:80:80 httpd 使用IP::ContainerPort 映射到指定地址的任意端口 12345docker run -d -p 127.0.0.1::80 httpd还可以使用udp标记来指定udp端口docker run -d -p 127.0.0.1:80:80/udp httpd 容器互联 创建一个数据库容器 1docker run -idt --name db postgres 1docker run -idt -P --name web --link db:db httpd /bin/bash 使用–link 选项，参数格式为name:alias 即要连接的容器名称 : 这个连接的别名 再建立一个web2容器，同web的配置，查看环境变量，可以看到与db容器的连接，以DB_开头的环境变量都是提供web连接db的 进入到web容器中查看/etc/hosts .可以看到db容器的信息 在web容器中安装ping命令 12apt-get update 更新源apt-get install inetutils-ping]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-数据卷]]></title>
    <url>%2F2018%2F12%2F16%2Fdocker-%E6%95%B0%E6%8D%AE%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[前言 容器中管理数据主要有两种方式： 数据卷：容器内数据直接映射到本地主机环境 数据卷容器：使用特定容器维护数据卷 数据卷可以提供很多有用的特性： 数据卷可以在容器间共享和重用，容器间传递数据变得高效方便 对数据卷内数据的修改即刻生效，无论容器内操作还是本地操作 对数据卷的更新不会影响镜像，解耦了应用和数据 卷会一直存在，知道没有容器使用，可以安全卸载 在容器内创建一个数据卷 1docker run -d -P --name web -v /webapp training/webapp python app.py 使用training/webapp 创建一个名为web的容器，在后台运行，自动映射到主机端口，创建一个数据卷挂载到容器的 /webapp 下，并执行app.py文件 可以看到 /webapp 的时间戳发生了变化 挂载一个主机目录作为数据卷 1docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py 使用training/webapp 创建一个名为web的容器，在后台运行，自动映射到主机端口，加载主机的/src/webapp到容器的/opt/webapp 下，并执行app.py文件 挂载数据卷时，要使用绝对路径，如果目录不存在则会自动创建 可以在容器中看到在宿主机上新建的hello_world文件 挂载一个主机文件作为数据卷 1docker run --rm -it -v ~/.bash_history:/.bash_history centos /bin/bash 使用centos镜像创建一个容器，当容器为退出状态时自动删除，加载本机的.bash_history 到容器的.bash_history 中 如果直接挂载一个文件到容器，使用文件编辑工具（vim ,sed等等）时，可能造成文件inode变化，造成报错 加载到容器中的文件仍能使用，但是和本机的文件不同步了（具体问题我也没有找到） 数据卷容器数据卷容器也是一个容器，专门用来提供数据卷供其他容器挂载，使得多个容器间共享一些持续更新的数据 db1和db2 中都可以看到dbdata 创建的test文件 可以多次使用–volumes-from 参数来从多个容器挂载多个数据卷，还可以从其他已经挂载了容器卷的容器来挂载数据卷 1docker run -d --name db3 --volumes-from db1 training/postgres 使用–volumes-from 参数所挂载数据卷的容器自身并不需要保持在运行状态 删除了挂载的容器，数据卷并不会被自动删除挂载信息,数据卷信息会保存在/var/lib/docker/volumes下 利用数据卷容器迁移数据 可以利用数据卷容器对其中的数据卷备份、恢复，以实现数据的迁移 备份 1docker run --volumes-from dbdata -v $(pwd):/backup --name worker centos tar -cvf /backup/backup.tar /dbdata 使用centos 镜像创建 ，根据数据卷容器dbdata来挂载数据卷，将本地当前目录挂载到容器worker的/backup，并将/dbdata 归档为/backup下的backup.tar 恢复 1docker run --volumes-from dbdata -v $(pwd):/backup --name backup centos tar-xvf /backup/backup.tar 注意事项挂载宿主机已存在目录后，在容器内对其进行操作，报“Permission denied”。 可通过两种方式解决： 关闭selinux。 12临时关闭：setenforce 0永久关闭：修改/etc/sysconfig/selinux文件，将SELINUX的值设置为disabled。 以特权方式启动容器 12指定--privileged参数docker run -it --privileged=true -v /test:/soft centos /usr/bin/init]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 容器]]></title>
    <url>%2F2018%2F12%2F13%2Fdocker-%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;docker容器是docker的运行实例，在镜像文件上带有可写的文件层。docker容器是一个轻量级应用，能够随时创建和部署、启动、停止 1.使用docker creat 创建新的容器 1docker create -it centos 创建以个新的Centos容器 使用docker ps -a 查看容器信息 STATUS 为容器运行状态，UP为正常运行，Exited为停止，Created为尚未启动 &nbsp;&nbsp;&nbsp;&nbsp;creat 命令和后续的run命令支持的选项都十分复杂，主要包括几大类：与容器运行模式相关，与容器和环境配置相关，与容器资源限制和安全保护相关 2.使用docker start 启动容器 1docker start 10f 可以看到容器状态为UP 代表已经启动。 3. 使用 docker run 新建并启动容器 1docker run centos /bin/echo &quot;this is new centos &quot; 当利用docker run 来创建并启动容器时，docker在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从共有仓库下载 利用镜像创建一个容器，并启动该容器 分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器 从网桥的地址池配置一个ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被自动终止 &nbsp;&nbsp;&nbsp;&nbsp;使用ps命令，可以看到只运行了bash应用，并无其他进程,用户可以输入exit 命令来退出容器 &nbsp;&nbsp;&nbsp;&nbsp;对于所创建的bash容器，当使用exit命令退出后，容器就自动处于退出(Exited)状态，对于docker 容器来说， 当运行的应用退出后容器也就没有继续运行的必要了 &nbsp;&nbsp;&nbsp;&nbsp;有时执行docker run会出错，因为命令无法正常执行容器会退出，可以查看默认返回的错误码 常见的有以下几个 125 Docker daemon 执行出错，例如指定不支持的参数 126 指定命令无法执行 例如权限出错 127 容器内命令无法找到 4. 守护状态运行 使docker容器在后台以守护状态运行（Daemonized） 使用-d 参数 1234docker run -d centos /bin/bash -c &quot;while ture ; do echo hello world ; sleep 2;done&quot; docker ps ### 查看容器信息docker logs ### 获取容器输出信息docker stop ### 停止容器 5. 终止容器 &nbsp;&nbsp;&nbsp;&nbsp;docker stop 会终止一个运行中的容器，命令格式为 docker stop [-t | –time=[10]] [container] &nbsp;&nbsp;&nbsp;&nbsp;首先向容器发送SIGTERM 信号，等待一段超时时间后（默认10秒 ） 在发送信号来终止容器&nbsp;&nbsp;&nbsp;&nbsp;docker kill 会 直接发送 SIGKILL 信号来终止容器 &nbsp;当Docker容器中指定的应用终结时，容器也会自动终止 1docker ps -qa 查看所有容器的id &nbsp;&nbsp;&nbsp;&nbsp;处于终止状态的容器可以通过 docker start命令重新启动,docker restart 会将一个运行态容器先终止再重新启动 6.进入容器 &nbsp;&nbsp;&nbsp;&nbsp;在使用-d参数后，容器会进入后台，用户无法操作，如果需要进入可以使用官方的attach、exec，和第三方的nsenter 1234docker attach [--detach-keys[ = [ ] ] ] [--no-stdin] [--sig-proxy[=ture]] container --detach-keys[ = [ ] ] : 指定退出attach模式的快捷键，默认是ctrl+q 和ctrl+p--no-stdin=true|false ： 是否关闭从标准输入，默认是打开--sig-proxy=true|false ： 是否代理收到的系统信给应用进程，默认true 多个窗口同时使用attach模式连接到同一容器时，所有窗口都会同步显示 12345docker exec [-d|--detach] [--detach-keys[=[ ] ] ] [-i|--interactive] [--privileged] [-t|--tty] [-u|--user[=USER] container COMMAND [ARG..]-i ,--interactive=true|false : 打开标准输入接受用户输入命令，默认false --privileged-true|false ： 是否给执行命令以最高权限 ，默认false-t，--tty=true|false ; 分配伪终端，默认false-u ，--user=&quot; &quot; : 执行命令的用户或ID &nbsp;&nbsp;&nbsp;通过指定-it 参数来保持标准输入打开，并且分配一个为终端，推荐使用exec命令对容器进行操作 1docker nsenter 第三方工具 7.删除容器 1docker rm [-f|--force] [-l | --link] [-v|--volumes] container [container……] 使用该命令来删除处于终止或退出状态的容器 -f ，–force=false ：是否强制终止并删除一个运行中的容器 -l，–link=false ：删除容器的连接，但是保留容器 -v，–volumes=false ： 删除容器挂载的数据卷 8. 导入导出容器 用于容器的系统迁移 1docker export [-o|--output[=&quot; &quot; ] ] container 可以通过-o 来指定导出的tar文件名，也可以直接重定向实现 导出的文件可以使用docker import 命令导入变成镜像 1docker import [-c|--change[=[]]] [-m|--message[=MESSAGE]] file|URL|-[REPOSITORY[:TAG]] docker save ：将一个镜像导出为文件，再使用dockerload –input 命令将文件导入为一个镜像，会保存该镜像的的所有历史记录。比dockerexport命令导出的文件大，很好理解，因为会保存镜像的所有历史记录。 docker export ：将一个容器导出为文件，再使用docker import命令将容器导入成为一个新的镜像，但是相比docker save命令，容器文件会丢失所有元数据和历史记录，仅保存容器当时的状态，相当于虚拟机快照。]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-ce安装 与docker镜像（Centos7)]]></title>
    <url>%2F2018%2F12%2F12%2Fdocker-ce%E5%AE%89%E8%A3%85-%E4%B8%8Edocker%E9%95%9C%E5%83%8F%EF%BC%88Centos7%2F</url>
    <content type="text"><![CDATA[安装docker-ce（设置清华大学镜像站为镜像源) 在centos7 yum仓库 的extras仓库中自带了docker源,都是docker 1.13版本，不建议使用老版本docker.清华大学在镜像站中给docker做了镜像在此目录下找到docker的repo文件我们可以自己建一个docker镜像源仓库，首先要把该repo文件下载到/etc/yum.repos.d 中下载后打开docker-ce.repo文件，文件中指向的地址是docker官方站点，这个下载速度是很慢的，因此还要修改下载路径仍然选择清华大学镜像站，来到这个目录下，选择稳定版可以看到这里有最新版本18.06选择复制链接中的linux父目录https://mirrors.tuna.tsinghua.edu.cn/docker-ce/然后全局替换docker-ce.repo中的官方地址的linux的父目录用vim打开，在末行模式下进行替换可以看到替换成功yum repolist 显示所有仓库，可以看到存在docker-ce的程序包yum install docker-ce ，完成 启动docker 1systemctl start docker 设置开机自启动 1systemctl enable docker 很简单镜像是运行docker容器的基础，容器运行前，必须存在对应的镜像，如果本地没有对应的镜像，docker会自动从默认仓库（DockerHub） 下载镜像,如果有本地镜像，也可以从本地仓库下载镜像获取镜像的主要方式是从共有仓库（DockerHub）下载 搜索并下载镜像（例如调用ubuntu镜像） 11.docker search ubuntu 搜索ubuntu镜像 其中列出了查找到的镜像名称、描述、星级、官方 、自动化的 12.docker pull ubuntu 下载镜像 13.docker images 查看已经下载的镜像文件 参数含义：REPOSITORY : 镜像来源于哪个仓库TAG : 镜像标签IMAGE ID : 镜像id(唯一标识镜像)CREATED : 镜像创建时间SIZE : 镜像大小，优秀的镜像往往体积小 如果不指定镜像系统版本，则会下载最新版本镜像，也可以通过指定TAG的方法来下载特定版本的镜像,在生产中不应忽略镜像标签信息或使用默认的latest标签，内容是不稳定的。 docker pull 默认从Docker Hub Registry仓库下载镜像，如果从非官方仓库下载，则需要在仓库名称前指定完整的仓库地址 例如docker pull hub.c.163.com/public/ubuntu14.04 即从网易下载 docker tag 为本地镜像任意添加新的标签14.docker tag ubuntu:latest myubuntu:latest 该命令添加的标签实际起到了类似链接的作用 15.docker inspect 获取镜像详细信息(元数据) 返回的时json格式信息，如果想要其中一项内容时，使用-f参数来指定 1docker inspect -f &#123;&#123;.RepoTag&#125;&#125; ImageID 16.docker history 查看镜像历史 镜像文件由多个层组成，docker history 可以查看镜像的创建过程 启动一个基于该ubuntu镜像的容器，并进入该容器 127.docker run -idt ubuntu /bin/bash8.docker exec -it /bin/bash -i是为了让容器能接受用户的输入，-t是指定docker为容器创建一个tty19.df -TH 查看容器文件系统的磁盘使用 保存和载入镜像 用户可以将镜像保存到本地以载入使用，或者将其复制到另外的文件系统110.docker save -o ubuntu_latest_save.tar ubuntu:latest 保存镜像 可以把保存的镜像文件载入到系统中，并载入标签等镜像文件的元数据 1211.docker load &lt; ubuntu_latest_save.tar 载入镜像12.docker load --input ubuntu_latest_save.tar 删除镜像 查询后可以看到镜像id 113.docker rmi IMAGE ID 报错为该镜像被683容器所使用，需要先删除基于这个镜像所创建的容器 docker ps -a 查询容器可以看到存在基于镜像ubuntu的容器状态为UP ，表示正在运行 114.docker stop CONTAINER ID 停止容器 115.docker rm CONTAINER ID删除该容器 116.docker rmi IMAGE ID 镜像已经删除。其中删除容器为rm 删除镜像为rmi。可以在待删除的镜像名称前面加参数-f ，强制删除。后来在DockerFile中推荐以下的命令写法 12317.docker container stop18.docker container rm19.docker images rm 创建镜像 创建镜像有三种方法，分别是基于本地模板导入镜像、基于已有镜像的容器创建镜像，基于Dockerfile 创建镜像1&gt; 基于本地模板导入镜像如果本地有镜像的模板文件，可以基于该模板创建镜像，镜像模板文件也可以从OpenVZ下载 wget http://download.openvz.org/template/precreated/ubuntu-14.04-x86_64-minimal.tar.gz 下载模板文件 下载完成后，执行以下命令，可以用该模板文件创建文件 120.cat ubuntu-14.04-x86_64-minimal.tar.gz | docker import - ubuntu-14.04_minimal_amd64 其中 docker import：从归档文件中创建镜像用法：docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]-c :应用docker 指令创建镜像；-m :提交时的说明文字； 可以看到刚刚导出的镜像，启动并运行 2&gt;基于已有的镜像容器创建镜像接上图在容器中新建一个for_new_image 目录 与原容器相比此时已经发生变化，，可以提交为新镜像 121.docker commit -m &quot;creatd new dir&quot; -a &quot;root&quot; 87acd63067e1 new_ubuntu 其中 docker commit ：从容器创建一个新的镜像。语法： docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]-a :提交的镜像作者；-c :使用Dockerfile指令来创建镜像；-m :提交时的说明文字；-p :在commit时，将容器暂停。 提交成功后会返回镜像ID，可以看到新镜像已经存在 3&gt; 基于Dockerfile 创建镜像&nbsp;&nbsp;&nbsp;&nbsp;Dockerfile 是一种被Docker程序解释的脚本，每条指令对应linux下的一条命令， Docker程序可以读取Dockerfile脚本，根据指令生成定制的镜像。Dockerfile指令分为构建指令和设置指令。构建指令用于构建镜像，不会在容器的镜像上运行；设置指令用于设置镜像属性，其操作可以在容器的镜像上执行 （1）FROM&nbsp;&nbsp;&nbsp;&nbsp;构建指令，用于指定基础镜像，必须指定，且必须在Dockerfile所有指令之前指定，因为后续指令都依赖该指令指定的镜像，，可以指定DockerHub中的镜像，也可以指定本地仓库中的 （2）MAINTAINER &nbsp;&nbsp;&nbsp;&nbsp;构建指令，用于将镜像制作者相关信息写入镜像中，当我们对该镜像执行docker inspect 命令时，会显示该字段 （3）RUN &nbsp;&nbsp;&nbsp;&nbsp;构建指令，用于执行任何被基础镜像所支持的命令，例如ubuntu基础镜像只能使用ubuntu命令，centos基础镜像只能使用centos命令 （4）CMD &nbsp;&nbsp;&nbsp;&nbsp;设置指令，用于指定容器启动时执行的操作，可以执行自定义脚本，亦可以执行系统命令，，此命令只能在Dockerfile脚本中设置一次，设置多个只会执行最后一个 （5）ENTRYPOINT （entrypoint） &nbsp;&nbsp;&nbsp;&nbsp;设置指令，用于指定容器启动时执行的命令，可以在Dockerfile脚本中设置多次，只有最后一个有效 ENTRYPOINT 使用分两种情况 ： &nbsp;&nbsp;&nbsp;&nbsp;独自使用时，如果同时使用了CMD命令，且CMD指定的是一个完整可执行命令，那么二者会互相覆盖，只有写在最后的那条指令有效；与CMD指令配合使用，CMD指令可以指定ENTRYPOINT的默认参数，此时CMD指令指定的仅仅是参数部分，而ENTRYPOINT需要使用JSON方式指定需要执行的命令但不能使用参数 （6）USER 设置指令，用于设置启动容器的用户，默认为root （7）EXPOSE &nbsp;&nbsp;&nbsp;&nbsp;设置指令，用于将容器中的端口映射称为宿主机中的摸个端口。极大方便了访问容器 。 宿主机IP：PORT &nbsp;&nbsp;&nbsp;&nbsp;需要两步操作，首先在Docerfile中使用 EXPOSE设置需要映射的容器端口号，然后在 docker run 中使用参数 -p 指定前面的端口号，该端口号就会被随机映射称为宿主机中的一个端口号，也可以指定需要映射到宿主机的哪个端口，但要注意指定的端口没有被占用。 &nbsp;&nbsp;&nbsp;&nbsp;端口映射是Docker比较重要的一个功能，因为每次运行容器时，容器IP不能被指定，而是桥接模式网卡随机生成的，但是宿主机IP地址是固定的，将容器端口映射称为宿主机上的一个端口，可以免去每次访问容器时都要查看容器IP的麻烦 &nbsp;&nbsp;&nbsp;&nbsp;一个运行中的容器，使用 ==docker port CONTAINER ID== 查看该端口号在宿主机上的映射端口 （8） ENV （environment） &nbsp;&nbsp;&nbsp;&nbsp;构建指令，用于在镜像中设置一个环境变量，设置成功后，后续的RUN 指令都可以使用该指令设置的环境 （9）ADD &nbsp;&nbsp;&nbsp;&nbsp;构建指令，用于把本地文件添加到容器，默认所有拷贝到容器中文件和文件夹权限为755（-rwxr-xr-x），UID和GID为0，如果是一个目录，那么会将该目录下的所有文件添加到容器，但不包括目录；如果文件是可识别的压缩格式，则docker会进行解压缩 （10）VOLUME&nbsp;&nbsp;&nbsp;&nbsp;设置指令， 指定挂载点，用于使容器中某个目录具有持久化存储数据的功能，该目录可以被容器本身使用，也可以共享给其他容器使用由于容器使用AUFS文件系统，不能持久化数据，容器关闭后，所有更改也会消失，因此容器有应用持久化数据存储的需求时，可以使用该指令 （11）WORKDIR&nbsp;&nbsp;&nbsp;&nbsp;设置指令，可以多次切换目录（cd），可以在RUN, CMD, ENTRYPOINT 命令前使用 (12) COPY (src)…(dest)&nbsp;&nbsp;&nbsp;&nbsp;复制本地主机 src (为Dockerfile所在目录的相对路径、文件或目标）下的内容到镜像中的 dest 下。路径不存在时会自动创建。支持正则。 下面展示一则使用Dockerfile创建Tomcat镜像的实例1234567891011121314151617181920212223242526272829303132333435363738394041#Pull base image // 获取基础镜像FROM ubuntu:latestMAINTAINER XXX# LABEL maintainer=&quot;XXX&quot;#update source //更新镜像源RUN echo &quot;deb http://cn.archive.ubuntu.com/ubuntu xenial main universe&quot;&gt;/etc/apt/sources.listRUN apt-get update#Install curl // 安装curlRUN apt-get -y install curl#Install JDK 8 //安装JDK,其中的cookie使用burpsuit获取RUN cd /tmp &amp;&amp; curl -L &apos;http://download.oracle.com/otn-pub/java/jdk/8u191-b12/2787e4a523244c269598db4e85c51e0c/jdk-8u191-linux-i586.tar.gz&apos; -H &apos;Cookie:s_fid=1CC16A1445A28C96-0DF2FFDC49166DB3; ELOQUA=GUID=25787B725D6B4A1E98D0D92A1C00A0F7; s_nr=1540978397285-Repeat; RT=&quot;sl=23&amp;ss=1540977568733&amp;tt=40261&amp;obo=21&amp;sh=1540977921638%3D23%3A2 1%3A40261%2C1540977919016%3D22%3A21%3A37654%2C1540977918989%3D21%3A20%3A3 7654%2C1540977913741%3D20%3A19%3A37654%2C1540977913712%3D19%3A18%3A37654&amp;dm=oracle.com&amp;si=6be7a975-8d66-41f3-92c8-a5748709fec8&amp;bcn=%2F%2F1288af 19.akstat.io%2F&amp;nu=http%3A%2F%2Fdownload.oracle.com%2Fotn-pub%2Fjava%2Fjdk%2F8u191-b12%2F2787e4a523244c269598db4e85c51e0c%2Fjdk-8u191-linux-i586 .tar.gz&amp;cl=1540978405737&quot;;atgRecVisitorId=127AFu33Mp_NNJQHlgn2ZpQPg5vZT6c4TietQ0-KTTWmfuc8127; gpw_e24=https%3A%2F%2Fwww.oracle.com%2Ftechnetwork %2Fjava%2Fjavase%2Fdownloads%2Fjdk8-downloads-2133151.html; s_cc=true; s_sq=%5B%5BB%5D%5D; oraclelicense=accept-securebackup-cookie&apos;|tar -zxRUN mkdir -p /usr/lib/jvmRUN mv /tmp/jdk1.8.0_191 /usr/lib/jvm/java-8-oracle/#Set Oracle JDK 8 as default Java //配置Java环境RUN update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-8-oracle/bin/java 300RUN update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java-8-oracle/bin/javac 300ENV JAVA_HOME /usr/lib/jvm/java-8-oracle/#Install Tomcat8 //安装TomcatRUN cd /tmp &amp;&amp; curl -L &apos;https://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.34/bin/apache-tomcat-8.5.34.tar.gz&apos;| tar -xzRUN mv /tmp/apache-tomcat-8.5.34/ /opt/tomcat8/ENV CATALINA_HOME /opt/tomcat8ENV PATH $PATH:$CATALINA_HOME/bin#Expose ports EXPOSE 8090:8080 //设置映射端口，tomcat的8080端口映射为宿主机的8090端口#Define default command //运行tomcat，查看日志ENTRYPOINT /opt/tomcat8/bin/startup.sh &amp;&amp; tail -f /opt/tomcat8/logs/catalina.out 或 运行Dockerfile要在Dockerfile所在的目录，”./“应为Dockerfile脚本所在目录，否则就会报上下文环境的错误,MV、COPY、ADD的文件位置都是相对于/root 来说的第一遍执行(使用的第一条命令)时出现很多错误，最后修改成功了，以下截图是第二遍执行(第二条命令) 因此会报使用缓存 在下载jdk的时候，需要加上cookie，没加时出现以下报错 Java和Tomcat程序的安装包下载地址可能会发生变化，因此使用该脚本时先根据实际下载地址对其进行修改，包括解压后的生成路径也会有改变 运行镜像，启动一个基于镜像tomcat的容器，宿主机输入http://localhost:8090 即可访问tomcat]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[亲测Hexo+Github个人博客搭建]]></title>
    <url>%2F2018%2F11%2F15%2F%E4%BA%B2%E6%B5%8BHexo-Github%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[什么是 Hexo？Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 安装 Hexo 相当简单然而在安装前，您必须检查电脑中是否已安装下列应用程序： Node.jshttps://nodejs.org/dist/v10.13.0/node-v10.13.0-x64.msi(Winx64) Githttps://github.com/git-for-windows/git/releases/download/v2.19.1.windows.1/Git-2.19.1-64-bit.exe（Win x64） 输入 ： 123node -vnpm -vgit --version 检查Node.js 和 Git 是否 安装成功 在此处，如果Node.js 版本低，在后面的搭建过程中无法顺利执行，建议各位在官网下载最新版本；Git如果没有加入环境变量需要将Git添加到环境变量 在自己认为合适的位置创建一个个文件夹，我的是E:\Personal-blog\hexo ，在命令行界面进入该文件夹，然后使用 npm 即可完成 Hexo 的安装 1npm install -g hexo-cli 安装完成，可能会有WARN，但不会影响正常使用然后输入： 1npm install hexo --save 在这一步时，我遇到如下报错12345npm WARN deprecated titlecase@1.1.2: no longer maintainednpm ERR! Unexpected end of JSON input while parsing near &apos;...&quot;:&quot;^0.3.1&quot;,&quot;benchmark&apos;npm ERR! A complete log of this run can be found in:npm ERR! C:\Users\dell\AppData\Roaming\npm-cache\_logs\2018-11-12T15_46_56_713Z-debug.log 解决办法：更新npm源即可 1npm config set registry https://registry.npm.taobao.org Hexo安装完成，检测是否正确安装 1hexo -v Hexo的配置在当前目录下新建一个名为blog的文件夹，用于存放博客网站的信息在命令行进入blog，初始化该文件夹，并安装所需组件 12hexo init npm install 安装完成后，检测是否安装成功 1hexo g 1hexo s 根据提示访问https://localhost:4000/ 出现该界面说明Hexo在本地的配置完成了。（因为我改了配置文件，所以显示出我的名字，原位置应为Hexo） 注册GitHub账号与配置https://github.com/ 进入网站后，点击Sign up 进行注册， 填写自己的用户名，邮箱，密码（邮箱后面会用到验证账户） 注册完成后，新建代码仓库点击网页右上角”+” 中的New repo ，新建仓库 在该界面输入仓库名，描述信息，选择共有或私有仓库注意仓库名要和你的用户名一致(yourname.github.io)，否则后面会访问错误 创建完成后会自动显示你的仓库界面 点击选项栏 Setting ，向下拖至此处，将none 选项选为第一个选项，开启GitHub Pages功能 并Save，可以暂时Change theme，以供暂时访问，但是后面我们使用的是Hexo主题，两者并不冲突 一段时间后即可看到提示创建成功 那么Github一侧的配置已经全部结束了。 将GitHub Page与Hexo关联配置Git个人信息123git config --golbal user.name &quot;username&quot;git config --global user.email &quot;xxx@example.com&quot;git config --list //查看用户信息 可以看到如下信息 在合适的位置新建文件夹daemon ，进入到该文件夹中右击进入 Git Bash 1$ git init 该命令将创建一个名为 .git 的子目录，这个子目录含有你初始化的 Git 仓库中所有的必须文件，这些文件是 Git 仓库的骨干 在Git bash中 123cd ~/.ssh lscat id_rsa.pub 就可以看到你自己的公钥，复制下来，进入Github的个人设置界面 点击New Ssh Key 将密钥粘贴上，添加就可以了 1ssh -T git@github.com 成功。编辑 hexo下的blog下的_config.yml123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/CrimsonRomance/CrimsonRomance.github.io branch: master 编辑daemon.git 下的config12345678910[core] repositoryformatversion = 0 filemode = false bare = false logallrefupdates = true symlinks = false ignorecase = true[branch &quot;master&quot;] remote = https://github.com/CrimsonRomance/CrimsonRomance.github.io merge = refs/heads/master 然后进入 hexo\blog ，右击进入 git bash 12hexo g // 生成hexo d // 部署 如果在 hexo d 出现下面的 错误， 1npm install --save hexo-deployer-git 安装此扩展即可 ，然后重新 hexo g ， hexo d 然后访问网站（https://youname.github.io/）即可]]></content>
      <tags>
        <tag>Hexo+GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F11%2F12%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
