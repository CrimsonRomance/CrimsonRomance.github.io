<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[省科协高可用负载均衡集群]]></title>
    <url>%2F2019%2F03%2F20%2F%E7%9C%81%E7%A7%91%E5%8D%8F%E9%AB%98%E5%8F%AF%E7%94%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[整个集群的架构如下图，服务器是exsi虚拟化。 一、Firewall&nbsp;&nbsp;&nbsp;&nbsp;在集群的配置过程中，我们的Firewall和SElinux是一直处于关闭的，感觉还是先配置上比较方便，说来惭愧 SElinux我不会（setenforce 0），在这里我就只打开Firewall了。 第一层Nginx监听的是80端口（也可以自定义），再将请求反向代理到web服务器的80端口（也可以自定义） ，所以他们都需要在Firewall上允许80端口的流量通过，即： 123firewall-cmd --zone=public --add-port=80/tcpfirewall-cmd --zone=public --add-interface=ens160firewall-cmd --reload nginx高可用实现依靠的keepalived是以VRRP为基础，keepalived官方文档给出的组播地址是224.0.0.18，所以第一层和第三层的nginx的服务器上都需要在防火墙上允许vrrp组播的通过，即： 12firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 \ --in-interface ens160 --destination 224.0.0.18 --protocol vrrp -j ACCEPT MySQL集群必然要开启3306端口，第三层的Nginx也是在监听3306端口，即： 12firewall-cmd --zone=public --add-port=3306/tcpfirewall-cmd --zone=public --add-interface=ens160 建议先看第五步网络存储挂载。 二、nginx高可用集群nginx version: nginx/1.14.0，keepalived-2.0.7 编译安装nginxwget http://www.zlib.net/zlib-1.2.11.tar.gzwget https://jaist.dl.sourceforge.net/project/pcre/pcre/8.41/pcre-8.41.tar.gzwget https://www.openssl.org/source/openssl-1.0.2o.tar.gzwget http://labs.frickle.com/files/ngx_cache_purge-2.3.tar.gzwget http://nginx.org/download/nginx-1.14.0.tar.gz tar xvf …… 解压缩 1234567891011cd nginx-1.14.0.tar.gz./configure --add-module=../ngx_cache_purge-2.3--prefix=/usr/local/nginx --with-http_ssl_module--with-stream --with-pcre=../pcre-8.41--with-zlib=../zlib-1.2.11--with-openssl=../openssl-1.0.2o make&amp;&amp;make install ln -s /usr/local/nginx/sbin/nginx /usr/local/bin/ systemctl enable nginx 配置nginx.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream backend &#123; server 192.168.255.50 weight=100; server 192.168.255.53 weight=80; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; proxy_pass http://backend; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;nginx负载均衡功能实现依靠upstream模块，upstream模块应放于nginx.conf配置的http{}标签内，支持五种分配方式，轮询（默认）、weight、ip_hash三种原生方式，以及fair、url_hash两种第三方支持的方式。我用的是weight方式。 123456proxy_pass http://backend；指向upstream backend &#123; server 192.168.255.50 weight=100; server 192.168.255.53 weight=80; &#125; &nbsp;&nbsp;&nbsp;&nbsp;访问的是nginx服务器的地址即起到了反向代理的作用，代理web&nbsp;&nbsp;&nbsp;&nbsp;接下来安装keepalive实现nginx集群的高可用。 编译安装keepalived1234cd keepalived-2.0.7./configure --prefix=/data/keepalived make make install &nbsp;&nbsp;&nbsp;&nbsp;生成Makefile时有如下报错，需要另外安装libnl/libnl-3以支持IPv6，此处确实用不到，VRRP功能开启即可 配置keepalived123456789101112131415161718192021222324252627282930313233343536373839! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id keepalived01 vrrp_skip_check_adv_addr #vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 vrrp_mcast_group4 224.0.0.18 #vrrp组播，默认为224.0.0.18&#125;vrrp_script chk_nginx &#123; script &quot;/etc/keepalived/nginx_check.sh&quot; # 检查nginx状态的脚本 interval 2 weight 3 &#125; vrrp_instance VI_1 &#123; state MASTER #MASTER为主，BACKUP为从 interface ens160 #网卡，根据自己实际 virtual_router_id 51 #主从一致，用来区分多个instance的VRRP组播 priority 100 #优先级，BACKUP上为99 advert_int 1 #健康查检时间间隔 authentication &#123; #authentication 认证区域 auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 172.18.74.100 #设置vip &#125; track_script &#123; chk_nginx &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;keepalived是集群管理中保证集群高可用的一个服务软件，其功能类似于heartbeat，用来防止单点故障。以VRRP协议为实现基础，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip（该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。 1234567891011nginx_check.sh如下：#!/bin/bashA=ps -C nginx --no-header |wc -lif [ $A -eq 0 ];then /usr/local/nginx/sbin sleep 3 if [ ps -C nginx --no-header |wc -l -eq 0 ];then systemctl stop keepalived fifi 配置完成后Ngx-Master： Ngx-Backup： 宕掉Master的网卡，vip直接转移到了Backup上 重启网卡后，vip回归到Master 三、web 集群&nbsp;&nbsp;&nbsp;&nbsp;这一部分其实很简单，在安装操作系统的时候我选的”Basic web server”,为了能验证web能提交数据到MySQL，写了一个PHP页面。在连接数据库的时候，数据库地址是vip：192.168.255.200 123456789101112131415161718192021index.php&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;charset=UTF-8&quot; /&gt; &lt;title&gt;产品添加-JD产品管理系统&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;JD产品管理&lt;/h3&gt; &lt;form action=&quot;deal.php&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; 图书名称：&lt;input type=&apos;text&apos; name=&apos;title&apos; /&gt; &lt;hr /&gt; 销售价格：&lt;input type=&quot;text&quot; name=&apos;price&apos; /&gt; &lt;hr /&gt; 市场价格：&lt;input type=&quot;text&quot; name=&apos;market_price&apos; /&gt; &lt;hr /&gt; &lt;input type=&quot;submit&quot; name=&quot;submit&quot; value=&quot;添加&quot; /&gt; &lt;input type=&quot;reset&quot; name=&quot;reset&quot; value=&quot;重置&quot; /&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 12345678910111213141516171819202122deal.php&lt;?php //1、设置响应头信息 header(&apos;Content-type:text/html; charset=utf-8&apos;); //2、submit安全判断 if(isset($_POST[&apos;submit&apos;])) &#123; //3、接收数据 $title = $_POST[&apos;title&apos;]; $price = $_POST[&apos;price&apos;]; $market_price = $_POST[&apos;market_price&apos;]; include &apos;coon.php&apos;; //9、定义SQL语句 $sql = &quot;insert into tb_goods values (null,&apos;$title&apos;,&apos;$price&apos;,&apos;$market_price&apos;,&apos;$thumb&apos;)&quot;; //10、执行SQL语句 $result = mysql_query($sql); if($result) &#123; echo &apos;添加成功&apos;; &#125; else &#123; echo &apos;添加失败&apos;; &#125; &#125;?&gt; 123456789coon.php&lt;?php //1、连接数据库,内容根据实际 mysql_connect(&apos;192.168.255.200&apos;,&apos;web&apos;,&apos;123456&apos;); //2、选择数据库 mysql_select_db(&apos;db_jd&apos;); //3、指定数据库的编码格式 mysql_query(&apos;set names utf8&apos;);?&gt; 下面的代码用来测试从数据库读取内容 1234567891011121314151617181920212223&lt;?php// mysql_connect(&quot;数据库地址&quot;,&quot;数据库账号&quot;,&quot;数据库密码&quot;,&quot;连接数据库&quot;);$con = mysql_connect(&quot;192.168.255.200&quot;,&quot;web&quot;,&quot;123456&quot;,&quot;db_jd&quot;);//测试是否连接数据库if($con)&#123; echo &quot;连接成功&quot;;&#125;else&#123; echo &quot;连接失败 &quot;;&#125;mysql_select_db(&quot;db_jd&quot;,$con);$result1=mysql_query(&quot;SELECT * from tb_goods&quot;);echo &quot;&lt;table&gt;&lt;tr&gt;&lt;td&gt;id&lt;/td&gt;&lt;td&gt;title&lt;/td&gt;&lt;td&gt;price&lt;/td&gt;&lt;td&gt;market_price&lt;/td&gt;&lt;td&gt;thumb&lt;/td&gt;&lt;/tr&gt;&quot;;while($row=mysql_fetch_array($result1))&#123;echo &quot;&lt;tr&gt;&quot;;echo &quot;&lt;td&gt;&quot;.$row[&apos;id&apos;].&quot;&lt;/td&gt;&quot;;echo &quot;&lt;td&gt;&quot;.$row[&apos;title&apos;].&quot;&lt;/td&gt;&quot;;echo &quot;&lt;td&gt;&quot;.$row[&apos;price&apos;].&quot;&lt;/td&gt;&quot;;echo &quot;&lt;td&gt;&quot;.$row[&apos;market_price&apos;].&quot;&lt;/td&gt;&quot;;echo &quot;&lt;td&gt;&quot;.$row[&apos;thumb&apos;].&quot;&lt;/td&gt;&quot;;echo &quot;&lt;/tr&gt;&quot;;&#125;mysql_close($con);?&gt; 如果两个web服务器中的页面不同，在提交表单的时候回显示无法找到。 最终效果为： 四、nginx高可用集群nginx version: nginx/1.14.0，keepalived-2.0.7 &nbsp;&nbsp;&nbsp;&nbsp;与第一层原理相同，只不过反向代理的数据库，监听端口是3306&nbsp;&nbsp;&nbsp;&nbsp;这里也会有一个Vip：192.168.255.200 配置Nginx12345678910111213141516171819202122232425262728293031nginx.conf#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;stream &#123; upstream mysql &#123; server 192.168.255.52:3306 weight=5 max_fails=3 fail_timeout=30s; server 192.168.255.57:3306 weight=5 max_fails=3 fail_timeout=30s; &#125; server &#123; listen 3306; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass mysql; &#125; &#125; 配置keepalived1234567891011121314151617181920212223242526272829303132333435363738394041keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id nginx_mysql_s vrrp_skip_check_adv_addr #vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 vrrp_mcast_group4 224.0.0.18&#125;vrrp_script chk_nginx &#123; script &quot;/etc/keepalived/nginx_check.sh&quot; # 检查nginx状态的脚本 interval 2 weight 3 &#125; vrrp_instance VI_1 &#123; state BACKUP interface ens160 virtual_router_id 66 priority 100 # Backup是90 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.255.200 &#125; track_script &#123; chk_nginx.sh &#125;&#125; vip转移不再演示。 五、mysql双机热备集群Server version: 5.6.43-log MySQL Community Server 源码安装mysql，不再展开。 mysql1：my.cnf1234567891011121314151617181920212223242526272829303132333435363738# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.6/en/server-configuration-defaults.html[mysqld]## Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M## Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin## Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2Mdatadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockserver-id=1log-bin=mysql-binbinlog_format=mixedrelay-log=relay-binrelay-log-index=slave-relay-bin.index auto-increment-increment=2auto-increment-offset=1log-slave-updates# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Recommended in standard MySQL setupsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES [mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid mysql2:my.cnf1234567891011121314151617181920212223242526272829303132333435363738# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.6/en/server-configuration-defaults.html[mysqld]## Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M## Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin## Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2Mdatadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockserver-id=2log-bin=mysql-binbinlog_format=mixedrelay-log=relay-binrelay-log-index=slave-relay-bin.indexauto-increment-increment=2auto-increment-offset=2log-slave-updates# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Recommended in standard MySQL setupsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES [mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid &nbsp;&nbsp;&nbsp;&nbsp;web想要上传数据到数据库，首先需要使用web登录至数据库，然后MySQL中应当有已经创建好的数据库，库中要有表，用户权限等等。MySQL集群我们做的是双主，数据是同步的。 &nbsp;&nbsp;&nbsp;&nbsp;先配置双主吧，然后只用建一遍库就可以了。双主模型其实就是互为主从，主从同步复制原理分成三步：master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events ），slave将master的binary log events拷贝到它的中继日志(relay log)，slave重做中继日志中的事件，将改变反映它自己的数据。 首先在两台mysql上创建用户张三 ，允许对方远程连接 12grant all privileges on *.* to zhangsan@192.168.255.52(192.168.255.57) identified by &apos;123456&apos;;Query OK, 0 rows affected (0.12 sec) 先以MySQL1为主MySQL1上（192.168.255.52 主）： 1234567mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000008 | 1480 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.03 sec) MySQL2上（192.168.255.57 从）： 1234mysql&gt; change master to master_host=&apos;192.168.255.52&apos;,master_port=3306,master_user=&apos;zhangsan&apos;,master_password=&apos;123456&apos;,m aster_log_file=&apos;mysql-bin.000008&apos;,master_log_pos=120;Query OK, 0 rows affected, 2 warnings (0.30 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.03 sec) 再以MySQL2为主MySQL2上（192.168.255.57 主）: 1234567mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000006 | 1480 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.04 sec) MySQL1上（192.168.255.52从）; 1234mysql&gt; change master to master_host=&apos;192.168.255.57&apos;,master_port=3306,master_user=&apos;zhangsan&apos;,master_password=&apos;123456&apos;,m aster_log_file=&apos;mysql-bin.000006&apos;,master_log_pos=120;Query OK, 0 rows affected, 2 warnings (0.41 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.05 sec) &nbsp;&nbsp;&nbsp;&nbsp;查看状态， Slave_IO_State 为等待主机事件；MySQL1主机显示192.168.255.57(即MySQL2)为主，在MySQL2上查看则相反；Slave_IO_Running: Yes；Slave_SQL_Running: Yes 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061Mysql 1 ：mysql&gt; show slave status\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.255.57 Master_User: zhangsan Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000006 Read_Master_Log_Pos: 1480 Relay_Log_File: relay-bin.000003 Relay_Log_Pos: 856 Relay_Master_Log_File: mysql-bin.000006 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 1480 Relay_Log_Space: 1023 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 2 Master_UUID: fb80dcb2-409a-11e9-8823-000c29a992e7 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 01 row in set (0.00 sec)ERROR: No query specified 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061MySQL 2：mysql&gt; show slave status\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.255.52 Master_User: zhangsan Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000008 Read_Master_Log_Pos: 1480 Relay_Log_File: relay-bin.000003 Relay_Log_Pos: 1070 Relay_Master_Log_File: mysql-bin.000008 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 1480 Relay_Log_Space: 1237 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: e6c1eb80-40db-11e9-89cb-00505687a987 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 01 row in set (0.03 sec)ERROR: No query specified 创建数据库&nbsp;&nbsp;&nbsp;&nbsp;创建db-jd数据库，在库中创建tb_goods表，表中字段与PHP网页相对应，在mysql1中创建，mysql2中同步 1234567891011121314mysql&gt; create database db_jd;Query OK, 1 row affected (0.00 sec)mysql&gt; use db_jd;Database changedmysql&gt; create table tb_goods (id int(11) null, tltle VarChar(40), price Decimal(10), market_price Decimal(10));Query OK, 0 rows affected (0.13 sec)mysql&gt; show tables;+-----------------+| Tables_in_db_jd |+-----------------+| tb_goods |+-----------------+1 row in set (0.00 sec) 授权允许web登陆在两台MySQL服务器上创建web用户，允许远程登陆，并赋予db_jd数据库的权限12345678mysql&gt; create user web@192.168.255.50 identified by &apos;123456&apos;;Query OK, 0 rows affected (0.37 sec)mysql&gt; grant all privileges on db_jd.* to web@192.168.255.50;Query OK, 0 rows affected (0.12 sec)mysql&gt; create user web@192.168.255.53 identified by &apos;123456&apos;;Query OK, 0 rows affected (0.37 sec)mysql&gt; grant all privileges on db_jd.* to web@192.168.255.53;Query OK, 0 rows affected (0.12 sec) 关于为什么不直接将权限赋给VIP，以及给Nginx服务器赋权，我认为归根到底还是web服务器的Apache与MySQL服务器MySQL -server之间通过套接字进行进程间通信，无论是vip还是Nginx只不过是中间的一座连接桥而已，实质上还是Apache与MySQL-Server通信。 在web插入数据进行测试，如下是在web1界面添加数据 mysql1中可以看到插入的数据test mysql2中同样有 六、网络链接NAS存储&nbsp;&nbsp;&nbsp;&nbsp;输入ip访问NAS服务器的web页面，然后将nas中已经存在的文件夹挂载到mysql服务器的数据目录下即可。&nbsp;&nbsp;&nbsp;&nbsp;使用mount挂载后，格式化了mysql数据目录下的文件，很郁闷，建议先挂载后再去安装mysql。 &nbsp;&nbsp;&nbsp;&nbsp;在NAS上开启NFS协议（NetworkFileSystem）。自带数据备份操作很简单。 12mount -t nfs -o nolock 172.18.74.39:/home/admin /var/lib/mysql #nolock -- 禁用文件锁 -t 指定文件系统类型]]></content>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Docker在linux上部署MySQL]]></title>
    <url>%2F2019%2F01%2F25%2F%E4%BD%BF%E7%94%A8Docker%E5%9C%A8linux%E4%B8%8A%E9%83%A8%E7%BD%B2MySQL%2F</url>
    <content type="text"><![CDATA[下载MySQL服务器Docker镜像使用命令下载MYSQL-Community： 1docker pull mysql/mysql-server:tag &nbsp;&nbsp;&nbsp;tag是你想拉的镜像版本的标签（例如5.5， 5.6，5.7， 8.0，或latest）。如果省略则会下载最新GA版本的MySQL-community-server的镜像。 12345678[root@docker-study ~]# docker pull mysql/mysql-server:5.65.6: Pulling from mysql/mysql-servera8d84c1f755a: Pull complete 36934cee5f0d: Pull complete 5a6871e55c04: Pull complete 7c67030deb6e: Pull complete Digest: sha256:5a1cfc50ab8d147cb163c32558c7334519f5bb69ea82587d480f9f7050b77047Status: Downloaded newer image for mysql/mysql-server:5.6 &nbsp;&nbsp;使用以下命令列出下载的Docker镜像： 1234[root@docker-study ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEmysql/mysql-server 5.6 ad62049ce4ab 6 weeks ago 217MB[root@docker-study ~]# 启动MySQL服务器实例&nbsp;&nbsp;&nbsp;将MySQL镜像启动为容器： 123[root@docker-study ~]# docker run --name=mysql1 -d mysql/mysql-server:5.6321d33b946e7eb8ebea4fe829d1cfb953c6dd5663021088fb9cff21bcea2a112[root@docker-study ~]# &nbsp;&nbsp;&nbsp;&nbsp;–name用于为容器提供自定义名称，该选项是可选的;，如果没有提供容器名称，则生成随机的名称。如果先前的docker pull或docker run 命令未下载指定名称和标记的镜像， 则现在下载该图像。下载完成后，开始初始化容器，并在运行docker ps命令时容器显示在正在运行的容器列表中 ; 例如： 1234[root@docker-study ~]# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES321d33b946e7 mysql/mysql-server:5.6 &quot;/entrypoint.sh mysq…&quot; 3 minutes ago Up 3 minutes (healthy) 3306/tcp mysql1[root@docker-study ~]# &nbsp;&nbsp;&nbsp;初始化完成后，命令的输出将包含为root用户生成的随机密码; 例如，使用以下命令检查密码： 123[root@docker-study ~]# docker logs mysql1 2&gt;&amp;1 | grep GENERATED[Entrypoint] GENERATED ROOT PASSWORD: mOkuHorEKBEh4plym@KYsXYk%Ih[root@docker-study ~]# 连接到Container内的MySQL服务器&nbsp;&nbsp;&nbsp;&nbsp;服务器准备就绪后，可以在刚刚启动的MySQL Server容器中运行 mysql客户端，并将其连接到MySQL服务器。使用docker exec -it命令在已启动的Docker容器中进入 mysql客户端，输入生成的root密码。因为MYSQL_ONETIME_PASSWORD 默认情况下该选项为true，所以在将mysql客户端连接 到服务器之后，重置服务器root密码，如下所示。 12345678910111213141516[root@docker-study ~]# docker exec -it mysql1 mysql -uroot -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 50Server version: 5.6.43Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; SET PASSWORD FOR &apos;root&apos;@&apos;localhost&apos; = PASSWORD(&apos;123456&apos;);Query OK, 0 rows affected (0.00 sec) 容器shell访问&nbsp;&nbsp;&nbsp;要使用shell访问MySQL Server容器，请使用 docker exec -it命令在容器内启动bash shell： 12[root@docker-study ~]# docker exec -it mysql1 bashbash-4.2# &nbsp;&nbsp;&nbsp;然后可以在容器内运行Linux命令。例如，要查看容器内server数据目录中的内容 123bash-4.2# ls /var/lib/mysqlauto.cnf ib_logfile0 ib_logfile1 ibdata1 mysql mysql.sock performance_schema testbash-4.2# 停止和删除MySQL容器&nbsp;&nbsp;&nbsp;使用以下命令停止创建的MySQL Server容器： 123[root@docker-study ~]# docker stop mysql1mysql1[root@docker-study ~]# &nbsp;&nbsp;&nbsp;docker stop向 mysqld进程发送SIGTERM信号 ，以便正常关闭服务器。 &nbsp;&nbsp;&nbsp;另请注意，当容器的主进程（MySQL服务器容器中的mysqld）停止时，Docker容器会自动停止。 123456789101112要再次启动MySQL Server容器：docker start mysql1使用单个命令停止并重新启动MySQL Server容器：docker restart mysql1要删除MySQL容器，请先将其停止，然后使用 docker rm命令：docker stop mysql1docker rm mysql1如果希望同时删除服务器数据目录的 Docker卷，请将该-v选项添加到 docker rm命令。docker rm -v mysql1 配置MySQL服务器&nbsp;&nbsp;&nbsp;启动MySQL Docker容器时，可以通过docker run命令将配置选项传递给服务器; 例如，对于MySQL服务器： 123[root@docker-study ~]# docker run --name mysql1 -d mysql/mysql-server:5.6 --character-set-server=utf8mb4 --collation-server=utf8mb4_colae491dde8ad07c8db420facc6a7b6546b3ae375d7e37430e4a01a6b4c34913f3[root@docker-study ~]# &nbsp;&nbsp;&nbsp;该命令启动MySQL服务器 utf8mb4作为默认字符集和 utf8mb4_col数据库的默认排序规则。 &nbsp;&nbsp;&nbsp;配置MySQL服务器的另一种方法是准备配置文件并将其安装在容器内的服务器配置文件的位置。 持久化数据和配置更改&nbsp;&nbsp;&nbsp;Docker容器原则上是短暂的，如果容器被删除或损坏，预计会丢失任何数据或配置。 但是，Docker卷提供了一种机制来保存在Docker容器中创建的数据。在初始化时，MySQL Server容器为服务器数据目录创建一个Docker卷。在容器上运行docker inspect命令的JSON输出有一个 Mount键，其值提供有关数据目录卷的信息： 123456789101112131415[root@docker-study ~]# docker inspect mysql1[………… &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;4ae57cb3823bf75c18b2212530fee42bc7d851446a5fee48406542c04df62221&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/4ae57cb3823bf75c18b2212530fee42bc7d851446a5fee48406542c04df62221/_data&quot;, &quot;Destination&quot;: &quot;/var/lib/mysql&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ],………… &nbsp;&nbsp;&nbsp;输出显示/var/lib/docker/volumes/4ae57cb3823bf75c18b2212530fee42bc7d851446a5fee48406542c04df62221/_data主机文件夹（主机上持有数据）已安装在 /var/lib/mysql容器内的服务器数据目录中。 &nbsp;&nbsp;&nbsp;保留数据的另一种方法是 在创建容器时 使用–mount绑定安装主机目录。可以使用相同的技术来持久保存服务器的配置。以下命令创建MySQL Server容器并绑定安装数据目录和服务器配置文件： 1234567891011121314151617181920212223[root@docker-study ~]# lsanaconda-ks.cfg datadir docker initial-setup-ks.cfg my.cnf src[root@docker-study ~]# cat my.cnf [client]default-character-set=utf8socket = /usr/local/mysql/mysql.sock[mysql]default-character-set=utf8[mysqld]basedir = /usr/local/mysqldatadir = /var/lib/mysqlport = 3306socket = /usr/local/mysql/mysql.sockcharacter-set-server=utf8sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES[root@docker-study ~]# docker run --name=mysql1 \--mount type=bind,src=/root/my.cnf,dst=/etc/my.cnf \--mount type=bind,src=/root/datadir,dst=/var/lib/mysql \-d mysql/mysql-server:5.658d707e7a9f75b38516d17dc54ee3685e00052969c01c887b40f0ac8f819a936[root@docker-study ~]# ls datadir/ibdata1 ib_logfile0 ib_logfile1 mysql performance_schema test[root@docker-study ~]# &nbsp;&nbsp;&nbsp;安装 path-on-host-machine/my.cnf 到/etc/my.cnf（容器内部的配置文件），同时 path-on-host-machine/datadir 到/var/lib/mysql（数据容器内的目录）。必须满足以下条件才能使绑定安装正常工作： &nbsp;&nbsp;&nbsp;配置文件 path-on-host-machine/my.cnf 必须已存在，并且必须包含使用用户启动mysql服务器的规范： 123[mysqld]user=mysql………… &nbsp;&nbsp;&nbsp;数据目录 path-on-host-machine/datadir 必须已存在。要进行服务器初始化，目录必须为空。还可以安装预先填充数据的目录并启动服务器; 但是必须确保使用与创建数据的服务器相同的配置来启动Docker容器，并在启动容器时装入所需的任何主机文件或目录。 运行其他初始化脚本如果在创建数据库后立即要在数据库上运行任何.sh或 .sql脚本，则可以将它们放入主机目录，然后将目录 /docker-entrypoint-initdb.d/挂载在容器内部。例如，对于MySQL Server容器： 123docker run --name=mysql1 \--mount type=bind,src=/path-on-host-machine/scripts/,dst=/docker-entrypoint-initdb.d/ \-d mysql/mysql-server:tag 从另一个Docker容器中的应用程序连接到MySQL&nbsp;&nbsp;&nbsp;通过设置Docker网络，您可以允许多个Docker容器相互通信，以便另一个Docker容器中的客户端应用程序可以访问服务器容器中的MySQL Server。首先，创建一个Docker网络： 123[root@docker-study ~]# docker network create my-custom-nete78c79012d0e865acc06f043f03e9a900a5a478780fc0d7fb30a82ae0c644303[root@docker-study ~]# &nbsp;&nbsp;&nbsp;然后，在创建和启动服务器和客户端容器时，使用该–network选项将它们放在您创建的网络上。例如： 12345[root@docker-study ~]# docker run --name=mysql2 --network=my-custom-net -d mysql/mysql-server:5.680415ae4ba16a3e89f3b7afc5d1f4ffde028fc65a66ff7f03810828070e6a17f[root@docker-study ~]# docker run --name=web --network=my-custom-net -d httpd264833168ac671eda95d0dd10547ce9bfa18bf83bc97531f85de202f72886088[root@docker-study ~]# &nbsp;&nbsp;在mysql容器中设置web用户 12345mysql&gt; create user web@172.19.0.3 identified by &apos;123456&apos;;Query OK, 0 rows affected (0.00 sec)mysql&gt; grant all privileges on *.* to web@172.19.0.3;Query OK, 0 rows affected (0.00 sec) &nbsp;&nbsp;&nbsp;然后，web容器可以使用mysql2主机名连接到mysql2容器， 反之亦然，因为Docker会自动为给定的容器名称设置DNS。 123456789101112131415[root@docker-study var]# docker exec -it web mysql --host=mysql2 --user=web --passwordEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 37Server version: 5.6.43 MySQL Community Server (GPL)Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; 服务器错误日志&nbsp;&nbsp;&nbsp;首次使用服务器容器启动MySQL服务器时， 如果满足以下任一条件，则不会生成服务器错误日志： 已装入主机的服务器配置文件，但该文件不包含系统变量 log_error。 尚未安装主机的服务器配置文件，但Docker环境变量 MYSQL_LOG_CONSOLE 是true（MySQL 5.6服务器容器的变量的默认状态false）。然后将MySQL服务器的错误日志重定向到 stderr，以便错误日志进入Docker容器的日志，并使用docker logs mysqld-container 命令查看 。 &nbsp;&nbsp;&nbsp;要使MySQL Server在两个条件之一为真时生成错误日志，请使用该 –log-error 选项 ，配置服务器以在容器内的特定位置生成错误日志。要保留错误日志，请将主机文件挂载到容器内错误日志的位置，如上文中所述。但是必须确保其容器内的MySQL Server具有对挂载的主机文件有写访问权。 Docker环境变量&nbsp;&nbsp;&nbsp;创建MySQL Server容器时，可以使用–env选项（-e简而言之）配置MySQL实例，并指定以下一个或多个环境变量。 注意&nbsp;&nbsp;&nbsp;如果挂载的数据目录不为空，则以下变量都不会产生任何影响，因为之后不会尝试进行服务器初始化。在容器启动期间，不会修改文件夹中任何预先存在的内容，包括任何旧服务器设置。 &nbsp;&nbsp;&nbsp;布尔变量包括 MYSQL_RANDOM_ROOT_PASSWORD, MYSQL_ONETIME_PASSWORD和MYSQL_ALLOW_EMPTY_PASSWORD， MYSQL_LOG_CONSOLE 通过使用任何非零长度的字符串设置它们来实现。例如”0”，”false”或 “no”不会使它们为假，但实际上使它们成立。这是MySQL Server容器的已知问题。 MYSQL_RANDOM_ROOT_PASSWORD：当此变量为true（这是默认状态，除非 MYSQL_ROOT_PASSWORD 或MYSQL_ALLOW_EMPTY_PASSWORD 设置为true）时，将在启动Docker容器时生成服务器root用户的随机密码。密码打印到stdout容器中，可以通过查看容器的日志找到。 MYSQL_ONETIME_PASSWORD：当变量为true（这是默认状态，除非 MYSQL_ROOT_PASSWORD 已设置或MYSQL_ALLOW_EMPTY_PASSWORD 设置为true）时，root用户的密码设置为expired，必须先更改才能正常使用MySQL。 MYSQL_DATABASE：此变量允许指定要在镜像启动时创建的数据库的名称。如果用户名和密码均由 MYSQL_USER 和MYSQL_PASSWORD提供，创建用户并授予该数据库（对应于超级用户权限GRANT ALL）。指定的数据库由 CREATE DATABASE IF NOT EXIST语句创建，因此如果数据库已存在，则该变量无效。 MYSQL_USER， MYSQL_PASSWORD：这些变量结合使用来创建用户并设置该用户的密码，并为该用户授予该MYSQL_DATABASE 变量指定的数据库的超级用户权限 。MYSQL_USER 和 MYSQL_PASSWORD 用于创建用户，如果这两个变量没有设置，则忽略。如果两个变量都已设置但未设置 MYSQL_DATABASE ，则创建用户时没有任何权限。 注意&nbsp;&nbsp;没有必要使用这种机制创建root用户，这是MYSQL_ROOT_PASSWORD 和 MYSQL_RANDOM_ROOT_PASSWORD两种机制默认创建的，除非 MYSQL_ALLOW_EMPTY_PASSWORD = ture。 MYSQL_ROOT_HOST：默认情况下，MySQL会创建 ‘root‘@’localhost’帐户。此帐户只能从容器内部连接。要允许来自其他主机的根连接，请设置此环境变量。例如，该值 为172.17.0.1允许来自运行容器的主机的连接。该选项仅接受一个参数，但允许使用通配符（例如， MYSQL_ROOT_HOST=172...*或MYSQL_ROOT_HOST=%）。 MYSQL_LOG_CONSOLE：当变量为true（变量的MySQL 5.6服务器容器的默认状态为false）时，MySQL服务器的错误日志被重定向到 stderr，以便错误日志进入Docker容器的日志，并且可以使用docker logs mysqld-container 命令查看 。 注意&nbsp;&nbsp;&nbsp;如果已挂载主机的服务器配置文件，则该变量无效。MYSQL_ROOT_PASSWORD：此变量指定为MySQL root帐户设置的密码。 警告&nbsp;&nbsp;&nbsp;在命令行上设置MySQL root用户密码是不安全的。作为显式指定密码的替代方法，可以使用容器文件路径为密码文件设置变量，然后从主机中装入包含容器文件路径密码的文件。这仍然不是很安全，因为密码文件的位置仍然暴露。最好使用默认设置， MYSQL_RANDOM_ROOT_PASSWORD=true 并且 MYSQL_ONETIME_PASSWORD=true。 MYSQL_ALLOW_EMPTY_PASSWORD。将其设置为true以允许使用root用户的空密码启动容器。 警告&nbsp;&nbsp;&nbsp;将此变量设置为true是不安全的，因为它会使MySQL实例完全不受保护，从而允许任何人获得完整的超级用户访问权限。最好使用默认设置， MYSQL_RANDOM_ROOT_PASSWORD=true 并且MYSQL_ONETIME_PASSWORD=true 。]]></content>
      <tags>
        <tag>MySQL</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL介绍]]></title>
    <url>%2F2019%2F01%2F23%2FMySQL%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[什么是MySQL&nbsp;&nbsp;&nbsp;&nbsp;MySQL 是最流行的关系型数据库管理系统，在 WEB 应用方面 MySQL 是最好的关系数据库管理系统(RDBMS)应用软件之一。 MySQL数据库是关系型的&nbsp;&nbsp;&nbsp;&nbsp;关系数据库将数据存储在单独的表中，而不是将所有数据放在一个大的库房中。数据库结构被组织成针对速度优化的物理文件。逻辑模型具有数据库，表，视图，行和列等对象，可提供灵活的编程环境。可以设置管理不同数据字段之间关系的规则，例如一对一，一对多，唯一，必需或可选，以及不同表之间的”指针”。数据库强制执行这些规则，因此使用设计良好的数据库，应用程序永远不会看到不一致，重复，孤立，过时或丢失的数据。 &nbsp;&nbsp;&nbsp;&nbsp;”MYSQL” 的SQL部分代表 “ 结构化查询语言 ”。SQL是用于访问数据库的最常用的标准化语言。根据编程环境，可以直接输入SQL（例如，生成报告），将SQL语句嵌入到用其他语言编写的代码中，或使用隐藏SQL语法的特定于语言的API。 MySQL数据库服务器非常快速，可靠，可扩展且易于使用&nbsp;&nbsp;&nbsp;&nbsp;MySQL Server最初是为了比现有解决方案更快地处理大型数据库而开发的，并且已经成功地在高要求的生产环境中使用了好几年。虽然在不断发展的今天，MySQL服务器提供了丰富而有用的功能集。它的连接性，速度和安全性使MySQL Server非常适合访问Internet上的数据库。 MySQL Server适用于客户端/服务器或嵌入式系统。&nbsp;&nbsp;&nbsp;&nbsp;MySQL数据库软件是一个C/S系统，由支持不同后端的多线程SQL服务器，几个不同的客户端程序和库，管理工具以及各种应用程序编程接口（API）组成。MySQL Server作为嵌入式多线程库，可以将其链接到应用程序，以获得更小，更快，更易于管理的独立产品。 MySQL特点 内部和可移植性 用C和C ++编写。 经过多种不同编译器的测试。 适用于许多不同的平台。 为了便于携带，在MySQL 5.5及更高版本中使用CMake。以前的系列使用GNU Automake，Autoconf和Libtool。 使用Purify（商业内存泄漏检测器）以及GPL工具Valgrind（http://developer.kde.org/~sewardj/）进行测试。 使用具有独立模块的多层服务器设计。 设计为使用内核线程完全多线程，以便在可用时轻松使用多个CPU。 提供事务性和非事务性存储引擎。 使用非常快的 B-tree 磁盘表 (MyISAM）实现索引压缩。 旨在使添加其他存储引擎相对容易。如果要为内部数据库提供SQL接口，这非常有用。 使用非常快速的基于线程的内存分配系统。 使用优化的嵌套循环连接执行速度非常快。 实现内存中的哈希表用作临时表。 使用应尽可能快的高度优化的类库实现SQL函数。通常在查询初始化之后根本没有内存分配。 将服务器作为单独的程序提供，用于客户端/服务器网络环境，以及作为可嵌入（链接）到独立应用程序的库。此类应用程序可以单独使用，也可以在没有网络的环境中使用。 数据类型 许多数据类型：有符号/无符号整数，8个字节长的数据，float(浮点型)， double(双精度型)， char(字符)， varchar(变长字符串)， binary(二进制)，varbinary(可变二进制)， text(文本)， blob， date， time， datetime， timestamp， year， set， enum，和开放GIS空间类型。 固定长度和可变长度的字符串类型。 函数和语句&nbsp;&nbsp;&nbsp;&nbsp;SELECT列表和 WHERE子句查询中的 完整运算符和函数支持 。例如： 123mysql&gt; SELECT CONCAT(first_name, &apos; &apos;, last_name) -&gt; FROM citizen -&gt; WHERE income/dependents &gt; 10000 AND age &gt; 30; 完全支持SQL GROUP BY和 ORDER BY子句。支持基函数（COUNT()， AVG()， STD()， SUM()， MAX()， MIN()，和GROUP_CONCAT()）。 支持LEFT OUTER JOIN和 RIGHT OUTER JOIN使用标准SQL和ODBC语法。 根据标准SQL的要求支持表和列上的别名。 支持DELETE， INSERT， REPLACE，和 UPDATE以返回更改（受影响）的行数，或返回通过连接到服务器时设置标志，而不是匹配的行的数量。 支持特定于MySQL的SHOW语句，用于检索有关数据库，存储引擎，表和索引的信息。支持 INFORMATION_SCHEMA数据库，根据标准SQL实现。 一个EXPLAIN语句来显示优化器如何解决一个查询。 表名或列名中函数名的独立性。例如，ABS是一个有效的列名。唯一的限制是，对于函数调用，函数名和它后面的“ (”之间不允许有空格 。 可以在同一语句中引用来自不同数据库的表。 安全 特权和密码系统，非常灵活和安全，可以进行基于主机的验证。 连接到服务器时加密所有密码流量的密码安全性。 可扩展性和限制 支持大型数据库。我们将MySQL Server与包含5000万条记录的数据库结合使用。 每个表最多支持64个索引。每个索引可以包含1到16列或部分列。InnoDB表的最大索引宽度为767字节或3072字节。MyISAM表的最大索引宽度为1000个字节。索引可使用的柱的前缀CHAR， VARCHAR， BLOB，或 TEXT列类型。 连接 客户端可以使用多种协议连接到MySQL Server: i. 客户端可以在任何平台上使用TCP / IP套接字进行连接。 ii. 在Windows系统上，如果使用该–enable-named-pipe选项启动服务器，则客户端可以使用命名管道进行连接。如果使用该–shared-memory选项启动，Windows服务器也支持共享内存连接。客户端可以使用该–protocol=memory选项通过共享内存进行连接。 iii. 在Unix系统上，客户端可以使用Unix域套接字文件进行连接。 MySQL客户端程序可以用多种语言编写。用C编写的客户端库可用于用C或C ++编写的客户端，或者用于提供C绑定的任何语言。 提供C，C ++，Eiffel，Java，Perl，PHP，Python，Ruby和Tcl的API，使MySQL客户端能够以多种语言编写。 客户端和工具 MySQL包括几个客户端和实用程序。这些包括命令行程序，如 mysqldump和 mysqladmin，以及图形程序，如 MySQL Workbench。 MySQL Server内置支持SQL语句来检查，优化和修复表。这些语句可以从命令行通过 mysqlcheck客户端获得。MySQL还包括myisamchk，这是一个非常快速的命令行实用程序，用于在MyISAM 表上执行这些操作。 可以使用–help 或-?选项调用MySQL程序以获取在线帮助。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cisco UCS B200 M2安装操作系统]]></title>
    <url>%2F2019%2F01%2F19%2FCisco-UCS-B200-M2%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[由于项目需要，要求把上图系统更换为 CentOS7. 踩了不少坑，折腾一天。 服务器的型号为UCS B200 M2 ,需要在网页登录他的管理器，本地的java环境为jdk-6u10。6版本的每一个我都试了，只有这个可以。在kvm manager的页面可以下载kvm console 的java程序，在本地运行就可以了 该刀片服务器重装\安装系统需要从本地映射镜像到服务器，也是在网上看的服务器配置指导才知道，我还想着拿个显示屏怼上呢。映射步骤如下： 1.点击virtual Medis （如果报错虚拟磁盘本地库无法加载，那就是java版本的问题了） 2.左侧有”Add Images”，选中需要安装的系统就可以了 3.勾选上第一列的Mapped ，即将本地镜像文件映射到 “Virtual CD/DVD” 4.重启 5.在该界面进入boot menu ，更改启动顺序 6.选择”Cisco Virtual CD/DVD 1.22”，不要选择EFI那一项 之后就是安装CentOS的步骤了，除了在分盘的时候把之前的分区先删除干净之外，其他步骤都相同了]]></content>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译安装mysql-server5.6.32]]></title>
    <url>%2F2019%2F01%2F16%2F%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85mysql-server5-6-32%2F</url>
    <content type="text"><![CDATA[摘自：http://www.cnblogs.com/yaohan/p/6288620.html 12wget http://downloads.mysql.com/archives/get/file/mysql-5.6.32.tar.gz tar -zxvf mysql-5.6.32.tar.gz 安装编译环境 123456yum install gcc gcc-c++yum install -y ncurses-develyum install -y cmakeyum install -y libaioyum install -y bisonyum install -y perl-Module-Install.noarch 编译 12345678910cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_UNIX_ADDR=/usr/local/mysql/mysql.sock -DDEFAULT_CHARSET=utf8-DDEFAULT_COLLATION=utf8_general_ci-DWITH_INNOBASE_STORAGE_ENGINE=1-DWITH_ARCHIVE_STORAGE_ENGINE=1-DWITH_BLACKHOLE_STORAGE_ENGINE=1-DMYSQL_DATADIR=/home/mysqldata-DMYSQL_TCP_PORT=3306-DENABLE_DOWNLOADS=1 若要重新运行配置，需要删除目录内CMakeCache.txt文件 1rm CMakeCache.txt 1make &amp;&amp; make install 使用下面的命令查看是否有mysql用户及用户组 12345678cat /etc/passwd #查看用户列表cat /etc/group #查看用户组列表如果没有就创建groupadd mysqluseradd -g mysql mysql修改/usr/local/mysql权限chown -R mysql:mysql /usr/local/mysql 修改配置文件 1234567891011121314151617181920212223242526272829303132333435363738cp support-files/my-default.cnf /etc/my.cnfvi /etc/my.cnf-----my.cnf begin------[client]default-character-set=utf8socket = /usr/local/mysql/mysql.sock[mysql]default-character-set=utf8[mysqld]# Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M# Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin# These are commonly set, remove the # and set as required.basedir = /usr/local/mysqldatadir = /home/mysqldata/port = 3306# server_id = .....socket = /usr/local/mysql/mysql.sockcharacter-set-server=utf8# Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2Msql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES-----my.cnf end------ 初始化数据库 12cd /usr/local/mysql/./scripts/mysql_install_db --user=mysql --datadir=/home/mysqldata 修改文件和目录权限，否则开启服务会报错 12chown -R mysql:root /usr/local/mysql/mysql.sockchown -R mysql:root /usr/local/mysql 测试开启编译安装的Mysql 1/usr/local/mysql/bin/mysqld_safe 运行正常则添加启动脚本 1234cp support-files/mysql.server /etc/init.d/mysqlchkconfig mysql onservice mysql start --启动MySQLln -s /usr/local/mysql/bin/mysql /usr/bin]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[harbor配置文件介绍]]></title>
    <url>%2F2019%2F01%2F15%2Fharbor%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[There are two categories of parameters in harbor.cfg, required parameters and optional parameters.在harbor.cfg中有两类参数，必需参数和可选参数。 required parameters: These parameters are required to be set in the configuration file. They will take effect if a user updates them in harbor.cfg and run the install.sh script to reinstall Harbor.required参数：需要在配置文件中设置这些参数。如果用户更新它们harbor.cfg 并运行 install.sh 脚本以重新安装Harbor，它们将生效。 optional parameters: These parameters are optional for updating, i.e. user can leave them as default and update them on Web Portal after Harbor is started. If they are set in harbor.cfg, they only take effect in the first launch of Harbor. Subsequent update to these parameters in harbor.cfg will be ignored.可选参数：这些参数对于更新是可选的，即用户可以将它们保留为默认值，并在启动Harbour后在Web Portal(门户网站)上更新它们。如果它们已经启用harbor.cfg，它们只会在首次启动Harbour时生效。harbor.cfg将忽略对这些参数的后续更新。 Note: If you choose to set these parameters via the Portal, be sure to do so right after Harbor is started. In particular, you must set the desired auth_mode before registering or creating any new users in Harbor. When there are users in the system (besides the default admin user), auth_mode cannot be changed.注意：如果你选择通过Portal设置这些参数，请务必在Harbour启动后立即执行此操作。特别是，你必须在Harbour中注册或创建任何新用户之前设置auth_mode。当系统中有用户时（除默认管理员用户外）， 无法更改auth_mode。 Required parameters: 必须参数hostname: The target host’s hostname, which is used to access the Portal and the registry service. It should be the IP address or the fully qualified domain name (FQDN) of your target machine, e.g., 192.168.1.10 or reg.yourdomain.com. Do NOT use localhost or 127.0.0.1 for the hostname - the registry service needs to be accessible by external clients!hostname：目标主机的主机名，用于访问Portal和registry服务。它应该是目标计算机的IP地址或完全限定的域名（FQDN），例如，192.168.1.10或reg.yourdomain.com。不要使用localhost或127.0.0.1作为主机名 - 外部客户端需要访问registry服务！ ui_url_protocol: (http or https. Default is http) The protocol used to access the Portal and the token/notification service. If Notary is enabled, this parameter has to be https. By default, this is http.ui_url_protocol :( http或https。默认为http）用于访问Portal和令牌/通知服务的协议。如果启用了公证，则此参数必须为https。默认情况下是http。 db_password: The root password for the PostgreSQL database used for db_auth. Change this password for any production use!db_password：用于db_auth的PostgreSQL数据库的root密码。生产环境中要修改密码！ max_job_workers: (default value is 10) The maximum number of replication workers in job service. For each image replication job, a worker synchronizes all tags of a repository to the remote destination. Increasing this number allows more concurrent replication jobs in the system. However, since each worker consumes a certain amount of network/CPU/IO resources, please carefully pick the value of this attribute based on the hardware resource of the host.max_job_workers :(默认值为10）作业服务中的最大复制工作数。对于每个镜像复制作业，工作程序将存储库的所有标记同步到远程目标。增加此数量可以在系统中实现更多并发复制作业。但是，由于每个工作者都消耗一定量的网络/ CPU / IO资源，请根据主机的硬件资源仔细选择该属性的值。 customize_crt: (on or off. Default is on) When this attribute is on, the prepare script creates private key and root certificate for the generation/verification of the registry’s token. Set this attribute to off when the key and root certificate are supplied by external sources.customize_crt：（开启或关闭，默认为开启），如果此属性开启，在准备脚本创建registry的令牌生成/验证私钥和根证书。当外部源提供密钥和根证书时，将此属性设置为off。 ssl_cert: The path of SSL certificate, it’s applied only when the protocol is set to https.ssl_cert：SSL证书的路径，仅在协议设置为https时应用。 ssl_cert_key: The path of SSL key, it’s applied only when the protocol is set to https.ssl_cert_key：SSL密钥的路径，仅在协议设置为https时应用。 secretkey_path: The path of key for encrypt or decrypt the password of a remote registry in a replication policy.secretkey_path：用于加密或解密复制策略中远程registry密码的密钥路径。 log_rotate_count: Log files are rotated log_rotate_count times before being removed. If count is 0, old versions are removed rather than rotated.log_rotate_count：日志文件在被删除之前会被轮换log_rotate_count次。如果count为0，则删除旧版本而不会轮转。 log_rotate_size: Log files are rotated only if they grow bigger than log_rotate_size bytes. If size is followed by k, the size is assumed to be in kilobytes. If the M is used, the size is in megabytes, and if G is used, the size is in gigabytes. So size 100, size 100k, size 100M and size 100G are all valid.log_rotate_size：仅当日志文件大于log_rotate_size字节时才会轮换日志文件。如果大小后跟k，则假定大小以千字节为单位。如果使用M，则大小以兆字节为单位，如果使用G，则大小为千兆字节。尺寸100，尺寸100k，尺寸100M和尺寸100G都是有效的。 http_proxy: Config http proxy for Clair, e.g. http://my.proxy.com:3128.http_proxy：为Clair配置http代理，例如http://my.proxy.com:3128。 https_proxy: Config https proxy for Clair, e.g. http://my.proxy.com:3128.https_proxy：为Clair配置https代理，例如http://my.proxy.com:3128。 no_proxy: Config no proxy for Clair, e.g. 127.0.0.1,localhost,core,registry.no_proxy：为Clair配置无代理，例如127.0.0.1,localhost,core,registry。 Optional parameters 可选参数Email settings: These parameters are needed for Harbor to be able to send a user a “password reset” email, and are only necessary if that functionality is needed. Also, do note that by default SSL connectivity is not enabled - if your SMTP server requires SSL, but does not support STARTTLS, then you should enable SSL by setting email_ssl = true. Setting email_insecure = true if the email server uses a self-signed or untrusted certificate.电子邮件设置：Harbor需要这些参数才能向用户发送“密码重置”电子邮件，并且仅在需要该功能时才需要。另外，请注意，在默认情况下SSL连接是禁用的，如果你的SMTP服务器需要SSL，但不支持STARTTLS，那么你应该通过设置启用SSL email_ssl = TRUE。如果电子邮件服务器使用自签名证书或不受信任证书，则设置email_insecure = true。 12345678email_server = smtp.mydomain.comemail_server_port = 25email_identity =email_username = sample_admin@mydomain.comemail_password = abcemail_from = admin sample_admin@mydomain.comemail_ssl = falseemail_insecure = false harbor_admin_password: The administrator’s initial password. This password only takes effect for the first time Harbor launches. After that, this setting is ignored and the administrator’s password should be set in the Portal. Note that the default username/password are admin/Harbor12345 .harbor_admin_password：管理员的初始密码。此密码仅在Harbor首次启动时生效。之后，将忽略此设置，并且应在Portal中设置管理员密码。请注意，默认用户名/密码为admin / Harbor12345。 auth_mode: The type of authentication that is used. By default, it is db_auth, i.e. the credentials are stored in a database. For LDAP authentication, set this to ldap_auth.auth_mode：使用的身份验证类型。默认情况下，它是db_auth，即凭据存储在数据库中。对于LDAP身份验证，请将其设置为ldap_auth.IMPORTANT: When upgrading from an existing Harbor instance, you must make sure auth_mode is the same in harbor.cfg before launching the new version of Harbor. Otherwise, users may not be able to log in after the upgrade.重要信息：从现有Harbor实例升级时，必须确保在启动新版本的Harbor之前harbor.cfg中的auth_mode相同。否则，用户可能无法在升级后登录。 ldap_url: The LDAP endpoint URL (e.g. ldaps://ldap.mydomain.com). Only used when auth_mode is set to ldap_auth .ldap_url：LDAP端点URL（例如ldaps://ldap.mydomain.com）。 仅在auth_mode设置为ldap_auth时使用。 ldap_searchdn: The DN of a user who has the permission to search an LDAP/AD server (e.g. uid=admin,ou=people,dc=mydomain,dc=com).ldap_searchdn：具有搜索LDAP/AD服务器权限的用户的DN（例如uid=admin,ou=people,dc=mydomain,dc=com）。 ldap_search_pwd: The password of the user specified by ldap_searchdn.ldap_search_pwd：ldap_searchdn指定的用户密码。 ldap_basedn: The base DN to look up a user, e.g. ou=people,dc=mydomain,dc=com. Only used when auth_mode is set to ldap_auth .ldap_basedn：查找用户的基本DN，例如ou=people,dc=mydomain,dc=com。 仅在auth_mode设置为ldap_auth时使用。 ldap_filter: The search filter for looking up a user, e.g. (objectClass=person).ldap_filter：用于查找用户的搜索过滤器，例如(objectClass=person) ldap_uid: The attribute used to match a user during a LDAP search, it could be uid, cn, email or other attributes.ldap_uid：用于在LDAP搜索期间匹配用户的属性，它可以是uid，cn，email或其他属性。 ldap_scope: The scope to search for a user, 0-LDAP_SCOPE_BASE, 1-LDAP_SCOPE_ONELEVEL, 2-LDAP_SCOPE_SUBTREE. Default is 2.ldap_scope：搜索用户的范围，0-LDAP_SCOPE_BASE，1-LDAP_SCOPE_ONELEVEL，2-LDAP_SCOPE_SUBTREE。默认值为2。 ldap_timeout: Timeout (in seconds) when connecting to an LDAP Server. Default is 5.ldap_timeout：连接LDAP服务器时超时（以秒为单位）。默认值为5。 ldap_verify_cert: Verify certificate from LDAP server. Default is true.ldap_verify_cert：验证来自LDAP服务器的证书。默认为true。 ldap_group_basedn: The base dn from which to lookup a group in LDAP/AD, e.g. ou=group,dc=mydomain,dc=com.ldap_group_basedn：在LDAP / AD中查找组的基本dn，例如ou=group,dc=mydomain,dc=com。 ldap_group_filter: The filter to search LDAP/AD group, e.g. objectclass=group.ldap_group_filter：搜索LDAP / AD组的过滤器，例如objectclass=group。 ldap_group_gid: The attribute used to name a LDAP/AD group, it could be cn, name.ldap_group_gid：用于命名LDAP / AD组的属性，它可以是cn，name。 ldap_group_scope: The scope to search for ldap groups. 0-LDAP_SCOPE_BASE, 1-LDAP_SCOPE_ONELEVEL, 2-LDAP_SCOPE_SUBTREE. Default is 2.ldap_group_scope：搜索ldap组的范围。0-LDAP_SCOPE_BASE，1-LDAP_SCOPE_ONELEVEL，2-LDAP_SCOPE_SUBTREE。默认值为2。 self_registration: (on or off. Default is on) Enable / Disable the ability for a user to register himself/herself. When disabled, new users can only be created by the Admin user, only an admin user can create new users in Harbor. NOTE: When auth_mode is set to ldap_auth, self-registration feature is always disabled, and this flag is ignored.self_registration :( 打开或关闭。默认打开）启用/禁用用户注册功能。禁用时，新用户只能由管理员用户创建，只有管理员用户可以在Harbor中创建新用户。注意：当auth_mode设置为ldap_auth时，始终禁用自注册功能，并忽略此标志。 token_expiration: The expiration time (in minutes) of a token created by token service, default is 30 minutes.token_expiration：令牌服务创建的令牌的到期时间（以分钟为单位），默认为30分钟。 project_creation_restriction: The flag to control what users have permission to create projects. By default everyone can create a project, set to “adminonly” such that only admin can create project.project_creation_restriction：用于控制用户有权创建项目的标志。默认情况下，每个人都可以创建一个项目；设置为“adminonly”，则只有管理员才能创建项目。 Configuring storage backend (optional) 配置存储后端（可选）By default, Harbor stores images on your local filesystem. In a production environment, you may consider using other storage backend instead of the local filesystem, like S3, OpenStack Swift, Ceph, etc. These parameters are configurations for registry.默认情况下，Harbor将镜像存储在本地文件系统中。在生产环境中，您可以考虑使用其他存储后端而不是本地文件系统，如S3，OpenStack Swift，Ceph等。这些参数是registry的配置。 registry_storage_provider_name: Storage provider name of registry, it can be filesystem, s3, gcs, azure, etc. Default is filesystem.registry_storage_provider_name：存储仓库名称，可以是filesystem，s3，gcs，azure等。默认为filesystem。 registry_storage_provider_config: Comma separated “key: value” pairs for storage provider config, e.g. “key1: value, key2: value2”. Default is empty string.registry_storage_provider_config：配置分隔键值对，例如“key1：value，key2：value2”。默认为空字符串。 registry_custom_ca_bundle: The path to the custom root ca certificate, which will be injected into the truststore of registry’s and chart repository’s containers. This is usually needed when the user hosts a internal storage with self signed certificate.registry_custom_ca_bundle：当用户使用自签名证书托管内部存储时，通常需要自定义根ca证书的路径，它将注入到registry和image存储库容器的信任库中。例如，如果使用Openstack Swift作为存储后端，则参数可能如下所示： 12registry_storage_provider_name = swiftregistry_storage_provider_config = “ username：admin，password：ADMIN_PASS，authurl：http：// kestone_addr：35357 / v3 / auth，tenant：admin，domain：default，region：regionOne，container：docker_images ” 对于LADP以及证书不理解，需要加入到后续的学习计划。]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[harbor 企业级docker registry]]></title>
    <url>%2F2019%2F01%2F12%2Fharbor-%E4%BC%81%E4%B8%9A%E7%BA%A7docker-registry%2F</url>
    <content type="text"><![CDATA[关于HarborHarbor is an an open source trusted cloud native registry project that stores, signs, and scans content. Harbor extends the open source Docker Distribution by adding the functionalities usually required by users such as security, identity and management. Having a registry closer to the build and run environment can improve the image transfer efficiency. Harbor supports replication of images between registries, and also offers advanced security features such as user management, access control and activity auditing.Harbor是一个开源的可信云本机registry项目，用于存储，签名和扫描内容。Harbor通过添加用户通常需要的功能（如安全性，身份和管理）来扩展开源Docker Distribution。使注册表更接近构建和运行环境可以提高图像传输效率。Harbor支持在注册表之间复制映像，还提供高级安全功能，如用户管理，访问控制和活动审计。 Features 特性Cloud native registry: With support for both container images and Helm charts, Harbor serves as registry for cloud native environments like container runtimes and orchestration platforms.云本机registry：Harbour支持容器镜像和Helm图表，可用作云本机环境（如容器运行时和业务流程平台）的registry。 Role based access control: Users and repositories are organized via ‘projects’ and a user can have different permission for images under a project.基于角色的访问控制：用户和存储库通过“项目”进行组织，用户可以对项目下的镜像拥有不同的权限。 Policy based image replication: Images can be replicated (synchronized) between multiple registry instances based on policies with multiple filters (repository, tag and label). Harbor will auto-retry to replicate if it encounters any errors. Great for load balancing, high availability, multi-datacenter, hybrid and multi-cloud scenarios.基于策略的镜像复制：可以基于具有多个过滤器（存储库，标记和标签）的策略在多个registry实例之间复制（同步）镜像。如果遇到任何错误，Harbor将自动重试进行复制。非常适合负载平衡，高可用性，多数据中心，混合和多云场景。 Vulnerability Scanning: Harbor scans images regularly and warns users of vulnerabilities.漏洞扫描：Harbor定期扫描镜像并警告用户漏洞。 LDAP/AD support: Harbor integrates with existing enterprise LDAP/AD for user authentication and management, and supports importing LDAP groups into Harbor and assigning proper project roles to them.LDAP / AD支持：Harbor与现有企业LDAP / AD集成以进行用户身份验证和管理，并支持将LDAP组导入Harbor并为其分配适当的项目角色。 Image deletion &amp; garbage collection: Images can be deleted and their space can be recycled.图像删除和垃圾收集：可以删除镜像，并可以回收它们的空间。 Notary: Image authenticity can be ensured.公证：可以确保镜像的真实性。 Graphical user portal: User can easily browse, search repositories and manage projects.用户图形界面：用户可以轻松浏览，搜索存储库和管理项目。 Auditing: All the operations to the repositories are tracked.审计：跟踪存储库的所有操作。 RESTful API: RESTful APIs for most administrative operations, easy to integrate with external systems.RESTful API：适用于大多数管理操作的RESTful API，易于与外部系统集成。 Easy deployment: Provide both an online and offline installer.易于部署：提供在线和离线安装程序。 企业级Registry项目Harbor是由Vmware公司开发的开源项目，其的目标是帮助用户迅速搭建一个企业级的Docker registry 服务。它以Docker公司开源的registry 为基础，提供了管理UI, 基于角色的访问控制(Role Based Access Control)，AD/LDAP集成、以及审计日志(Audit logging) 等企业用户需求的功能，同时还原生支持中文。 Harbor的每个组件都是以Docker 容器的形式构建的，因此很自然地，我们使用Docker Compose来对它进行部署。在源代码中(https://github.com/vmware/harbor), 用于部署Harbor的Docker Compose 模板位于 /Deployer/docker-compose.yml. 打开这个模板文件，会发现Harbor由5个容器组成： proxy: 由Nginx 服务器构成的反向代理。 registry:由Docker官方的开源registry 镜像构成的容器实例。 ui: 即架构中的core services, 构成此容器的代码是Harbor项目的主体。 mysql: 由官方MySql镜像构成的数据库容器。 log: 运行着rsyslogd的容器，通过log-driver的形式收集其他容器的日志。 这几个容器通过Docker link的形式连接在一起，这样，在容器之间可以通过容器名字互相访问。对终端用户而言，只需要暴露proxy （即Nginx）的服务端口。（摘自 http://dockone.io/article/1179） 安装及配置(参考 https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md 下载harbor软件包：https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-offline-installer-v1.7.1.tgzharbor软件包较大，建议科学上网 解压后如下 123[root@Web2 harbor]# lscommon docker-compose.clair.yml docker-compose.yml harbor.v1.7.1.tar.gz LICENSE preparedocker-compose.chartmuseum.yml docker-compose.notary.yml harbor.cfg install.sh open_source_license 12345678910111213141516171819202122232425262728293031323334[root@Web2 ~]# yum info docker-compose已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.neusoft.edu.cn * epel: mirrors.tuna.tsinghua.edu.cn * extras: mirrors.nwsuaf.edu.cn * updates: mirrors.tuna.tsinghua.edu.cn已安装的软件包名称 ：docker-compose架构 ：noarch版本 ：1.18.0发布 ：2.el7大小 ：1.1 M源 ：installed来自源：epel简介 ： Multi-container orchestration for Docker网址 ：https://github.com/docker/compose协议 ： ASL 2.0描述 ： Compose is a tool for defining and running multi-container Docker : applications. With Compose, you use a Compose file to configure your : application&apos;s services. Then, using a single command, you create and : start all the services from your configuration. : : Compose is great for development, testing, and staging environments, : as well as CI workflows. : : Using Compose is basically a three-step process. : : 1. Define your app&apos;s environment with a Dockerfile so it can be : reproduced anywhere. : 2. Define the services that make up your app in docker-compose.yml so : they can be run together in an isolated environment: : 3. Lastly, run docker-compose up and Compose will start and run your : entire app. 还需要docker-compose 编排工具，该工具在epel源中提供，所以需要先配置epel源；然后再安装即可 123yum install epel-releaseyum repolistyum install docker-compose python和openssl 1234567[root@Web2 ~]# opensslOpenSSL&gt; versionOpenSSL 1.0.2k-fips 26 Jan 2017OpenSSL&gt; exit[root@Web2 ~]# python --versionPython 2.7.5[root@Web2 ~]# 修改harbor配置文件 123[root@Web2 ~]# vim /usr/local/harbor/harbor.cfg hostname = 172.18.74.101 //IP地址或域名max_job_workers = 3 //CPU数减一 Harbor has integrated with Notary and Clair (for vulnerability scanning). However, the default installation does not include Notary or Clair service.Harbor已与Notary和Clair集成（用于漏洞扫描）。但是，默认安装不包括Notary或Clair服务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135执行脚本安装harbor[root@Web2 harbor]# ./install.sh [Step 0]: checking installation environment ...Note: docker version: 18.09.0Note: docker-compose version: 1.18.0[Step 1]: loading Harbor images ...ae18db924eef: Loading layer [==================================================&gt;] 32.92MB/32.92MB1c06074dba9c: Loading layer [==================================================&gt;] 8.955MB/8.955MB7a719a639e34: Loading layer [==================================================&gt;] 3.072kB/3.072kB49f7bca05da9: Loading layer [==================================================&gt;] 2.56kB/2.56kBe86d69bef97e: Loading layer [==================================================&gt;] 2.56kB/2.56kB81e122d773f5: Loading layer [==================================================&gt;] 2.048kB/2.048kB5fe5adb8cf31: Loading layer [==================================================&gt;] 22.8MB/22.8MBd760045419e4: Loading layer [==================================================&gt;] 22.8MB/22.8MBLoaded image: goharbor/registry-photon:v2.6.2-v1.7.1c0f668a21621: Loading layer [==================================================&gt;] 133.2MB/133.2MBf8cb0bf39ff2: Loading layer [==================================================&gt;] 684MB/684MB444ac38a117b: Loading layer [==================================================&gt;] 7.68kB/7.68kB2e16f24ac8bc: Loading layer [==================================================&gt;] 212kB/212kBLoaded image: goharbor/harbor-migrator:v1.7.1fa2dcaba747a: Loading layer [==================================================&gt;] 8.955MB/8.955MBeeaaf4c760eb: Loading layer [==================================================&gt;] 15.6MB/15.6MB98ffd6175b61: Loading layer [==================================================&gt;] 18.94kB/18.94kBfc1db6c4f652: Loading layer [==================================================&gt;] 15.6MB/15.6MBLoaded image: goharbor/harbor-adminserver:v1.7.18d55a6a034d6: Loading layer [==================================================&gt;] 8.955MB/8.955MB01ef68a17913: Loading layer [==================================================&gt;] 27.24MB/27.24MBf9258cfa4b48: Loading layer [==================================================&gt;] 5.632kB/5.632kBdcf5c61ede76: Loading layer [==================================================&gt;] 27.24MB/27.24MBLoaded image: goharbor/harbor-core:v1.7.11f65d10893c9: Loading layer [==================================================&gt;] 50.39MB/50.39MB358f40be2091: Loading layer [==================================================&gt;] 3.584kB/3.584kBc7f3ef058d0b: Loading layer [==================================================&gt;] 3.072kB/3.072kB154caf7c7173: Loading layer [==================================================&gt;] 4.096kB/4.096kB42c7764aa777: Loading layer [==================================================&gt;] 3.584kB/3.584kB023f3a96f324: Loading layer [==================================================&gt;] 10.24kB/10.24kBLoaded image: goharbor/harbor-log:v1.7.1a1b528067504: Loading layer [==================================================&gt;] 8.955MB/8.955MB2d3d34f3ba5b: Loading layer [==================================================&gt;] 21.51MB/21.51MBa5da70777097: Loading layer [==================================================&gt;] 21.51MB/21.51MBLoaded image: goharbor/harbor-jobservice:v1.7.1ab31dfc84e9d: Loading layer [==================================================&gt;] 8.954MB/8.954MBb130423af762: Loading layer [==================================================&gt;] 13.43MB/13.43MB357c059d0598: Loading layer [==================================================&gt;] 17.3MB/17.3MBfabc6edfac55: Loading layer [==================================================&gt;] 11.26kB/11.26kBcfaa3b5d445a: Loading layer [==================================================&gt;] 3.072kB/3.072kB12c73a4b2c7a: Loading layer [==================================================&gt;] 30.72MB/30.72MBLoaded image: goharbor/notary-server-photon:v0.6.1-v1.7.150a6467bd619: Loading layer [==================================================&gt;] 113MB/113MB6ae61fc91943: Loading layer [==================================================&gt;] 11.46MB/11.46MB5c840c272f78: Loading layer [==================================================&gt;] 2.048kB/2.048kB077d16ebcba8: Loading layer [==================================================&gt;] 48.13kB/48.13kBb822f5ff7858: Loading layer [==================================================&gt;] 3.072kB/3.072kB4548140152fd: Loading layer [==================================================&gt;] 11.51MB/11.51MBLoaded image: goharbor/clair-photon:v2.0.7-v1.7.1232024be30e3: Loading layer [==================================================&gt;] 3.39MB/3.39MBa73624ae3fad: Loading layer [==================================================&gt;] 4.721MB/4.721MB96b8c5c532c3: Loading layer [==================================================&gt;] 3.584kB/3.584kBLoaded image: goharbor/harbor-portal:v1.7.1e2fd12afe6e8: Loading layer [==================================================&gt;] 63.31MB/63.31MBe973513bcb58: Loading layer [==================================================&gt;] 40.74MB/40.74MB4f45af643b2b: Loading layer [==================================================&gt;] 6.656kB/6.656kB54a84094f024: Loading layer [==================================================&gt;] 2.048kB/2.048kB2d78cf8a687b: Loading layer [==================================================&gt;] 7.68kB/7.68kBe96067b83a72: Loading layer [==================================================&gt;] 2.56kB/2.56kB38a7d304147f: Loading layer [==================================================&gt;] 2.56kB/2.56kBa36c0cb6a35a: Loading layer [==================================================&gt;] 2.56kB/2.56kBLoaded image: goharbor/harbor-db:v1.7.1b0c31ad64c85: Loading layer [==================================================&gt;] 65.01MB/65.01MB22fbab41769e: Loading layer [==================================================&gt;] 3.072kB/3.072kB7f28bf5373b2: Loading layer [==================================================&gt;] 59.9kB/59.9kBabb9969cff2a: Loading layer [==================================================&gt;] 61.95kB/61.95kBLoaded image: goharbor/redis-photon:v1.7.1933cd9a15fc5: Loading layer [==================================================&gt;] 3.39MB/3.39MBLoaded image: goharbor/nginx-photon:v1.7.16ee16a137af2: Loading layer [==================================================&gt;] 8.955MB/8.955MB954443cb7d20: Loading layer [==================================================&gt;] 22.8MB/22.8MB302a998137db: Loading layer [==================================================&gt;] 3.072kB/3.072kBe342723aef9b: Loading layer [==================================================&gt;] 7.465MB/7.465MB4eeb61ed730b: Loading layer [==================================================&gt;] 30.26MB/30.26MBLoaded image: goharbor/harbor-registryctl:v1.7.15b40d957fafd: Loading layer [==================================================&gt;] 12.11MB/12.11MB63489681dd6c: Loading layer [==================================================&gt;] 17.3MB/17.3MB696209dcd336: Loading layer [==================================================&gt;] 11.26kB/11.26kB8dc53997aa1f: Loading layer [==================================================&gt;] 3.072kB/3.072kBcb6d560a9958: Loading layer [==================================================&gt;] 29.41MB/29.41MBLoaded image: goharbor/notary-signer-photon:v0.6.1-v1.7.1dc1e16790c89: Loading layer [==================================================&gt;] 8.96MB/8.96MB046c7e7a0100: Loading layer [==================================================&gt;] 35.08MB/35.08MB8c8428e3d6c6: Loading layer [==================================================&gt;] 2.048kB/2.048kBebb477ee35a2: Loading layer [==================================================&gt;] 3.072kB/3.072kB19636f39e29d: Loading layer [==================================================&gt;] 35.08MB/35.08MBLoaded image: goharbor/chartmuseum-photon:v0.7.1-v1.7.1[Step 2]: preparing environment ...Generated and saved secret to file: /data/secretkeyGenerated configuration file: ./common/config/nginx/nginx.confGenerated configuration file: ./common/config/adminserver/envGenerated configuration file: ./common/config/core/envGenerated configuration file: ./common/config/registry/config.ymlGenerated configuration file: ./common/config/db/envGenerated configuration file: ./common/config/jobservice/envGenerated configuration file: ./common/config/jobservice/config.ymlGenerated configuration file: ./common/config/log/logrotate.confGenerated configuration file: ./common/config/registryctl/envGenerated configuration file: ./common/config/core/app.confCreating harbor-log ... doneThe configuration files are ready, please use docker-compose to start the service.[Step 3]: checking existing instance of Harbor ...Creating registry ... doneCreating harbor-core ... done[Step 4]: starting Harbor ...Creating harbor-portal ... doneCreating nginx ... doneCreating harbor-adminserver ... Creating harbor-db ... Creating redis ... Creating registry ... Creating registryctl ... Creating harbor-core ... Creating harbor-jobservice ... Creating harbor-portal ... Creating nginx ... ✔ ----Harbor has been installed and started successfully.----Now you should be able to visit the admin portal at http://172.18.74.101. For more details, please visit https://github.com/goharbor/harbor . 在安装 脚本执行过程过程中看到下拉了很多镜像，Harbor的每个组件都是以Docker 容器的形式构建的。 1234567891011121314151617181920212223242526272829[root@Web2 ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEgoharbor/chartmuseum-photon v0.7.1-v1.7.1 f61c186d5b1b 6 days ago 111MBgoharbor/harbor-migrator v1.7.1 9ec6467899b6 6 days ago 799MBgoharbor/redis-photon v1.7.1 c7aa92fb1c26 6 days ago 96.3MBgoharbor/clair-photon v2.0.7-v1.7.1 832461eef7dd 6 days ago 165MBgoharbor/notary-server-photon v0.6.1-v1.7.1 382cd390eaff 6 days ago 102MBgoharbor/notary-signer-photon v0.6.1-v1.7.1 76486e1aa1a2 6 days ago 99.6MBgoharbor/harbor-registryctl v1.7.1 aefea98e6f92 6 days ago 101MBgoharbor/registry-photon v2.6.2-v1.7.1 13b348ffd0c9 6 days ago 86.4MBgoharbor/nginx-photon v1.7.1 9b9520572494 6 days ago 35.5MBgoharbor/harbor-log v1.7.1 0744800d7a4c 6 days ago 81MBgoharbor/harbor-jobservice v1.7.1 db96ce6ed531 6 days ago 83.8MBgoharbor/harbor-core v1.7.1 8f253c0f9d50 6 days ago 95.2MBgoharbor/harbor-portal v1.7.1 b50162ab177a 6 days ago 40.2MBgoharbor/harbor-adminserver v1.7.1 22d66cccedba 6 days ago 72MBgoharbor/harbor-db v1.7.1 c2a95254c0bf 6 days ago 133MB[root@Web2 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf007d1aae3fa goharbor/nginx-photon:v1.7.1 &quot;nginx -g &apos;daemon of…&quot; About a minute ago Up About a minute (healthy) 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:4443-&gt;4443/tcp nginxbf48e808d152 goharbor/harbor-portal:v1.7.1 &quot;nginx -g &apos;daemon of…&quot; About a minute ago Up About a minute (healthy) 80/tcp harbor-portal0d78ea5ff51f goharbor/harbor-jobservice:v1.7.1 &quot;/harbor/start.sh&quot; About a minute ago Up About a minute harbor-jobservicec07ca8d7cf72 goharbor/harbor-core:v1.7.1 &quot;/harbor/start.sh&quot; About a minute ago Up About a minute (healthy) harbor-cored6ce992225e9 goharbor/harbor-adminserver:v1.7.1 &quot;/harbor/start.sh&quot; About a minute ago Up About a minute (healthy) harbor-adminserver86200773e6fc goharbor/harbor-registryctl:v1.7.1 &quot;/harbor/start.sh&quot; About a minute ago Up About a minute (healthy) registryctla496f40a1d95 goharbor/harbor-db:v1.7.1 &quot;/entrypoint.sh post…&quot; About a minute ago Up About a minute (healthy) 5432/tcp harbor-dbbecbead56360 goharbor/redis-photon:v1.7.1 &quot;docker-entrypoint.s…&quot; About a minute ago Up About a minute 6379/tcp redisb66044203146 goharbor/registry-photon:v2.6.2-v1.7.1 &quot;/entrypoint.sh /etc…&quot; About a minute ago Up About a minute (healthy) 5000/tcp registryd6f266aa5a49 goharbor/harbor-log:v1.7.1 &quot;/bin/sh -c /usr/loc…&quot; About a minute ago Up About a minute (healthy) 127.0.0.1:1514-&gt;10514/tcp harbor-log 以admin/Harbor12345 默认登录名密码进行登录 将镜像推送至registryHarbor的默认安装使用HTTP协议，需要将 –insecure-registry 参数添加进客户端的daemon.json 。 12345root@ubuntu16:~# vim /etc/docker/daemon.json&#123; &quot;insecure-registries&quot;:[&quot;172.18.74.101&quot;]&#125;root@ubuntu16:~# systemctl restart docker 然后以admin身份登录 1234root@ubuntu16:~# docker login 172.18.74.101Username: adminPassword: Login Succeeded 对镜像进行打标 ，使用docker tag 命令 12345root@ubuntu16:~# docker tag alpine 172.18.74.101/library/alpine:latestroot@ubuntu16:~# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEalpine latest 196d12cf6ab1 4 months ago 4.41MB172.18.74.101/library/alpine latest 196d12cf6ab1 4 months ago 4.41MB 推送镜像 1234root@ubuntu16:~# docker push 172.18.74.101/library/alpineThe push refers to a repository [172.18.74.101/library/alpine]df64d3292fd6: Pushed latest: digest: sha256:76ebd8b93b384fe8121d87be22c2089843f663fb342f1e6345a0a0bd6424c5c2 size: 528 推送后在Harbor中即可看到alpine镜像 Harbor管理使用docker-compose命令可以用来管理Harbor，但是必须与docker-compose.yml在同一目录中运行，否则报错如下。 12345ERROR: Can&apos;t find a suitable configuration file in this directory or any parent. Are you in the right directory? Supported filenames: docker-compose.yml, docker-compose.yaml 使用 docker-compose stop 来关闭Harbor和docker-compose start 关闭后进行重启。 123456789101112131415161718192021222324[root@Web2 harbor]# docker-compose stopStopping nginx ... doneStopping harbor-portal ... doneStopping harbor-jobservice ... doneStopping harbor-core ... doneStopping harbor-adminserver ... doneStopping registryctl ... doneStopping harbor-db ... doneStopping redis ... doneStopping registry ... doneStopping harbor-log ... done[root@Web2 harbor]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@Web2 harbor]# docker-compose startStarting log ... doneStarting redis ... doneStarting adminserver ... doneStarting registryctl ... doneStarting registry ... doneStarting core ... doneStarting portal ... doneStarting jobservice ... doneStarting postgresql ... doneStarting proxy ... done 要更改Harbour的配置，要停止现有的Harbor实例并更新 harbor.cfg。然后运行 prepare 脚本以填充配置。最后重新创建并启动Harbor 1234sudo docker-compose down -vvim harbor.cfgsudo preparesudo docker-compose up -d 默认情况下，注册表数据保留在主机的/data/目录中。即使Harbor的容器被移除和/或重新创建，此数据仍保持不变。 1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@Web2 data]# lsca_download config database job_logs psc redis registry secretkey[root@Web2 data]# cd registry/[root@Web2 registry]# tree.└── docker └── registry └── v2 ├── blobs │ └── sha256 │ ├── 19 │ │ └── 196d12cf6ab19273823e700516e98eb1910b03b17840f9d5509f03858484d321 │ │ └── data │ ├── 76 │ │ └── 76ebd8b93b384fe8121d87be22c2089843f663fb342f1e6345a0a0bd6424c5c2 │ │ └── data │ └── c4 │ └── c432c1aab6335df5a9ff6237f8d19627f95ea7dc3f5709c555b2a28cd8df4d0a │ └── data └── repositories └── library └── alpine ├── _layers │ └── sha256 │ ├── 196d12cf6ab19273823e700516e98eb1910b03b17840f9d5509f03858484d321 │ │ └── link │ └── c432c1aab6335df5a9ff6237f8d19627f95ea7dc3f5709c555b2a28cd8df4d0a │ └── link ├── _manifests │ ├── revisions │ │ └── sha256 │ │ └── 76ebd8b93b384fe8121d87be22c2089843f663fb342f1e6345a0a0bd6424c5c2 │ │ └── link │ └── tags │ └── latest │ ├── current │ │ └── link │ └── index │ └── sha256 │ └── 76ebd8b93b384fe8121d87be22c2089843f663fb342f1e6345a0a0bd6424c5c2 │ └── link └── _uploads29 directories, 8 files 此外，Harbor使用 rsyslog 来收集每个容器的日志。默认情况下，这些日志文件存储在/var/log/harbor/目标主机上的目录中以进行故障排除。 123[root@Web2 registry]# cd /var/log/harbor/[root@Web2 harbor]# lsadminserver.log core.log jobservice.log portal.log postgresql.log proxy.log redis.log registryctl.log registry.log 删除Harbor的容器，同时将图像数据和Harbor的数据库文件保存在文件系统上： 1sudo docker-compose down -v 删除Harbor的数据库和图像数据（用于重新安装）： 12rm -r / data / database rm -r / data / registry 自定义配置Harbor监听端口1.修改docker-compose.yml将默认的80:80 修改为8888:80，访问主机8888端口nginx容器就可以代理至harbor-portal容器的80端口 1234567891011121314151617181920proxy: image: goharbor/nginx-photon:v1.6.0 container_name: nginx restart: always volumes: - ./common/config/nginx:/etc/nginx:z ports: - 8888:80 //将默认的80:80 修改为8888:80 - 443:443 depends_on: - postgresql - registry - core - portal - log logging: driver: &quot;syslog&quot; options: syslog-address: &quot;tcp://127.0.0.1:1514&quot; tag: &quot;proxy&quot; 2. 修改harbor.cfg1hostname = 172.18.74.101:8888 3.重新部署Harbor见上文]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker私有仓库docker-registry搭建]]></title>
    <url>%2F2019%2F01%2F09%2Fdocker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93docker-registry%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[关于docker-registryThe Registry is a stateless, highly scalable server side application that stores and lets you distribute Docker images. The Registry is open-source, under the permissive Apache license.（docker documents） docker-registry是一个无状态的、可高度伸缩的服务器端应用程序，可以存储并允许您分发docker 镜像。docker-registry是开源的，是Apache许可证所允许的。 使用互联网上的的registry会受到网络因素的跟大影响，在pull 和push 时速度会不尽人意，在生产环境中并行启动的容器不会只有一两个会是几十上百个，而且并不能保证docker host 本地拥有所需要的所有镜像，所以通过互联网去下载就无法做到快速启动了很明显违背了容器轻量快速部署的初衷，此时就要自己在本地搭建私有registry。如果运维的系统环境托管在云服务上例如阿里云，那我们就去使用阿里的registry服务，也就是说将其建在生产环境的服务器的局域网中以达到更快的目的。 在Docker Hub中有registry镜像，pull下来即可使用，用法在上一篇博客中已经说到 docker-registry安装还有一种简单的方法就是Docker 提供了一个docker-distribution程序包 我们直接yum安装即可查看其安装生成的文件config.yml 是配置文件，registry是主程序，启动服务是docker-distribution.services, 数据存储在/var/lib/registry 在config.yml中可以修改缓存、存储路径、监听端口等，如果作为专门的rigistry应该把端口改成80或者https的443 1systemctl start docker-distribution //启动服务 然后就可以push镜像了 在另外一台主机上向刚搭建好的registry推送镜像推送之前还应该说一下docker镜像的命名规则 The Docker Registry is a component of Docker’s ecosystem. A registry is a storage and content delivery system, holding named Docker images, available in different tagged versions. For example, the image distribution/registry, with tags 2.0 and latest. Users interact with a registry by using docker push and pull commands such as docker pull myregistry.com/stevvooe/batman:voice.Docker Hub is an instance of a Docker Registry. Docker仓库是Docker生态系统的一部分。registry是一个存储和交付系统，支持命名镜像，存在不同的标记版本。例如一个镜像 distribution/registry 拥有2.0 和latest标记。用户和registry交互使用docker push 和docker pull命令例如:docker pull myregistry.com/stevvooe/batman:voice.Docker Hub是docker registry的一个实例。 也就是说用仓库名加标签来唯一标识一个镜像，只不过平常我们使用docker pull centos 时，docker.io为默认域名，latest为默认标签即docker pull docker.io/library/centos:latest 所以在我们docke push 镜像时，同样也要遵守命名规则 我们使用docker tag 进行打标 1docker tag hadoop web1:5000/hadoop:1.0 这里使用顶层仓库 123root@ubuntu16:~# docker push web1:5000/hadoop:1.0The push refers to a repository [web1:5000/hadoop]Get https://web1:5000/v1/_ping: http: server gave HTTP response to HTTPS client 报错为 http服务器响应https客户端，docker push 默认基于https协议工作，服务器端支持http ，二者不兼容。 我们搭建的是内网的仓库使用http协议就可以，修改客户端的docker daemon 1234vim /etc/docker/daemon.json&#123; &quot;insecure-registries&quot; : [&quot;web1:5000&quot;]&#125;systemctl restart docker 再去docker push 就可以了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071[root@Web2 registry]# tree /var/lib/registry//var/lib/registry/└── docker └── registry └── v2 ├── blobs │ └── sha256 │ ├── 09 │ │ └── 09d6e0703b59972f3832b563f62afeb0a4d952d79724c933543b4ecd389ac7c3 │ │ └── data │ ├── 53 │ │ └── 5301edc7ec17551bb197f15b3e9708231924392df6d403ac22cc897da75c6c5b │ │ └── data │ ├── 7c │ │ └── 7cab4876127f1e8ad7460cc656f61e7203cf8a04cebb5585c1e29f1c097266e9 │ │ └── data │ ├── 89 │ │ └── 8916107b7faec7a28f9bfb0d59579a51b8b9f80835b0ed134f5f511deae095be │ │ └── data │ ├── 95 │ │ └── 95acc0e10968e9babf3a942a085279db4269728c4c77f8f3a7d5e208108908c6 │ │ └── data │ ├── 96 │ │ └── 967a799109e4d74670438c51aba1b270c0f72caca675342acc955512f11e7459 │ │ └── data │ ├── a1 │ │ └── a185367e7bddc7bb3f22e43f388c0e9aefb2e6b679d2cbed1a3c7ff1f584dbf1 │ │ └── data │ ├── a4 │ │ └── a4dd3fbaa1db732a34a7ecf2e1f40a095aab3dab94109fd7c628c8966071944e │ │ └── data │ └── f4 │ └── f4236122778c0399bad22e265f9c017b5eb6aaead18ea21a21f5c0d9c97e907f │ └── data └── repositories └── hadoop ├── _layers │ └── sha256 │ ├── 09d6e0703b59972f3832b563f62afeb0a4d952d79724c933543b4ecd389ac7c3 │ │ └── link │ ├── 5301edc7ec17551bb197f15b3e9708231924392df6d403ac22cc897da75c6c5b │ │ └── link │ ├── 7cab4876127f1e8ad7460cc656f61e7203cf8a04cebb5585c1e29f1c097266e9 │ │ └── link │ ├── 8916107b7faec7a28f9bfb0d59579a51b8b9f80835b0ed134f5f511deae095be │ │ └── link │ ├── 95acc0e10968e9babf3a942a085279db4269728c4c77f8f3a7d5e208108908c6 │ │ └── link │ ├── 967a799109e4d74670438c51aba1b270c0f72caca675342acc955512f11e7459 │ │ └── link │ ├── a4dd3fbaa1db732a34a7ecf2e1f40a095aab3dab94109fd7c628c8966071944e │ │ └── link │ └── f4236122778c0399bad22e265f9c017b5eb6aaead18ea21a21f5c0d9c97e907f │ └── link ├── _manifests │ ├── revisions │ │ └── sha256 │ │ └── a185367e7bddc7bb3f22e43f388c0e9aefb2e6b679d2cbed1a3c7ff1f584dbf1 │ │ └── link │ └── tags │ └── 1.0 │ ├── current │ │ └── link │ └── index │ └── sha256 │ └── a185367e7bddc7bb3f22e43f388c0e9aefb2e6b679d2cbed1a3c7ff1f584dbf1 │ └── link └── _uploads46 directories, 20 files[root@Web2 registry]# 使用tree 命令完整的看到了/var/lib/registry/ 下的目录结构，hadoop镜像已经存在，镜像的每一层都是单独推送单独存放。再找一台服务器 执行docker pull 命令， 同样需要修改daemon.json中的内容，使用http协议。 docker-registry搭建完成。 上一篇博客感觉很粗糙，做的很仓促，本篇博客再重新梳理一下。]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[上传镜像至docker Hub，以及搭建本地私有仓库]]></title>
    <url>%2F2019%2F01%2F08%2F%E4%B8%8A%E4%BC%A0%E9%95%9C%E5%83%8F%E8%87%B3docker-Hub%EF%BC%8C%E4%BB%A5%E5%8F%8A%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[仓库（Repository）是集中存放镜像的地方，分为公共仓库和私有仓库注册服务器（Registry）是存放仓库的具体服务器，一个注册服务器上可以有多个仓库，每个仓库下面有多个镜像 首先要说的是docker Hub 公共镜像市场本地执行docker iogin 登陆 官方给出的命令 1docker pull 注册仓库/仓库名 这里需要将要上传的镜像改名，在名称前加上自己dockerHub的ID 速度很慢，需要配置镜像加速器，我配置的是阿里的配置镜像加速器 里面会有自己专用的加速连接 1234567891011mkdir -p /etc/dockervim daemon.json&#123; &quot;registry-mirrors&quot;: [&quot;your accelerate address&quot;]&#125; systemctl daemon-reload systemctl restart docker 再次上传就很快了 来到docker hub就可以看到了 可以通过官方提供的registry 镜像来搭建本地私有仓库环境 1docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry 可以看到容器已经启动了，映射主机5000端口，容器的/tmp/registry 挂载到主机/opt/data/registry目录，地址为172.17.0.2:5000docker tag 将要上传的镜像进行标记（docker tag Image[:tag] [Registryhost/] [Username/] Name [:Tag]） 1docker tag centos 172.17.0.2:5000/test 配置对仓库进行的安全性检查 在/etc/docker/daemon.json1&#123;&quot;insecure-registries&quot;:[&quot;172.17.0.2:5000&quot;]&#125; 123systemctl restart dockerdocker restart e46 重启registry 容器netstat -ntl 查看5000端口是否开放 1docker push 172.17.0.2：5000/test 1curl -XGET http://172.17.0.2:5000/v2/_catalog 可以看到镜像存在 删除本地镜像 1docker pull 172.17.0.2:500/test 可以看到镜像被拉下来了]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPv6（RIP、OSPF、EIGRP、DHCP、双栈、隧道）]]></title>
    <url>%2F2019%2F01%2F07%2FIPv6%EF%BC%88RIP%E3%80%81OSPF%E3%80%81EIGRP%E3%80%81DHCP%E3%80%81%E5%8F%8C%E6%A0%88%E3%80%81%E9%9A%A7%E9%81%93%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本篇博客介绍了Ipv6 的各种基本配置，也是本学期本门课的一个总结，使用Cisco Packet Tracer7.0 和GNS3 0.8 模拟器进行的以下实验 ，路由器选型为cisco 2911，Gns3中是c2691。 实验一 IPv6 IP地址配置方法（2911） 设备 接口 IP地址 &emsp;Router0&emsp; &emsp;g0/0 &emsp; &emsp;&emsp;2001:0db8:cafe:A001::2/64&emsp;&emsp; &emsp; &emsp;g0/1 &emsp;&emsp;2001:0db8:cafe:A002::2/64 &emsp; &emsp;g0/2 &emsp;&emsp;2001:0db8:cafe:0002::1/64 &emsp;Router1 &emsp;g0/0 &emsp;&emsp;2001:0db8:cafe:A001::1/64 &nbsp; &emsp;g0/1 &emsp;&emsp;2001:0db8:cafe:A003::1/64 &nbsp; &emsp;g0/2 &emsp;&emsp;2001:0db8:cafe:0001::1/64 &emsp;Router2 &emsp;g0/0 &emsp;&emsp;2001:0db8:cafe:A003::2/64 &nbsp; &emsp;g0/1 &emsp;&emsp;2001:0db8:cafe:A002::1/64 &nbsp; &emsp;g0/2 &emsp;&emsp;2001:0db8:feed:0001::1/64 &emsp;Router3 &emsp;g0/0 &emsp;&emsp;2001:0db8:feed:0001::2/64 &nbsp; &emsp;g0/1 &emsp;&emsp;2001:0db8:face:c0de::1/64 &emsp;PC 0 &nbsp; &emsp;&emsp;2001:0db8:cafe:0001::2/64 &emsp;PC 1 &nbsp; &emsp;&emsp;2001:0db8:face:c0de::2/64 &emsp;PC2 &nbsp; &emsp;&emsp;2001:0db8:cafe:0002::2/64 123456789101112131415161718192021222324252627Route1Router&gt;enableRouter#config terminalRouter(config)#ipv6 unicast-routing // 开启 IPV6流量转发Router(config)#int g0/0Router(config)#no shutdownRouter(config-if)#ipv6 add 2001:0db8:cafe:A001::1/64 //前64位为网络地址；后64位为主机位Router#show ipv6 interface brief使用EUI-64格式配置静态地址：Router(config)#int g0/1Router(config)#no shutdownRouter(config-if)#ipv6 address 2001:0db8:cafe:A003::1/64 euRouter(config-if)#ipv6 address 2001:0db8:cafe:A003::1/64 eui-64仅启用接口IPv6功能Router#conf tRouter(config)#int g0/2Router(config)#no shutdownRouter(config-if)#ipvRouter(config-if)#ipv6 enable //会自动分配Ipv6地址配置无编号地址Router(config)#interface f0/3/0Router(config)#no shutdownRouter(config-if)#ipv6 unnumbered g0/0 // 结果显示为接口f0/3/0借用g0/0的地址 实验二 静态路由配置 1. 直连静态路由12r1(config)#ipv6 route 2022:2:2:22::/64 e1/1到达目标网络2022:2:2:22::/64 的数据包从接口e1/1发出去 2.递归静态路由12r1(config)#ipv6 route 2022:2:2:22::/64 2012:1:1:11::2 到达目标网络2022:2:2:22::/64 的数据包发给下一跳地址2012:1:1:11::2 3.完全静态路由12r1(config)#ipv6 route 2022:2:2:22::/64 f0/0 2012:1:1:11::2 到达目标网络2022:2:2:22::/64 的数据包从接口F0/0发出去，并且交给下一跳地址2012:1:1:11::2 1234567891011配置递归路由(pc0 ping pc1)pc0至pc1Router1(config)#ipv6 unicast-routingRouter1(config)#ipv6 route 2001:0db8:face:c0de::/64(pc1网段) 2001:0db8:cafe:A003::2(Route2g0/0)Router2(config)#ipv6 unicast-routingRouter2(config)#ipv6 route 2001:0db8:face:c0de::/64(pc1网段) 2001:0db8:feed:0001::2(Route3g0/0)pc1 至PC0Router3(config)#ipv6 unicast-routingRouter3(config)#ipv6 route 2001:0db8:cafe:1::/64(pc0网段) 2001:0db8:feed:0001::1(Route2g0/2)Router3(config)#ipv6 unicast-routingRouter(config)#ipv6 route 2001:0db8:cafe:1::/64(pc0网段) 2001:0db8:cafe:A003::1(Route1g0/1)** PC0 ping PC1 实验三 IPv6 RIP (RIPng)基础实验 以Route2为例12345678910111213Router2&gt;enRouter2#conf tRouter1(config)#ipv6 unicast-routing // 开启IPv6路由转发Router2(config)#ipv6 router rip test //启动IPv6 RIPng进程，RIP进程名字为testRouter2(config-rtr)#int g0/0Router2(config-if)#no shutdownRouter2(config-if)#ipv6 rip test enableRouter2(config-if)#int g0/1Router2(config-if)#no shutdownRouter2(config-if)#ipv6 rip test enableRouter2(config-if)#int g0/2Router2(config-if)#no shutdownRouter2(config-if)#ipv rip test enable 所有路由器的所有接口都要进行配置! 下面查看Route2的RIP数据库 1234567891011121314151617181920Router2#show ipv6 rip database //查看IPv6数据库RIP process &quot;test&quot; local RIB2001:DB8:CAFE:1::/64, metric 2, installed // 路由条目装入路由表GigabitEthernet0/0/FE80::2E0:F7FF:FE48:CB02, expires in 151 sec2001:DB8:CAFE:2::/64, metric 2, installedGigabitEthernet0/1/FE80::2E0:8FFF:FE67:C502, expires in 161 sec2001:DB8:CAFE:A001::/64, metric 2, installedGigabitEthernet0/0/FE80::2E0:F7FF:FE48:CB02, expires in 151 sec2001:DB8:CAFE:A001::/64, metric 2, installedGigabitEthernet0/0/FE80::2E0:F7FF:FE48:CB02, expires in 151 sec2, installedGigabitEthernet0/1/FE80::2E0:8FFF:FE67:C502, expires in 161 sec2001:DB8:CAFE:A002::/64, metric 2GigabitEthernet0/1/FE80::2E0:8FFF:FE67:C502, expires in 161 sec2001:DB8:CAFE:A003::/64, metric 2GigabitEthernet0/0/FE80::2E0:F7FF:FE48:CB02, expires in 151 sec2001:DB8:FACE:C0DE::/64, metric 2, installedGigabitEthernet0/2/FE80::2D0:BAFF:FE71:9201, expires in 166 sec2001:DB8:FEED:1::/64, metric 2GigabitEthernet0/2/FE80::2D0:BAFF:FE71:9201, expires in 166 secRouter2# 在Pc0上进行检测 实验四 OSPFv3基础实验 1234567891011121314151617181920212223242526272829303132以Route1为例Router1&gt;enRouter1#conf tRouter1(config)#ipv6 unicast-routing // 开启Ipv6路由转发Router1(config)#ipv6 router ospf 2 // 启动OSPFv3进程%OSPFv3-4-NORTRID: OSPFv3 process 2 could not pick a router-id,please configure manually //要求手工指定router-idRouter1(config-rtr)#router-id 1.1.1.1 //给OSPF路由器指定身份，每个路由器的route-id都是唯一的Router1(config-rtr)#int g0/0Router1(config-if)#no shutdownRouter1(config-if)#ipv6 ospf 2 area 0Router1(config-if)#int g0/1Router1(config-if)#no shutdownRouter1(config-if)#ipv6 ospf 2 area 0Router1(config-if)#int g0/2Router1(config-if)#no shutdownRouter1(config-if)#ipv6 ospf 2 area 0在Route 0 路由器Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routingRouter(config)#ipv6 router ospf 2%OSPFv3-4-NORTRID: OSPFv3 process 2 could not pick a router-id,please configure manuallyRouter(config-rtr)#router-id 4.4.4.4Router(config-rtr)#int g0/0Router(config-if)#no shutdownRouter(config-if)#ipv6 ospf 2 area 0Router(config-if)#int g0/1Router(config-if)#no shutdownRouter(config-if)#ipv6 ospf 2 area 0Router(config-if)#int g0/2Router(config-if)#no shutdownRouter(config-if)#ipv6 ospf 2 area 0 Route2，Route3同理 实验五 IPv6 EIGRP实验 1234567891011121314151617181920212223242526272829303132333435363738394041R1 // R2 同理，此处不再进行配置演示R1#conf t // R1初始配置R1(config)#ipv6 unicast-routingR1(config)#int g0/0R1(config-if)#no shutdownR1(config-if)#ipv6 add 2012:1:1:11::1/64R1(config-if)#exitR1(config)#int loopback 1R1(config-if)#no shutdownR1(config-if)#ipv6 add 3001:1:1:11::1/64R1(config-if)#exitR1(config)#int loopback 2R1(config-if)#no shutdownR1(config-if)#ipv6 add 3002:1:1:11::1/64R1(config-if)#exitR1(config)#int loopback 3R1(config-if)#no shR1(config-if)#ipv6 add 3003:1:1:11::1/64R1#show ipv6 interface briFastEthernet0/0 [up/up] FE80::C204:8FF:FEB8:0 2012:1:1:11::1FastEthernet0/1 [administratively down/down] unassignedLoopback1 [up/up] FE80::C204:8FF:FEB8:0 3001:1:1:11::1Loopback2 [up/up] FE80::C204:8FF:FEB8:0 3002:1:1:11::1Loopback3 [up/up] FE80::C204:8FF:FEB8:0 3003:1:1:11::1R1(config)#ipv6 router eigrp 10 // 在R1上启动EIGRP v6进程R1(config-rtr)#no shutdown //EIGRP v6进程默认是shutdown的，必须手工开启R1(config-rtr)#eigrp router-id 1.1.1.1R1(config)#int g0/0 //将 R1上的接口放进EIGRP v6进程R1(config-if)#ipv6 eigrp 10 R1(config-if)#exitR1(config)#int loopback 1R1(config-if)#ipv6 eigrp 10 重分布IPv6网段 将R1上的剩余网段重分布进EIGRP v6 123456789101112131415161718192021222324r1(config)#route-map con permit 10 //在R1上配置重分布剩余网段进EIGRP v6r1(config-route-map)#match interface loopback 2r1(config-route-map)#exitr1(config)#route-map con permit 20 r1(config-route-map)#match interface loopback 3 r1(config)#ipv6 router eigrp 10r1(config-rtr)#redistribute connected route-map conr1(config-rtr)#exit在R2上查看重分布进EIGRP v6的剩余网段r2#sh ipv6 route eigrp IPv6 Routing Table - 9 entriesCodes: C - Connected, L - Local, S - Static, R - RIP, B - BGP U - Per-user Static route I1 - ISIS L1, I2 - ISIS L2, IA - ISIS interarea, IS - ISIS summary O - OSPF intra, OI - OSPF inter, OE1 - OSPF ext 1, OE2 - OSPF ext 2 ON1 - OSPF NSSA ext 1, ON2 - OSPF NSSA ext 2 D - EIGRP, EX - EIGRP externalD 3001:1:1:11::/64 [90/409600] via FE80::C200:9FF:FE54:0, FastEthernet0/0EX 3002:1:1:11::/64 [170/409600] via FE80::C200:9FF:FE54:0, FastEthernet0/0EX 3003:1:1:11::/64 [170/409600] via FE80::C200:9FF:FE54:0, FastEthernet0/0r2# 过滤IPv6路由 在R2上过滤掉IPv6路由，只留想要的网段，使用distribute-list过滤 1234567891011121314r2(config)#ipv6 prefix-list abc permit 3002:1:1:11::/64 //配置只留3002:1:1:11::/64网段r2(config)#ipv6 router eigrp 10r2(config-rtr)#distribute-list prefix-list abc in f0/0r2#sh ipv6 route eigrp IPv6 Routing Table - 7 entriesCodes: C - Connected, L - Local, S - Static, R - RIP, B - BGP U - Per-user Static route I1 - ISIS L1, I2 - ISIS L2, IA - ISIS interarea, IS - ISIS summary O - OSPF intra, OI - OSPF inter, OE1 - OSPF ext 1, OE2 - OSPF ext 2 ON1 - OSPF NSSA ext 1, ON2 - OSPF NSSA ext 2 D - EIGRP, EX - EIGRP externalEX 3002:1:1:11::/64 [170/409600] via FE80::C200:9FF:FE54:0, FastEthernet0/0r2# 实验七 IPv6地址SLAAC与有状态自动配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344451.配置无状态自动获得IP地址（SLAAC）R1Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routingRouter(config)#int g0/0Router(config-if)#ipv6 address 2023::2/64Router(config-if)#no shutdownR2Router&gt;enRouter#conf tRouter(config)#int g0/0Router(config-if)#ipv6 address autoconfigRouter(config-if)#no shRouter#show ipv6 int g0/0GigabitEthernet0/0 is up, line protocol is upIPv6 is enabled, link-local address is FE80::230:F2FF:FEC9:1D01No Virtual link-local address(es):Global unicast address(es):2023::230:F2FF:FEC9:1D01, subnet is 2023::/64Joined group address(es):FF02::1FF02::1:FFC9:1D01MTU is 1500 bytesICMP error messages limited to one every 100 millisecondsICMP redirects are enabledICMP unreachables are sentND DAD is enabled, number of DAD attempts: 1ND reachable time is 30000 millisecondsRouter#2.调整NDRouter1：interface g0/0ipv6 address 2023::2/64no shutdownipv6 nd ra-interval 5 //每5s通告一次RAipv6 nd ra-lifetime 1000 //RA的lifetimeipv6 nd prefix 2023::/64 5000 4000 //修改valid time和preferred time3.不希望SLAAC抑制RA消息：ipv6 nd ra suppress //对IOS版本有要求 实验八.DHCPv6分配 123456789101112131415161718192021222324252627282930313233343536373839401.无状态自动配置注：此时地址是EUI/64获取的，而其他信息是由DHCP获取的Router1:Ipv6 unicast-routingipv6 dhcp pool cafe-1dns-server 2022::2domain-name www.heuet.edu.cninterface G0/0ipv6 address 2023::2/64ipv6 dhcp server café-1ipv6 nd other-config-flag //O置位Router2:interface g0/0ipv6 address autoconfig2.有状态自动配置Router1:Ipv6 unicast-routeipv6 dhcp pool cafe-1dns-server 2022::2domain-name www.heuet.edu.cnaddress prefix 2023:2323::/64interface g0/0ipv6 address 2023::2/64ipv6 dhcp server cafe-1ipv6 nd other-config-flagipv6 nd managed-config-flag //M置位Router2:interface g0/0ipv6 enable //让接口获得link-local地址作为DHCP源来发送DHCP报文ipv6 address dhcp查看：Router1#sh ipv6 dhcp poolDHCPv6 pool: cafe-1DNS server: 2022::2Domain name: www.heuet.edu.cnActive clients: 1 //一个client 实验九 DHCPv6前缀代表 1234567891011121314151617181920DHCP SERVERRouter&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#ipv6 dhcp pool dhcpv6 //定义DHCP服务的名字Router(config-dhcpv6)#prefix-delegation pool dhcpv6-pool lifetime 1800 600 //创建DHCPV6-pool的前缀代//表地址池，并定义有效期Router(config-dhcpv6)#dns-server 2001:db8:3000:3000::42Router(config-dhcpv6)#domain-name www.heuet.edu.cnRouter(config-dhcpv6)#exit lRouter(config)#int g0/0Router(config-if)#ipv6 dhcp server dhcpv6 //在接口上启动DHCP服务对象Router(config-if)#exit Router(config)#ipv6 local pool dhcpv6-pool 2001:db8:1200::/40 48 //定义一个前缀长度为40的本地前缀代表//地址池,并且定义分配给DHCPv6-PD Client的前缀长度是48位Router(config)#int g0/0Router(config-if)#ipv6 add 2010:AB8::1/64Router(config-if)#ipv6 enable Router(config-if)#no shutdown 12345678910111213141516171819DHCP ClientRouter&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#int g0/0Router(config-if)#no shRouter(config-if)#ipv6 add autoconfig //无状态自动配置IPv6地址Router(config-if)#ipv6 enable Router(config-if)#ipv6 dhcp client pd prefix-from-pr //在接口上启用PD，将PD命名为prefix-from-prRouter(config-if)#Router(config-if)#int g0/1Router(config-if)#no shRouter(config-if)#ipv6 address prefix-from-pr ::1:0:0:0:1/64 配置接口从名字prefix-from-pr那里取得前缀，然后附加上1:0:0:0:1，最后形成接口的地址是2001：DB8:1200:1::1/64Router(config-if)#int g0/2Router(config-if)#no shRouter(config-if)#ipv6 address prefix-from-pr ::1/64 //接口地址为2001：DB8:1200:::1/64Router(config-if)# 123456789Client1Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#Router(config)#int g0/0Router(config-if)#no shRouter(config-if)#ipv6 address autoconfig //启用无状态自动获得IP地址Router#show ipv6 interface brief 12345678Client2Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#int g0/0Router(config-if)#no shRouter(config-if)#ipv6 add autoconfig //启用无状态自动获得IP地址Router#show ipv6 inter bri 实验十 IPv6、IPv4双栈实验 12345678910111213141516171819202122232425262728293031323334353637383940R0Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#ipv6 router ospf 1Router(config-rtr)#router-id 10.1.1.1Router(config-rtr)#int g0/0Router(config-if)#no shRouter(config-if)#ip add 10.10.10.1 255.255.255.252Router(config-if)#duplex auto Router(config-if)#speed auto Router(config-if)#Router(config-if)#ipv6 add 2001:DB8:CAFE:A001::1/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#exit Router(config)#int g0/1Router(config-if)#no shRouter(config-if)#ip add 10.10.10.9 255.255.255.252Router(config-if)#duplex auto Router(config-if)#speed auRouter(config-if)#ipv6 address 2001:DB8:CAFE:A003::1/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#exit Router(config)#int g0/2Router(config-if)#no shRouter(config-if)#ip add 10.1.0.1 255.255.0.0Router(config-if)#duplex auto Router(config-if)#speed auto Router(config-if)#ipv6 add 2001:DB8:CAFE::1/64Router(config-if)#ipv6 address 2001:DB8:CAFE:1::1/64Router(config-if)#ipvRouter(config-if)#ipv6 osRouter(config-if)#ipv6 ospf 1 arRouter(config-if)#ipv6 ospf 1 area 0Router(config-if)#router ospf 2Router(config-router)#log-adjacency-changes Router(config-router)#network 10.1.0.0 0.0.255.255 area 0Router(config-router)#network 10.10.10.0 0.0.0.3 area 0Router(config-router)#network 10.10.10.8 0.0.0.3 area 0Router(config-router)# 12345678910111213141516171819202122232425262728293031323334R1Router&gt;enRouter#conf tRouter(config)#ipv unicast-routing Router(config)#ipv6 router ospf 1Router(config-rtr)#router-id 10.3.3.3Router(config-rtr)#log-adjacency-changes Router(config-rtr)#int g0/0Router(config-if)#no shRouter(config-if)#ip address 10.10.10.6 255.255.255.252Router(config-if)#duplex auRouter(config-if)#speed auRouter(config-if)#ipv6 address 2001:DB8:CAFE:A002::2/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#int g0/1Router(config-if)#no shRouter(config-if)#ip address 10.10.10.10 255.255.255.252Router(config-if)#duplex auto Router(config-if)#speed auto Router(config-if)#ipv6 address 2001:DB8:CAFE:A003::2/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#int g0/2Router(config-if)#no shRouter(config-if)#ip address 10.3.0.1 255.255.0.0Router(config-if)#duplex auto Router(config-if)#speed auto Router(config-if)#ipv6 address 2001:DB8:CAFE:3::1/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#router ospf 2Router(config-router)#log-adjacency-changesRouter(config-router)#network 10.10.10.8 0.0.0.3 area 0Router(config-router)#network 10.10.10.4 0.0.0.3 area 0Router(config-router)#network 10.3.0.0 0.0.255.255 area 0Router(config-router)# 1234567891011121314151617181920212223242526272829303132R2Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#ipv6 router ospf 1Router(config-rtr)#router-id 10.2.2.2Router(config-rtr)#int g0/0Router(config-if)#no shRouter(config-if)#ip address 10.10.10.2 255.255.255.252Router(config-if)#duplex autoRouter(config-if)#speed autoRouter(config-if)#ipv6 address 2001:DB8:CAFE:A001::2/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#interface g0/1Router(config-if)#no shRouter(config-if)#ip address 10.10.10.5 255.255.255.252Router(config-if)#duplex autoRouter(config-if)#speed autoRouter(config-if)#ipv6 address 2001:DB8:CAFE:A002::1/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#int g0/2Router(config-if)#no shRouter(config-if)#ip address 10.2.0.1 255.255.0.0Router(config-if)#duplex auRouter(config-if)#speed autoRouter(config-if)#ipv6 address 2001:DB8:CAFE:2::1/64Router(config-if)#ipv6 ospf 1 area 0Router(config-if)#router ospf 2Router(config-router)#log-adjacency-changesRouter(config-router)#network 10.10.10.0 0.0.0.3 area 0Router(config-router)#network 10.10.10.4 0.0.0.3 area 0Router(config-router)#network 10.2.0.0 0.0.255.255 area 0 实验十一 手工隧道 123456789101112131415161718R0Router&gt;enRouter#conf tRouter(config)#ipv6 UNicast-routing Router(config)#int g0/0Router(config-if)#no shRouter(config-if)#ipv6 address 2001:DB8:CAFE:1::1/64Router(config-if)#int g0/1Router(config-if)#no shRouter(config-if)#ip add 192.168.1.1 255.255.255.0Router(config-if)#int t0Router(config-if)#ipv6 address 2001:DB8:CAFF:1::1/64Router(config-if)#ipv6 enRouter(config-if)#tunnel source g0/1Router(config-if)#tunnel destination 192.168.1.2Router(config-if)#tunnel mode ipv6ipRouter(config-if)#ipv6 route 2001:DB8:ACE:2::/64 2001:DB8:CAFF:1::2Router(config)# 1234567891011121314151617R1Router&gt;enRouter#conf tRouter(config)#ipv6 unicast-routing Router(config)#int g0/0Router(config-if)#ip address 192.168.1.2 255.255.255.0Router(config-if)#no shRouter(config-if)#int g0/1Router(config-if)#ipv6 address 2001:DB8:ACE:2::1/64Router(config-if)#no shRouter(config-if)#int t0Router(config-if)#ipv6 address 2001:DB8:CAFF:1::2/64Router(config-if)#ipv6 enRouter(config-if)#tunnel source g0/0Router(config-if)#tunnel destination 192.168.1.1Router(config-if)#tunnel mode ipv6ip Router(config-if)#i 实验十二 6to4隧道的配置 需要特别说明的是由于6to4隧道原理的特殊性，隧道端口的IPv4地址与IPv6网络的Ipv6地址有关联，所以分配IPv6网络的IP地址应该注意符合6to4隧道的编码要求。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970R1R1#conf tR1(config)#ipv6 unicast-routing //启用路由器的Ipv6转发功能R1(config)#int loopback 0R1(config-if)#ipv add 2002:0a01:0101:1::1/64R1(config-if)#int f0/1R1(config-if)#no shR1(config-if)#ip add 10.1.1.1 255.255.255.0R1(config)#router ospf 1 //配置IPv4网络的动态路由协议OSPFR1(config-router)#network 10.1.1.0 0.0.0.255 area 0R1(config)#int t0 创建隧道，并配置隧道的IPv6地址及隧道模式R1(config-if)#no shR1(config-if)#ipv enR1(config-if)#ipv6 address 2002:A01:101::1/64R1(config-if)#tunnel source f0/1R1(config-if)#tunnel mode ipv6ip 6to4R1(config)#ipv6 route 2002::/16 Tunnel0 //配置IPv6路由R2R2#conf tR2(config)#ipv6 unicast-routing //启用路由器的Ipv6转发功能R2(config)#int loopback 0R2(config-if)#ipv6 add 2002:0a03:0303:1::1/64R2(config-if)#int f0/1R2(config-if)#ip add 10.3.3.3 255.255.255.0R2(config-if)#no shR2(config)#router ospf 1 //配置IPv4网络的动态路由协议OSPFR2(config-router)#network 10.3.3.0 0.0.0.255 area 0R2(config)#int t0 创建隧道，并配置隧道的IPv6地址及隧道模式R2(config-if)#no shR2(config-if)#ipv enR2(config-if)#ipv6 address 2002:A03:303::1/64R2(config-if)# tunnel source f0/1R2(config-if)# tunnel mode ipv6ip 6to4R2(config)#ipv6 route 2002::/16 Tunnel0 //配置IPv6路由R3R3#conf tR3(config)#ipv6 unicast-routing //启用路由器的Ipv6转发功能R3(config)#int loopback 0R3(config-if)#ipv add 2002:0a02:0202:1::1/64R3(config-if)#int f0/1R3(config-if)#no shR3(config-if)#ip add 10.2.2.2 255.255.255.0R3(config)#router ospf 1 //配置IPv4网络的动态路由协议OSPFR3(config-router)#network 10.2.2.0 0.0.0.255 area 0R3(config)#int t0 创建隧道，并配置隧道的IPv6地址及隧道模式R3(config-if)#no shR3(config-if)#ipv6 address 2002:A02:202::1/64R3(config-if)#ipv enR3(config-if)# tunnel source f0/1R3(config-if)# tunnel mode ipv6ip 6to4R3(config)#ipv6 route 2002::/16 Tunnel0 //配置IPv6路由R4R4#conf tR4(config)#ipv un //启用路由器的Ipv6转发功能R4(config)#int f0/0R4(config-if)#no shR4(config-if)#ip add 10.1.1.10 255.255.255.0R4(config-if)#int f0/1R4(config-if)#ip add 10.3.3.10 255.255.255.0R4(config-if)#no shR4(config-if)#int f1/0R4(config-if)#no shR4(config-if)#ip add 10.2.2.10 255.255.255.0R4(config)#router ospf 1 //配置IPv4网络的动态路由协议OSPFR4(config-router)#network 10.1.1.0 0.0.0.255 area 0R4(config-router)#network 10.2.2.0 0.0.0.255 area 0R4(config-router)#network 10.3.3.0 0.0.0.255 area 0 实验十三 ISATAP隧道 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475R1R1#CONF TR1(config)#int loopback 0R1(config-if)#ipv add 2002:303:301::1/64R1(config-if)#int f0/0R1(config-if)#no shR1(config-if)#ip add 3.3.30.1 255.255.255.0R1(config-if)#exitR1(config)#ip route 2.2.20.0 255.255.255.0 3.3.30.2R1(config)#int t0R1(config-if)#no shR1(config-if)#ipv enR1(config-if)#tunnel source f0/0R1(config-if)# tunnel mode ipv6ip isatapR1(config-if)#exiR1(config)#ipv unicast-routingR1(config)#ipv6 router ospf 1R1(config-rtr)#router-id 1.1.1.1R1(config-rtr)#int t0 //创建ISATAP隧道，并配置隧道相关参数R1(config-if)#ipv6 ospf network point-to-multipoint non-broadcastR1(config-if)#ipv6 ospf neighbor FE80::5EFE:202:1401 //手工指定邻居使用本地链路地址R1(config-if)#ipv6 ospf 1 area 0R1(config-if)#exitR1(config)#int lo 0R1(config-if)#ipv6 ospf 1 area 0R2R2#conf tR2(config)#int f0/0R2(config-if)#no shR2(config-if)# ip address 3.3.30.2 255.255.255.0R2(config-if)#int f0/1R2(config-if)#no shR2(config-if)# ip address 2.2.20.2 255.255.255.0R3R3#conf tR3(config)#ipv unicast-routingR3(config)#int f0/0R3(config-if)#no shR3(config-if)#ip add 2.2.20.1 255.255.255.0R3(config-if)#int f0/1R3(config-if)#no shR3(config-if)#ipv6 add 2002:202:201::1/64R3(config-if)#exiR3(config)#ip route 3.3.30.0 255.255.255.0 2.2.20.2R3(config)#int t0R3(config-if)#no shR3(config-if)#ipv enR3(config-if)#tunnel source f0/0R3(config-if)#tunnel mode ipv6ip isatapR3(config-if)#exiR3(config)#ipv6 router ospf 1R3(config-rtr)# router-id 3.3.3.3R3(config-rtr)#int t0 //创建ISATAP隧道，并配置隧道相关参数R3(config-if)#ipv6 ospf network point-to-multipoint non-broadcast //为简化OSPF的运行，//避免DR和BDR的选举，在隧道接口上把网络类型改为点到多点广播R3(config-if)#ipv6 ospf neighbor FE80::5EFE:303:1E01 //手工指定邻居使用本地链路地址R3(config-if)# ipv6 ospf 1 area 0R3(config-if)#int f0/1R3(config-if)#ipv6 ospf 1 area 0R3(config-if)#R4R4#conf tR4(config)#ipv unR4(config)#int f0/0R4(config-if)#no shR4(config-if)#ipv6 address 2002:202:201::2/64R4(config-if)#exitR4(config)#ipv6 router ospf 1R4(config-rtr)#router-id 4.4.4.4R4(config-rtr)#int f0/0R4(config-if)#ipv6 ospf 1 area 0R4(config-if)# 实验十四 ISATAP隧道（二） C1 桥接本机网卡 ，路由器为C7200 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647R1R1#conf tR1(config)#int f0/0R1(config-if)#ip address 192.168.10.10 255.255.255.0R1(config-if)#no shR1(config-if)#exiR1(config)#int s2/0R1(config-if)#clock rate 64000R1(config-if)#ip add 131.107.0.1 255.255.255.0R1(config-if)#no shR2R2#conf tR2(config)#ipv unR2(config)#int s2/0R2(config-if)#ip address 131.107.0.2 255.255.255.0R2(config-if)#no shR2(config-if)#exiR2(config)#int s2/1R2(config-if)#clock rate 64000R2(config-if)#ipv6 address 2001:2::1/64R2(config-if)#no shR2(config-if)#exiR2(config)#ip route 192.168.10.0 255.255.255.0 131.107.0.1R2(config)#ipv6 route 2001:1::/64 2001:2::2R2(config)#int t0R2(config-if)#ipv6 address 2001:3::/64 eui-64R2(config-if)#no ipv6 nd suppress-raR2(config-if)#tunnel source 131.107.0.2R2(config-if)#tunnel mode ipv6ip isatapR2(config-if)#no shR3R3#conf tR3(config)#ipv unR3(config)#int s2/1R3(config-if)#ipv6 address 2001:2::2/64R3(config-if)#no shR3(config-if)#exiR3(config)#int f0/0R3(config-if)#ipv6 address 2001:1::1/64R3(config-if)#no shR3(config-if)#exiR3(config)#ipv6 route 2001:3::/64 2001:2::1 以管理员身份运行cmd。执行以下命令： 1netsh interface ipv6 isatap set route 131.107.0.2 （Win10操作系统要先运行：netsh interface isatap set state enable命令）执行以下命令查看结果： 1234567891011121314151617181920212223242526C:\WINDOWS\system32&gt; ipconfig /all 无线局域网适配器 本地连接* 2: 媒体状态 . . . . . . . . . . . . : 媒体已断开连接 连接特定的 DNS 后缀 . . . . . . . : 描述. . . . . . . . . . . . . . . : Microsoft Wi-Fi Direct Virtual Adapter #2 物理地址. . . . . . . . . . . . . : BC-A8-A6-EB-A1-CD DHCP 已启用 . . . . . . . . . . . : 是 自动配置已启用. . . . . . . . . . : 是 隧道适配器 isatap.&#123;331437F1-5F3E-436E-8E71-36228471287E&#125;: 连接特定的 DNS 后缀 . . . . . . . : 描述. . . . . . . . . . . . . . . : Microsoft ISATAP Adapter 物理地址. . . . . . . . . . . . . : 00-00-00-00-00-00-00-E0 DHCP 已启用 . . . . . . . . . . . : 否 自动配置已启用. . . . . . . . . . : 是 IPv6 地址 . . . . . . . . . . . . : 2001:3::5efe:192.168.10.20(首选) 本地链接 IPv6 地址. . . . . . . . : fe80::5efe:192.168.10.20%22(首选) 默认网关. . . . . . . . . . . . . : fe80::5efe:131.107.0.2%22 DNS 服务器 . . . . . . . . . . . : fec0:0:0:ffff::1%1 fec0:0:0:ffff::2%1 fec0:0:0:ffff::3%1 TCPIP 上的 NetBIOS . . . . . . . : 已禁用 执行ping命令测试是否能够互通。 123456789101112PS C:\WINDOWS\system32&gt; ping 2001:1::1 正在 Ping 2001:1::1 具有 32 字节的数据:来自 2001:1::1 的回复: 时间=74ms来自 2001:1::1 的回复: 时间=81ms来自 2001:1::1 的回复: 时间=99ms来自 2001:1::1 的回复: 时间=61ms 2001:1::1 的 Ping 统计信息: 数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，往返行程的估计时间(以毫秒为单位): 最短 = 61ms，最长 = 99ms，平均 = 78ms 特别说明：1、如果你的操作系统是win10，请下载win10关于IPv6的补丁.2、为了用ping命令测试是否互通，请暂时关闭计算机防火墙或者通过设置防火墙规则允许ping命令数据包通过。]]></content>
      <tags>
        <tag>IPv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-端口映射与容器互联]]></title>
    <url>%2F2018%2F12%2F17%2Fdocker-%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E4%B8%8E%E5%AE%B9%E5%99%A8%E4%BA%92%E8%81%94%2F</url>
    <content type="text"><![CDATA[端口映射 当容器中运行一些应用，可以通过-p ，-P 参数来指定端口映射使用-P时，Docker会随机映射一个49000~49900的端口到内部容器开放的端口如果一个镜像中没有可以对外提供的服务，使用-P参数基于该镜像启动容器后，不会有端口的映射 12例如：docker run -idt -P centos /bin/bash docker run -idt -P httpd /bin/bash 另外几种查看端口映射的方法 12docker port IDdocker inspect -f &#123;&#123;.NetworkSettings.Ports&#125;&#125; ID 使用-p(小写)可以指定要映射的端口使用HostPort : ContainPort将本地的5000映射到容器的5000，会默认绑定本地所有接口上的所有地址 可以多次使用-p参数绑定多个端口 12docker run -d -p 80:80 httpd docker run -d -p 80:80 -p 8080:8080 httpd 使用IP:HostPort:ContainPort格式指定映射使用一个特定地址 1docker run -d -p 127.0.0.1:80:80 httpd 使用IP::ContainerPort 映射到指定地址的任意端口 12345docker run -d -p 127.0.0.1::80 httpd还可以使用udp标记来指定udp端口docker run -d -p 127.0.0.1:80:80/udp httpd 容器互联 创建一个数据库容器 1docker run -idt --name db postgres 1docker run -idt -P --name web --link db:db httpd /bin/bash 使用–link 选项，参数格式为name:alias 即要连接的容器名称 : 这个连接的别名 再建立一个web2容器，同web的配置，查看环境变量，可以看到与db容器的连接，以DB_开头的环境变量都是提供web连接db的 进入到web容器中查看/etc/hosts .可以看到db容器的信息 在web容器中安装ping命令 12apt-get update 更新源apt-get install inetutils-ping]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-数据卷]]></title>
    <url>%2F2018%2F12%2F16%2Fdocker-%E6%95%B0%E6%8D%AE%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[前言 容器中管理数据主要有两种方式： 数据卷：容器内数据直接映射到本地主机环境 数据卷容器：使用特定容器维护数据卷 数据卷可以提供很多有用的特性： 数据卷可以在容器间共享和重用，容器间传递数据变得高效方便 对数据卷内数据的修改即刻生效，无论容器内操作还是本地操作 对数据卷的更新不会影响镜像，解耦了应用和数据 卷会一直存在，知道没有容器使用，可以安全卸载 在容器内创建一个数据卷 1docker run -d -P --name web -v /webapp training/webapp python app.py 使用training/webapp 创建一个名为web的容器，在后台运行，自动映射到主机端口，创建一个数据卷挂载到容器的 /webapp 下，并执行app.py文件 可以看到 /webapp 的时间戳发生了变化 挂载一个主机目录作为数据卷 1docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py 使用training/webapp 创建一个名为web的容器，在后台运行，自动映射到主机端口，加载主机的/src/webapp到容器的/opt/webapp 下，并执行app.py文件 挂载数据卷时，要使用绝对路径，如果目录不存在则会自动创建 可以在容器中看到在宿主机上新建的hello_world文件 挂载一个主机文件作为数据卷 1docker run --rm -it -v ~/.bash_history:/.bash_history centos /bin/bash 使用centos镜像创建一个容器，当容器为退出状态时自动删除，加载本机的.bash_history 到容器的.bash_history 中 如果直接挂载一个文件到容器，使用文件编辑工具（vim ,sed等等）时，可能造成文件inode变化，造成报错 加载到容器中的文件仍能使用，但是和本机的文件不同步了（具体问题我也没有找到） 数据卷容器数据卷容器也是一个容器，专门用来提供数据卷供其他容器挂载，使得多个容器间共享一些持续更新的数据 db1和db2 中都可以看到dbdata 创建的test文件 可以多次使用–volumes-from 参数来从多个容器挂载多个数据卷，还可以从其他已经挂载了容器卷的容器来挂载数据卷 1docker run -d --name db3 --volumes-from db1 training/postgres 使用–volumes-from 参数所挂载数据卷的容器自身并不需要保持在运行状态 删除了挂载的容器，数据卷并不会被自动删除挂载信息,数据卷信息会保存在/var/lib/docker/volumes下 利用数据卷容器迁移数据 可以利用数据卷容器对其中的数据卷备份、恢复，以实现数据的迁移 备份 1docker run --volumes-from dbdata -v $(pwd):/backup --name worker centos tar -cvf /backup/backup.tar /dbdata 使用centos 镜像创建 ，根据数据卷容器dbdata来挂载数据卷，将本地当前目录挂载到容器worker的/backup，并将/dbdata 归档为/backup下的backup.tar 恢复 1docker run --volumes-from dbdata -v $(pwd):/backup --name backup centos tar-xvf /backup/backup.tar 注意事项挂载宿主机已存在目录后，在容器内对其进行操作，报“Permission denied”。 可通过两种方式解决： 关闭selinux。 12临时关闭：setenforce 0永久关闭：修改/etc/sysconfig/selinux文件，将SELINUX的值设置为disabled。 以特权方式启动容器 12指定--privileged参数docker run -it --privileged=true -v /test:/soft centos /usr/bin/init]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 容器]]></title>
    <url>%2F2018%2F12%2F13%2Fdocker-%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;docker容器是docker的运行实例，在镜像文件上带有可写的文件层。docker容器是一个轻量级应用，能够随时创建和部署、启动、停止 1.使用docker creat 创建新的容器 1docker create -it centos 创建以个新的Centos容器 使用docker ps -a 查看容器信息 STATUS 为容器运行状态，UP为正常运行，Exited为停止，Created为尚未启动 &nbsp;&nbsp;&nbsp;&nbsp;creat 命令和后续的run命令支持的选项都十分复杂，主要包括几大类：与容器运行模式相关，与容器和环境配置相关，与容器资源限制和安全保护相关 2.使用docker start 启动容器 1docker start 10f 可以看到容器状态为UP 代表已经启动。 3. 使用 docker run 新建并启动容器 1docker run centos /bin/echo &quot;this is new centos &quot; 当利用docker run 来创建并启动容器时，docker在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从共有仓库下载 利用镜像创建一个容器，并启动该容器 分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器 从网桥的地址池配置一个ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被自动终止 &nbsp;&nbsp;&nbsp;&nbsp;使用ps命令，可以看到只运行了bash应用，并无其他进程,用户可以输入exit 命令来退出容器 &nbsp;&nbsp;&nbsp;&nbsp;对于所创建的bash容器，当使用exit命令退出后，容器就自动处于退出(Exited)状态，对于docker 容器来说， 当运行的应用退出后容器也就没有继续运行的必要了 &nbsp;&nbsp;&nbsp;&nbsp;有时执行docker run会出错，因为命令无法正常执行容器会退出，可以查看默认返回的错误码 常见的有以下几个 125 Docker daemon 执行出错，例如指定不支持的参数 126 指定命令无法执行 例如权限出错 127 容器内命令无法找到 4. 守护状态运行 使docker容器在后台以守护状态运行（Daemonized） 使用-d 参数 1234docker run -d centos /bin/bash -c &quot;while ture ; do echo hello world ; sleep 2;done&quot; docker ps ### 查看容器信息docker logs ### 获取容器输出信息docker stop ### 停止容器 5. 终止容器 &nbsp;&nbsp;&nbsp;&nbsp;docker stop 会终止一个运行中的容器，命令格式为 docker stop [-t | –time=[10]] [container] &nbsp;&nbsp;&nbsp;&nbsp;首先向容器发送SIGTERM 信号，等待一段超时时间后（默认10秒 ） 在发送信号来终止容器&nbsp;&nbsp;&nbsp;&nbsp;docker kill 会 直接发送 SIGKILL 信号来终止容器 &nbsp;当Docker容器中指定的应用终结时，容器也会自动终止 1docker ps -qa 查看所有容器的id &nbsp;&nbsp;&nbsp;&nbsp;处于终止状态的容器可以通过 docker start命令重新启动,docker restart 会将一个运行态容器先终止再重新启动 6.进入容器 &nbsp;&nbsp;&nbsp;&nbsp;在使用-d参数后，容器会进入后台，用户无法操作，如果需要进入可以使用官方的attach、exec，和第三方的nsenter 1234docker attach [--detach-keys[ = [ ] ] ] [--no-stdin] [--sig-proxy[=ture]] container --detach-keys[ = [ ] ] : 指定退出attach模式的快捷键，默认是ctrl+q 和ctrl+p--no-stdin=true|false ： 是否关闭从标准输入，默认是打开--sig-proxy=true|false ： 是否代理收到的系统信给应用进程，默认true 多个窗口同时使用attach模式连接到同一容器时，所有窗口都会同步显示 12345docker exec [-d|--detach] [--detach-keys[=[ ] ] ] [-i|--interactive] [--privileged] [-t|--tty] [-u|--user[=USER] container COMMAND [ARG..]-i ,--interactive=true|false : 打开标准输入接受用户输入命令，默认false --privileged-true|false ： 是否给执行命令以最高权限 ，默认false-t，--tty=true|false ; 分配伪终端，默认false-u ，--user=&quot; &quot; : 执行命令的用户或ID &nbsp;&nbsp;&nbsp;通过指定-it 参数来保持标准输入打开，并且分配一个为终端，推荐使用exec命令对容器进行操作 1docker nsenter 第三方工具 7.删除容器 1docker rm [-f|--force] [-l | --link] [-v|--volumes] container [container……] 使用该命令来删除处于终止或退出状态的容器 -f ，–force=false ：是否强制终止并删除一个运行中的容器 -l，–link=false ：删除容器的连接，但是保留容器 -v，–volumes=false ： 删除容器挂载的数据卷 8. 导入导出容器 用于容器的系统迁移 1docker export [-o|--output[=&quot; &quot; ] ] container 可以通过-o 来指定导出的tar文件名，也可以直接重定向实现 导出的文件可以使用docker import 命令导入变成镜像 1docker import [-c|--change[=[]]] [-m|--message[=MESSAGE]] file|URL|-[REPOSITORY[:TAG]] docker save ：将一个镜像导出为文件，再使用dockerload –input 命令将文件导入为一个镜像，会保存该镜像的的所有历史记录。比dockerexport命令导出的文件大，很好理解，因为会保存镜像的所有历史记录。 docker export ：将一个容器导出为文件，再使用docker import命令将容器导入成为一个新的镜像，但是相比docker save命令，容器文件会丢失所有元数据和历史记录，仅保存容器当时的状态，相当于虚拟机快照。]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-ce安装 与docker镜像（Centos7)]]></title>
    <url>%2F2018%2F12%2F12%2Fdocker-ce%E5%AE%89%E8%A3%85-%E4%B8%8Edocker%E9%95%9C%E5%83%8F%EF%BC%88Centos7%2F</url>
    <content type="text"><![CDATA[安装docker-ce（设置清华大学镜像站为镜像源) 在centos7 yum仓库 的extras仓库中自带了docker源,都是docker 1.13版本，不建议使用老版本docker.清华大学在镜像站中给docker做了镜像在此目录下找到docker的repo文件我们可以自己建一个docker镜像源仓库，首先要把该repo文件下载到/etc/yum.repos.d 中下载后打开docker-ce.repo文件，文件中指向的地址是docker官方站点，这个下载速度是很慢的，因此还要修改下载路径仍然选择清华大学镜像站，来到这个目录下，选择稳定版可以看到这里有最新版本18.06选择复制链接中的linux父目录https://mirrors.tuna.tsinghua.edu.cn/docker-ce/然后全局替换docker-ce.repo中的官方地址的linux的父目录用vim打开，在末行模式下进行替换可以看到替换成功yum repolist 显示所有仓库，可以看到存在docker-ce的程序包yum install docker-ce ，完成 启动docker 1systemctl start docker 设置开机自启动 1systemctl enable docker 很简单镜像是运行docker容器的基础，容器运行前，必须存在对应的镜像，如果本地没有对应的镜像，docker会自动从默认仓库（DockerHub） 下载镜像,如果有本地镜像，也可以从本地仓库下载镜像获取镜像的主要方式是从共有仓库（DockerHub）下载 搜索并下载镜像（例如调用ubuntu镜像） 11.docker search ubuntu 搜索ubuntu镜像 其中列出了查找到的镜像名称、描述、星级、官方 、自动化的 12.docker pull ubuntu 下载镜像 13.docker images 查看已经下载的镜像文件 参数含义：REPOSITORY : 镜像来源于哪个仓库TAG : 镜像标签IMAGE ID : 镜像id(唯一标识镜像)CREATED : 镜像创建时间SIZE : 镜像大小，优秀的镜像往往体积小 如果不指定镜像系统版本，则会下载最新版本镜像，也可以通过指定TAG的方法来下载特定版本的镜像,在生产中不应忽略镜像标签信息或使用默认的latest标签，内容是不稳定的。 docker pull 默认从Docker Hub Registry仓库下载镜像，如果从非官方仓库下载，则需要在仓库名称前指定完整的仓库地址 例如docker pull hub.c.163.com/public/ubuntu14.04 即从网易下载 docker tag 为本地镜像任意添加新的标签14.docker tag ubuntu:latest myubuntu:latest 该命令添加的标签实际起到了类似链接的作用 15.docker inspect 获取镜像详细信息(元数据) 返回的时json格式信息，如果想要其中一项内容时，使用-f参数来指定 1docker inspect -f &#123;&#123;.RepoTag&#125;&#125; ImageID 16.docker history 查看镜像历史 镜像文件由多个层组成，docker history 可以查看镜像的创建过程 启动一个基于该ubuntu镜像的容器，并进入该容器 127.docker run -idt ubuntu /bin/bash8.docker exec -it /bin/bash -i是为了让容器能接受用户的输入，-t是指定docker为容器创建一个tty19.df -TH 查看容器文件系统的磁盘使用 保存和载入镜像 用户可以将镜像保存到本地以载入使用，或者将其复制到另外的文件系统110.docker save -o ubuntu_latest_save.tar ubuntu:latest 保存镜像 可以把保存的镜像文件载入到系统中，并载入标签等镜像文件的元数据 1211.docker load &lt; ubuntu_latest_save.tar 载入镜像12.docker load --input ubuntu_latest_save.tar 删除镜像 查询后可以看到镜像id 113.docker rmi IMAGE ID 报错为该镜像被683容器所使用，需要先删除基于这个镜像所创建的容器 docker ps -a 查询容器可以看到存在基于镜像ubuntu的容器状态为UP ，表示正在运行 114.docker stop CONTAINER ID 停止容器 115.docker rm CONTAINER ID删除该容器 116.docker rmi IMAGE ID 镜像已经删除。其中删除容器为rm 删除镜像为rmi。可以在待删除的镜像名称前面加参数-f ，强制删除。后来在DockerFile中推荐以下的命令写法 12317.docker container stop18.docker container rm19.docker images rm 创建镜像 创建镜像有三种方法，分别是基于本地模板导入镜像、基于已有镜像的容器创建镜像，基于Dockerfile 创建镜像1&gt; 基于本地模板导入镜像如果本地有镜像的模板文件，可以基于该模板创建镜像，镜像模板文件也可以从OpenVZ下载 wget http://download.openvz.org/template/precreated/ubuntu-14.04-x86_64-minimal.tar.gz 下载模板文件 下载完成后，执行以下命令，可以用该模板文件创建文件 120.cat ubuntu-14.04-x86_64-minimal.tar.gz | docker import - ubuntu-14.04_minimal_amd64 其中 docker import：从归档文件中创建镜像用法：docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]-c :应用docker 指令创建镜像；-m :提交时的说明文字； 可以看到刚刚导出的镜像，启动并运行 2&gt;基于已有的镜像容器创建镜像接上图在容器中新建一个for_new_image 目录 与原容器相比此时已经发生变化，，可以提交为新镜像 121.docker commit -m &quot;creatd new dir&quot; -a &quot;root&quot; 87acd63067e1 new_ubuntu 其中 docker commit ：从容器创建一个新的镜像。语法： docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]-a :提交的镜像作者；-c :使用Dockerfile指令来创建镜像；-m :提交时的说明文字；-p :在commit时，将容器暂停。 提交成功后会返回镜像ID，可以看到新镜像已经存在 3&gt; 基于Dockerfile 创建镜像&nbsp;&nbsp;&nbsp;&nbsp;Dockerfile 是一种被Docker程序解释的脚本，每条指令对应linux下的一条命令， Docker程序可以读取Dockerfile脚本，根据指令生成定制的镜像。Dockerfile指令分为构建指令和设置指令。构建指令用于构建镜像，不会在容器的镜像上运行；设置指令用于设置镜像属性，其操作可以在容器的镜像上执行 （1）FROM&nbsp;&nbsp;&nbsp;&nbsp;构建指令，用于指定基础镜像，必须指定，且必须在Dockerfile所有指令之前指定，因为后续指令都依赖该指令指定的镜像，，可以指定DockerHub中的镜像，也可以指定本地仓库中的 （2）MAINTAINER &nbsp;&nbsp;&nbsp;&nbsp;构建指令，用于将镜像制作者相关信息写入镜像中，当我们对该镜像执行docker inspect 命令时，会显示该字段 （3）RUN &nbsp;&nbsp;&nbsp;&nbsp;构建指令，用于执行任何被基础镜像所支持的命令，例如ubuntu基础镜像只能使用ubuntu命令，centos基础镜像只能使用centos命令 （4）CMD &nbsp;&nbsp;&nbsp;&nbsp;设置指令，用于指定容器启动时执行的操作，可以执行自定义脚本，亦可以执行系统命令，，此命令只能在Dockerfile脚本中设置一次，设置多个只会执行最后一个 （5）ENTRYPOINT （entrypoint） &nbsp;&nbsp;&nbsp;&nbsp;设置指令，用于指定容器启动时执行的命令，可以在Dockerfile脚本中设置多次，只有最后一个有效 ENTRYPOINT 使用分两种情况 ： &nbsp;&nbsp;&nbsp;&nbsp;独自使用时，如果同时使用了CMD命令，且CMD指定的是一个完整可执行命令，那么二者会互相覆盖，只有写在最后的那条指令有效；与CMD指令配合使用，CMD指令可以指定ENTRYPOINT的默认参数，此时CMD指令指定的仅仅是参数部分，而ENTRYPOINT需要使用JSON方式指定需要执行的命令但不能使用参数 （6）USER 设置指令，用于设置启动容器的用户，默认为root （7）EXPOSE &nbsp;&nbsp;&nbsp;&nbsp;设置指令，用于将容器中的端口映射称为宿主机中的摸个端口。极大方便了访问容器 。 宿主机IP：PORT &nbsp;&nbsp;&nbsp;&nbsp;需要两步操作，首先在Docerfile中使用 EXPOSE设置需要映射的容器端口号，然后在 docker run 中使用参数 -p 指定前面的端口号，该端口号就会被随机映射称为宿主机中的一个端口号，也可以指定需要映射到宿主机的哪个端口，但要注意指定的端口没有被占用。 &nbsp;&nbsp;&nbsp;&nbsp;端口映射是Docker比较重要的一个功能，因为每次运行容器时，容器IP不能被指定，而是桥接模式网卡随机生成的，但是宿主机IP地址是固定的，将容器端口映射称为宿主机上的一个端口，可以免去每次访问容器时都要查看容器IP的麻烦 &nbsp;&nbsp;&nbsp;&nbsp;一个运行中的容器，使用 ==docker port CONTAINER ID== 查看该端口号在宿主机上的映射端口 （8） ENV （environment） &nbsp;&nbsp;&nbsp;&nbsp;构建指令，用于在镜像中设置一个环境变量，设置成功后，后续的RUN 指令都可以使用该指令设置的环境 （9）ADD &nbsp;&nbsp;&nbsp;&nbsp;构建指令，用于把本地文件添加到容器，默认所有拷贝到容器中文件和文件夹权限为755（-rwxr-xr-x），UID和GID为0，如果是一个目录，那么会将该目录下的所有文件添加到容器，但不包括目录；如果文件是可识别的压缩格式，则docker会进行解压缩 （10）VOLUME&nbsp;&nbsp;&nbsp;&nbsp;设置指令， 指定挂载点，用于使容器中某个目录具有持久化存储数据的功能，该目录可以被容器本身使用，也可以共享给其他容器使用由于容器使用AUFS文件系统，不能持久化数据，容器关闭后，所有更改也会消失，因此容器有应用持久化数据存储的需求时，可以使用该指令 （11）WORKDIR&nbsp;&nbsp;&nbsp;&nbsp;设置指令，可以多次切换目录（cd），可以在RUN, CMD, ENTRYPOINT 命令前使用 (12) COPY (src)…(dest)&nbsp;&nbsp;&nbsp;&nbsp;复制本地主机 src (为Dockerfile所在目录的相对路径、文件或目标）下的内容到镜像中的 dest 下。路径不存在时会自动创建。支持正则。 下面展示一则使用Dockerfile创建Tomcat镜像的实例1234567891011121314151617181920212223242526272829303132333435363738394041#Pull base image // 获取基础镜像FROM ubuntu:latestMAINTAINER XXX# LABEL maintainer=&quot;XXX&quot;#update source //更新镜像源RUN echo &quot;deb http://cn.archive.ubuntu.com/ubuntu xenial main universe&quot;&gt;/etc/apt/sources.listRUN apt-get update#Install curl // 安装curlRUN apt-get -y install curl#Install JDK 8 //安装JDK,其中的cookie使用burpsuit获取RUN cd /tmp &amp;&amp; curl -L &apos;http://download.oracle.com/otn-pub/java/jdk/8u191-b12/2787e4a523244c269598db4e85c51e0c/jdk-8u191-linux-i586.tar.gz&apos; -H &apos;Cookie:s_fid=1CC16A1445A28C96-0DF2FFDC49166DB3; ELOQUA=GUID=25787B725D6B4A1E98D0D92A1C00A0F7; s_nr=1540978397285-Repeat; RT=&quot;sl=23&amp;ss=1540977568733&amp;tt=40261&amp;obo=21&amp;sh=1540977921638%3D23%3A2 1%3A40261%2C1540977919016%3D22%3A21%3A37654%2C1540977918989%3D21%3A20%3A3 7654%2C1540977913741%3D20%3A19%3A37654%2C1540977913712%3D19%3A18%3A37654&amp;dm=oracle.com&amp;si=6be7a975-8d66-41f3-92c8-a5748709fec8&amp;bcn=%2F%2F1288af 19.akstat.io%2F&amp;nu=http%3A%2F%2Fdownload.oracle.com%2Fotn-pub%2Fjava%2Fjdk%2F8u191-b12%2F2787e4a523244c269598db4e85c51e0c%2Fjdk-8u191-linux-i586 .tar.gz&amp;cl=1540978405737&quot;;atgRecVisitorId=127AFu33Mp_NNJQHlgn2ZpQPg5vZT6c4TietQ0-KTTWmfuc8127; gpw_e24=https%3A%2F%2Fwww.oracle.com%2Ftechnetwork %2Fjava%2Fjavase%2Fdownloads%2Fjdk8-downloads-2133151.html; s_cc=true; s_sq=%5B%5BB%5D%5D; oraclelicense=accept-securebackup-cookie&apos;|tar -zxRUN mkdir -p /usr/lib/jvmRUN mv /tmp/jdk1.8.0_191 /usr/lib/jvm/java-8-oracle/#Set Oracle JDK 8 as default Java //配置Java环境RUN update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-8-oracle/bin/java 300RUN update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java-8-oracle/bin/javac 300ENV JAVA_HOME /usr/lib/jvm/java-8-oracle/#Install Tomcat8 //安装TomcatRUN cd /tmp &amp;&amp; curl -L &apos;https://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.34/bin/apache-tomcat-8.5.34.tar.gz&apos;| tar -xzRUN mv /tmp/apache-tomcat-8.5.34/ /opt/tomcat8/ENV CATALINA_HOME /opt/tomcat8ENV PATH $PATH:$CATALINA_HOME/bin#Expose ports EXPOSE 8090:8080 //设置映射端口，tomcat的8080端口映射为宿主机的8090端口#Define default command //运行tomcat，查看日志ENTRYPOINT /opt/tomcat8/bin/startup.sh &amp;&amp; tail -f /opt/tomcat8/logs/catalina.out 或 运行Dockerfile要在Dockerfile所在的目录，”./“应为Dockerfile脚本所在目录，否则就会报上下文环境的错误,MV、COPY、ADD的文件位置都是相对于/root 来说的第一遍执行(使用的第一条命令)时出现很多错误，最后修改成功了，以下截图是第二遍执行(第二条命令) 因此会报使用缓存 在下载jdk的时候，需要加上cookie，没加时出现以下报错 Java和Tomcat程序的安装包下载地址可能会发生变化，因此使用该脚本时先根据实际下载地址对其进行修改，包括解压后的生成路径也会有改变 运行镜像，启动一个基于镜像tomcat的容器，宿主机输入http://localhost:8090 即可访问tomcat]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[亲测Hexo+Github个人博客搭建]]></title>
    <url>%2F2018%2F11%2F15%2F%E4%BA%B2%E6%B5%8BHexo-Github%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[什么是 Hexo？Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 安装 Hexo 相当简单然而在安装前，您必须检查电脑中是否已安装下列应用程序： Node.jshttps://nodejs.org/dist/v10.13.0/node-v10.13.0-x64.msi(Winx64) Githttps://github.com/git-for-windows/git/releases/download/v2.19.1.windows.1/Git-2.19.1-64-bit.exe（Win x64） 输入 ： 123node -vnpm -vgit --version 检查Node.js 和 Git 是否 安装成功 在此处，如果Node.js 版本低，在后面的搭建过程中无法顺利执行，建议各位在官网下载最新版本；Git如果没有加入环境变量需要将Git添加到环境变量 在自己认为合适的位置创建一个个文件夹，我的是E:\Personal-blog\hexo ，在命令行界面进入该文件夹，然后使用 npm 即可完成 Hexo 的安装 1npm install -g hexo-cli 安装完成，可能会有WARN，但不会影响正常使用然后输入： 1npm install hexo --save 在这一步时，我遇到如下报错12345npm WARN deprecated titlecase@1.1.2: no longer maintainednpm ERR! Unexpected end of JSON input while parsing near &apos;...&quot;:&quot;^0.3.1&quot;,&quot;benchmark&apos;npm ERR! A complete log of this run can be found in:npm ERR! C:\Users\dell\AppData\Roaming\npm-cache\_logs\2018-11-12T15_46_56_713Z-debug.log 解决办法：更新npm源即可 1npm config set registry https://registry.npm.taobao.org Hexo安装完成，检测是否正确安装 1hexo -v Hexo的配置在当前目录下新建一个名为blog的文件夹，用于存放博客网站的信息在命令行进入blog，初始化该文件夹，并安装所需组件 12hexo init npm install 安装完成后，检测是否安装成功 1hexo g 1hexo s 根据提示访问https://localhost:4000/ 出现该界面说明Hexo在本地的配置完成了。（因为我改了配置文件，所以显示出我的名字，原位置应为Hexo） 注册GitHub账号与配置https://github.com/ 进入网站后，点击Sign up 进行注册， 填写自己的用户名，邮箱，密码（邮箱后面会用到验证账户） 注册完成后，新建代码仓库点击网页右上角”+” 中的New repo ，新建仓库 在该界面输入仓库名，描述信息，选择共有或私有仓库注意仓库名要和你的用户名一致(yourname.github.io)，否则后面会访问错误 创建完成后会自动显示你的仓库界面 点击选项栏 Setting ，向下拖至此处，将none 选项选为第一个选项，开启GitHub Pages功能 并Save，可以暂时Change theme，以供暂时访问，但是后面我们使用的是Hexo主题，两者并不冲突 一段时间后即可看到提示创建成功 那么Github一侧的配置已经全部结束了。 将GitHub Page与Hexo关联配置Git个人信息123git config --golbal user.name &quot;username&quot;git config --global user.email &quot;xxx@example.com&quot;git config --list //查看用户信息 可以看到如下信息 在合适的位置新建文件夹daemon ，进入到该文件夹中右击进入 Git Bash 1$ git init 该命令将创建一个名为 .git 的子目录，这个子目录含有你初始化的 Git 仓库中所有的必须文件，这些文件是 Git 仓库的骨干 在Git bash中 123cd ~/.ssh lscat id_rsa.pub 就可以看到你自己的公钥，复制下来，进入Github的个人设置界面 点击New Ssh Key 将密钥粘贴上，添加就可以了 1ssh -T git@github.com 成功。编辑 hexo下的blog下的_config.yml123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/CrimsonRomance/CrimsonRomance.github.io branch: master 编辑daemon.git 下的config12345678910[core] repositoryformatversion = 0 filemode = false bare = false logallrefupdates = true symlinks = false ignorecase = true[branch &quot;master&quot;] remote = https://github.com/CrimsonRomance/CrimsonRomance.github.io merge = refs/heads/master 然后进入 hexo\blog ，右击进入 git bash 12hexo g // 生成hexo d // 部署 如果在 hexo d 出现下面的 错误， 1npm install --save hexo-deployer-git 安装此扩展即可 ，然后重新 hexo g ， hexo d 然后访问网站（https://youname.github.io/）即可]]></content>
      <tags>
        <tag>Hexo+GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F11%2F12%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
